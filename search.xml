<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Java 并发编程]]></title>
    <url>%2F2019%2F04%2F16%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[请谈谈你对 volatile 的理解volatile 是 Java 虚拟机提供的轻量级的同步机制 保证可见性 禁止指令排序 不保证原子性 JMM（Java 内存模型） 你谈谈基本概念 JMM 本身是一种抽象的概念并不是真实存在，它描述的是一组规定或则规范，通过这组规范定义了程序中的访问方式。 JMM 同步规定 线程解锁前，必须把共享变量的值刷新回主内存 线程加锁前，必须读取主内存的最新值到自己的工作内存 加锁解锁是同一把锁 由于 JVM 运行程序的实体是线程，而每个线程创建时 JVM 都会为其创建一个工作内存，工作内存是每个线程的私有数据区域，而 Java 内存模型中规定所有变量的储存在主内存，主内存是共享内存区域，所有的线程都可以访问，但线程对变量的操作（读取赋值等）必须都工作内存进行看。 首先要将变量从主内存拷贝的自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，不能直接操作主内存中的变量，工作内存中存储着主内存中的变量副本拷贝，前面说过，工作内存是每个线程的私有数据区域，因此不同的线程间无法访问对方的工作内存，线程间的通信(传值)必须通过主内存来完成。 内存模型图 三大特性 可见性 123456789101112131415161718192021222324252627282930313233/** * @Author: cuzz * @Date: 2019/4/16 21:29 * @Description: 可见性代码实例 */public class VolatileDemo &#123; public static void main(String[] args) &#123; Data data = new Data(); new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + " coming..."); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; data.addOne(); System.out.println(Thread.currentThread().getName() + " updated..."); &#125;).start(); while (data.a == 0) &#123; // looping &#125; System.out.println(Thread.currentThread().getName() + " job is done..."); &#125;&#125;class Data &#123; // int a = 0; volatile int a = 0; void addOne() &#123; this.a += 1; &#125;&#125; 如果不加 volatile 关键字，则主线程会进入死循环，加 volatile 则主线程能够退出，说明加了 volatile 关键字变量，当有一个线程修改了值，会马上被另一个线程感知到，当前值作废，从新从主内存中获取值。对其他线程可见，这就叫可见性。 原子性 123456789101112131415161718192021222324252627282930public class VolatileDemo &#123; public static void main(String[] args) &#123; // test01(); test02(); &#125; // 测试原子性 private static void test02() &#123; Data data = new Data(); for (int i = 0; i &lt; 20; i++) &#123; new Thread(() -&gt; &#123; for (int j = 0; j &lt; 1000; j++) &#123; data.addOne(); &#125; &#125;).start(); &#125; // 默认有 main 线程和 gc 线程 while (Thread.activeCount() &gt; 2) &#123; Thread.yield(); &#125; System.out.println(data.a); &#125;&#125;class Data &#123; volatile int a = 0; void addOne() &#123; this.a += 1; &#125;&#125; 发现并不能输入 20000 有序性 计算机在执行程序时，为了提高性能，编译器个处理器常常会对指令做重排，一般分为以下 3 种 编译器优化的重排 指令并行的重排 内存系统的重排 单线程环境里面确保程序最终执行的结果和代码执行的结果一致 处理器在进行重排序时必须考虑指令之间的数据依赖性 多线程环境中线程交替执行，由于编译器优化重排的存在，两个线程中使用的变量能否保证用的变量能否一致性是无法确定的，结果无法预测 代码示例 123456789101112131415161718public class ReSortSeqDemo &#123; int a = 0; boolean flag = false; public void method01() &#123; a = 1; // flag = true; // ----线程切换---- flag = true; // a = 1; &#125; public void method02() &#123; if (flag) &#123; a = a + 3; System.out.println("a = " + a); &#125; &#125;&#125; 如果两个线程同时执行，method01 和 method02 如果线程 1 执行 method01 重排序了，然后切换的线程 2 执行 method02 就会出现不一样的结果。 禁止指令排序volatile 实现禁止指令重排序的优化，从而避免了多线程环境下程序出现乱序的现象 先了解一个概念，内存屏障（Memory Barrier）又称内存栅栏，是一个 CPU 指令，他的作用有两个： 保证特定操作的执行顺序 保证某些变量的内存可见性（利用该特性实现 volatile 的内存可见性） 由于编译器个处理器都能执行指令重排序优化，如果在指令间插入一条 Memory Barrier 则会告诉编译器和 CPU，不管什么指令都不能个这条 Memory Barrier 指令重排序，也就是说通过插入内存屏障禁止在内存屏障前后执行重排序优化。内存屏障另一个作用是强制刷出各种 CPU 缓存数据，因此任何 CPU 上的线程都能读取到这些数据的最新版本。 下面是保守策略下，volatile写插入内存屏障后生成的指令序列示意图： 下面是在保守策略下，volatile读插入内存屏障后生成的指令序列示意图： 线程安全性保证 工作内存与主内存同步延迟现象导致可见性问题 可以使用 synchronzied 或 volatile 关键字解决，它们可以使用一个线程修改后的变量立即对其他线程可见 对于指令重排导致可见性问题和有序性问题 可以利用 volatile 关键字解决，因为 volatile 的另一个作用就是禁止指令重排序优化 你在哪些地方用到过 volatile单例 多线程环境下可能存在的安全问题 123456789101112131415161718192021@NotThreadSafepublic class Singleton01 &#123; private static Singleton01 instance = null; private Singleton01() &#123; System.out.println(Thread.currentThread().getName() + " construction..."); &#125; public static Singleton01 getInstance() &#123; if (instance == null) &#123; instance = new Singleton01(); &#125; return instance; &#125; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 10; i++) &#123; executorService.execute(()-&gt; Singleton01.getInstance()); &#125; executorService.shutdown(); &#125;&#125; 发现构造器里的内容会多次输出 双重锁单例 代码 123456789101112131415161718192021222324public class Singleton02 &#123; private static volatile Singleton02 instance = null; private Singleton02() &#123; System.out.println(Thread.currentThread().getName() + " construction..."); &#125; public static Singleton02 getInstance() &#123; if (instance == null) &#123; synchronized (Singleton01.class) &#123; if (instance == null) &#123; instance = new Singleton02(); &#125; &#125; &#125; return instance; &#125; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; 10; i++) &#123; executorService.execute(()-&gt; Singleton02.getInstance()); &#125; executorService.shutdown(); &#125;&#125; 如果没有加 volatile 就不一定是线程安全的，原因是指令重排序的存在，加入 volatile 可以禁止指令重排。 原因是在于某一个线程执行到第一次检测，读取到的 instance 不为 null 时，instance 的引用对象可能还没有完成初始化。 instance = new Singleton() 可以分为以下三步完成 123memory = allocate(); // 1.分配对象空间instance(memory); // 2.初始化对象instance = memory; // 3.设置instance指向刚分配的内存地址，此时instance != null 步骤 2 和步骤 3 不存在依赖关系，而且无论重排前还是重排后程序的执行结果在单线程中并没有改变，因此这种优化是允许的。 发生重排 123memory = allocate(); // 1.分配对象空间instance = memory; // 3.设置instance指向刚分配的内存地址，此时instance != null，但对象还没有初始化完成instance(memory); // 2.初始化对象 所以不加 volatile 返回的实例不为空，但可能是未初始化的实例 CAS 你知道吗？1234567891011public class CASDemo &#123; public static void main(String[] args) &#123; AtomicInteger atomicInteger = new AtomicInteger(666); // 获取真实值，并替换为相应的值 boolean b = atomicInteger.compareAndSet(666, 2019); System.out.println(b); // true boolean b1 = atomicInteger.compareAndSet(666, 2020); System.out.println(b1); // false atomicInteger.getAndIncrement(); &#125;&#125; CAS 底层原理？谈谈对 UnSafe 的理解？getAndIncrement();12345678/** * Atomically increments by one the current value. * * @return the previous value */public final int getAndIncrement() &#123; return unsafe.getAndAddInt(this, valueOffset, 1);&#125; 引出一个问题：UnSafe 类是什么？ UnSafe 类123456789101112131415161718public class AtomicInteger extends Number implements java.io.Serializable &#123; private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; try &#123; // 获取下面 value 的地址偏移量 valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField("value")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; private volatile int value; // ...&#125; Unsafe 是 CAS 的核心类，由于 Java 方法无法直接访问底层系统，而需要通过本地（native）方法来访问， Unsafe 类相当一个后门，基于该类可以直接操作特定内存的数据。Unsafe 类存在于 sun.misc 包中，其内部方法操作可以像 C 指针一样直接操作内存，因为 Java 中 CAS 操作执行依赖于 Unsafe 类。 变量 vauleOffset，表示该变量值在内存中的偏移量，因为 Unsafe 就是根据内存偏移量来获取数据的。 变量 value 用 volatile 修饰，保证了多线程之间的内存可见性。 CAS 是什么 CAS 的全称 Compare-And-Swap，它是一条 CPU 并发。 它的功能是判断内存某一个位置的值是否为预期，如果是则更改这个值，这个过程就是原子的。 CAS 并发原体现在 JAVA 语言中就是 sun.misc.Unsafe 类中的各个方法。调用 UnSafe 类中的 CAS 方法，JVM 会帮我们实现出 CAS 汇编指令。这是一种完全依赖硬件的功能，通过它实现了原子操作。由于 CAS 是一种系统源语，源语属于操作系统用语范畴，是由若干条指令组成，用于完成某一个功能的过程，并且原语的执行必须是连续的，在执行的过程中不允许被中断，也就是说 CAS 是一条原子指令，不会造成所谓的数据不一致的问题。 分析一下 getAndAddInt 这个方法 12345678// unsafe.getAndAddIntpublic final int getAndAddInt(Object obj, long valueOffset, long expected, int val) &#123; int temp; do &#123; temp = this.getIntVolatile(obj, valueOffset); // 获取快照值 &#125; while (!this.compareAndSwap(obj, valueOffset, temp, temp + val)); // 如果此时 temp 没有被修改，就能退出循环，否则重新获取 return temp;&#125; CAS 的缺点？ 循环时间长开销很大 如果 CAS 失败，会一直尝试，如果 CAS 长时间一直不成功，可能会给 CPU 带来很大的开销（比如线程数很多，每次比较都是失败，就会一直循环），所以希望是线程数比较小的场景。 只能保证一个共享变量的原子操作 对于多个共享变量操作时，循环 CAS 就无法保证操作的原子性。 引出 ABA 问题 原子类 AtomicInteger 的 ABA 问题谈一谈？原子更新引用知道吗？ 原子引用 12345678910public class AtomicReferenceDemo &#123; public static void main(String[] args) &#123; User cuzz = new User("cuzz", 18); User faker = new User("faker", 20); AtomicReference&lt;User&gt; atomicReference = new AtomicReference&lt;&gt;(); atomicReference.set(cuzz); System.out.println(atomicReference.compareAndSet(cuzz, faker)); // true System.out.println(atomicReference.get()); // User(userName=faker, age=20) &#125;&#125; ABA 问题是怎么产生的 123456789101112131415161718192021222324252627/** * @program: learn-demo * @description: ABA * @author: cuzz * @create: 2019-04-21 23:31 **/public class ABADemo &#123; private static AtomicReference&lt;Integer&gt; atomicReference = new AtomicReference&lt;&gt;(100); public static void main(String[] args) &#123; new Thread(() -&gt; &#123; atomicReference.compareAndSet(100, 101); atomicReference.compareAndSet(101, 100); &#125;).start(); new Thread(() -&gt; &#123; // 保证上面线程先执行 try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; atomicReference.compareAndSet(100, 2019); System.out.println(atomicReference.get()); // 2019 &#125;).start(); &#125;&#125; 当有一个值从 A 改为 B 又改为 A，这就是 ABA 问题。 时间戳原子引用 123456789101112131415161718192021222324252627282930313233343536373839404142package com.cuzz.thread;import java.util.concurrent.atomic.AtomicReference;import java.util.concurrent.atomic.AtomicStampedReference;/** * @program: learn-demo * @description: ABA * @author: cuzz * @create: 2019-04-21 23:31 **/public class ABADemo2 &#123; private static AtomicStampedReference&lt;Integer&gt; atomicStampedReference = new AtomicStampedReference&lt;&gt;(100, 1); public static void main(String[] args) &#123; new Thread(() -&gt; &#123; int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + " 的版本号为：" + stamp); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; atomicStampedReference.compareAndSet(100, 101, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1 ); atomicStampedReference.compareAndSet(101, 100, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1 ); &#125;).start(); new Thread(() -&gt; &#123; int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + " 的版本号为：" + stamp); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; boolean b = atomicStampedReference.compareAndSet(100, 2019, stamp, stamp + 1); System.out.println(b); // false System.out.println(atomicStampedReference.getReference()); // 100 &#125;).start(); &#125;&#125; 我们先保证两个线程的初始版本为一致，后面修改是由于版本不一样就会修改失败。 我们知道 ArrayList 是线程不安全，请编写一个不安全的案例并给出解决方案？ 故障现象 123456789101112public class ContainerDemo &#123; public static void main(String[] args) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); Random random = new Random(); for (int i = 0; i &lt; 100; i++) &#123; new Thread(() -&gt; &#123; list.add(random.nextInt(10)); System.out.println(list); &#125;).start(); &#125; &#125;&#125; 发现报 java.util.ConcurrentModificationException 导致原因 解决方案 new Vector(); Collections.synchronizedList(new ArrayList&lt;&gt;()); 优化建议 1 参考链接 Java内存模型-volatile]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生产者消费者]]></title>
    <url>%2F2019%2F04%2F06%2F%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%2F</url>
    <content type="text"><![CDATA[维基百科解释： In computing, the producer–consumer problem[1][2] (also known as the bounded-buffer problem) is a classic example of a multi-process) synchronization) problem. The problem describes two processes, the producer and the consumer, who share a common, fixed-size buffer) used as a queue). The producer’s job is to generate data, put it into the buffer, and start again. At the same time, the consumer is consuming the data (i.e., removing it from the buffer), one piece at a time. The problem is to make sure that the producer won’t try to add data into the buffer if it’s full and that the consumer won’t try to remove data from an empty buffer. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import java.util.LinkedList;import java.util.List;import java.util.Random;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;/** * @Author: cuzz * @Date: 2019/4/6 13:03 * @Description: 生产者消费者 */public class ProducerConsumerDemo &#123; public static void main(String[] args) &#123; Container container = new Container(); ExecutorService executor = Executors.newFixedThreadPool(2); executor.execute(() -&gt; container.produce()); executor.execute(() -&gt; container.consume()); executor.shutdown(); &#125;&#125;class Container &#123; private List&lt;Integer&gt; list = new LinkedList&lt;&gt;(); private final int MAX_SIZE = 5; private Random random = new Random(); public void produce() &#123; while (true) &#123; synchronized (this) &#123; try &#123; while (list.size() &gt;= MAX_SIZE) &#123; wait(); &#125; int i = random.nextInt(); System.out.println("produce..." + i); list.add(i); notify(); Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; public void consume() &#123; while (true) &#123; try &#123; synchronized (this) &#123; while (list.isEmpty()) &#123; wait(); &#125; int i = list.remove(1); System.out.println("consume..." + i); notify(); Thread.sleep(1000); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>ProducerConsumer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LRUCache]]></title>
    <url>%2F2019%2F03%2F16%2FLRUCache%2F</url>
    <content type="text"><![CDATA[LRU（Least recently used，最近最少使用）算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高” 。 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899/** * @Author: cuzz * @Date: 2019/3/16 15:35 * @Description: LRU cache */public class LRUCache &#123; private Map&lt;Integer, DLinkedList&gt; cache = new HashMap&lt;&gt;(); private int count; private int capacity; private DLinkedList head, tail; public LRUCache(int capacity) &#123; this.count = 0; this.capacity = capacity; this.head = new DLinkedList(); this.tail = new DLinkedList(); head.next = tail; tail.pre = head; &#125; public int get(int key) &#123; DLinkedList node = cache.get(key); if (node == null) &#123; return -1; &#125; removeNode(node); addHead(node); return node.value; &#125; public void put(int key, int value) &#123; DLinkedList node = cache.get(key); if (node == null) &#123; node = new DLinkedList(key, value); addHead(node); cache.put(key, node); count++; if (count &gt; capacity) &#123; DLinkedList preTail = tail.pre; removeNode(preTail); cache.remove(preTail.key); count--; &#125; &#125; else &#123; node.value = value; removeNode(node); addHead(node); &#125; &#125; // 移除给定的结点 private void removeNode(DLinkedList node) &#123; DLinkedList pre = node.pre; DLinkedList next = node.next; pre.next = next; next.pre = pre; &#125; // 把结点添加头节点 private void addHead(DLinkedList node) &#123; DLinkedList next = head.next; head.next = node; node.next = next; next.pre = node; node.pre = head; &#125; public static void main(String[] args) &#123; LRUCache cache = new LRUCache(2); cache.put(1, 1); cache.put(2, 2); System.out.println(cache.get(1)); // 返回 1 cache.put(3, 3); // 使 2 作废 System.out.println(cache.get(2)); // 返回 -1 cache.put(4, 4); // 使 1 作废 System.out.println(cache.get(1)); // 返回 -1 未找到 System.out.println(cache.get(3)); // 返回 3 System.out.println(cache.get(4)); // 返回 4 &#125;&#125;class DLinkedList &#123; int key; int value; DLinkedList pre; DLinkedList next; public DLinkedList() &#123;&#125;; public DLinkedList(int key, int value) &#123; this.key = key; this.value = value; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>LRUCache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解Java虚拟机（四）]]></title>
    <url>%2F2019%2F03%2F04%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%88%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[synchronized 字节码分析我们先来看一下一个简单的方法 123456789101112/** * @Author: cuzz * @Date: 2019/3/4 13:34 * @Description: */public class MyTest02 &#123; int x = 0; public void setX(int x) &#123; this.x = x; &#125;&#125; 使用 javap -v com.cuzz.jvm.bytecode.MyTest02 命令，找到 setX 方法 12345678910111213141516public void setX(int); descriptor: (I)V flags: ACC_PUBLIC Code: stack=2, locals=2, args_size=2 0: aload_0 1: iload_1 2: putfield #2 // Field x:I 5: return LineNumberTable: line 12: 0 line 13: 5 LocalVariableTable: Start Length Slot Name Signature 0 6 0 this Lcom/cuzz/jvm/bytecode/MyTest02; 0 6 1 x I 如果我们在方法中添加 synchronzied 关键字 1234567public class MyTest02 &#123; int x = 0; public synchronized void setX(int x) &#123; this.x = x; &#125;&#125; 我们再反编译一下 12345678910111213141516public synchronized void setX(int); descriptor: (I)V flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=2, locals=2, args_size=2 0: aload_0 1: iload_1 2: putfield #2 // Field x:I 5: return LineNumberTable: line 12: 0 line 13: 5 LocalVariableTable: Start Length Slot Name Signature 0 6 0 this Lcom/cuzz/jvm/bytecode/MyTest02; 0 6 1 x I 对比这两个反编译的结果，我们发现在 flags 中多了 ACC_SYNCHRONIZED，不会出现 monitorenter 和 monitorexit。 如果我们是在方法体重添加 synchronized 关键字 12345678910public class MyTest02 &#123; String lock = "lock"; int x = 0; public int getX() &#123; synchronized (lock) &#123; return x; &#125; &#125;&#125; 我们反编译一下 找到 getX 方法 123456789101112131415161718192021222324252627282930313233343536public int getX(); descriptor: ()I flags: ACC_PUBLIC Code: stack=2, locals=3, args_size=1 0: aload_0 1: getfield #3 // Field lock:Ljava/lang/String; 4: dup 5: astore_1 6: monitorenter 7: aload_0 8: getfield #4 // Field x:I 11: aload_1 12: monitorexit 13: ireturn 14: astore_2 15: aload_1 16: monitorexit 17: aload_2 18: athrow Exception table: from to target type 7 13 14 any 14 17 14 any LineNumberTable: line 17: 0 line 18: 7 line 19: 14 LocalVariableTable: Start Length Slot Name Signature 0 19 0 this Lcom/cuzz/jvm/bytecode/MyTest02; StackMapTable: number_of_entries = 1 frame_type = 255 /* full_frame */ offset_delta = 14 locals = [ class com/cuzz/jvm/bytecode/MyTest02, class java/lang/Object ] stack = [ class java/lang/Throwable ] 在 6 中出现 monitorenter，在 16 中出现 moniterexit]]></content>
      <categories>
        <category>深入理解Java虚拟机</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis]]></title>
    <url>%2F2019%2F02%2F23%2FRedis%2F</url>
    <content type="text"><![CDATA[什么是 Redis ？Redis，全称 Remote Dictionary Server，是一个基于内存的高性能 Key-Value 数据库。 另外，Redis 已经成为互联网公司在缓存组件选择的唯一，更多的关注点是，如何使用好 Redis 。 Redis 有什么优点？1、速度快 因为数据存在内存中，类似于 HashMap ，HashMap 的优势就是查找和操作的时间复杂度都是O (1) 。 Redis 本质上是一个 Key-Value 类型的内存数据库，很像Memcached ，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据 flush 到硬盘上进行保存。 因为是纯内存操作，Redis 的性能非常出色，每秒可以处理超过 10 万次读写操作，是已知性能最快的 Key-Value 数据库。 如果我们查看在阿里云销售的 Redis 规格，最低的也是 8W QPS 。 2、支持丰富数据类型 支持 String ，List，Set，Sorted Set，Hash 。 Redis 的出色之处不仅仅是性能，Redis 最大的魅力是支持保存多种数据结构，此外单个 Value 的最大限制是1GB，不像 Memcached只能保存1MB的数据，因此Redis可以用来实现很多有用的功能。比方说： 用他的 List 来做 FIFO 双向链表，实现一个轻量级的高性能消息队列服务。 用他的 Set 可以做高性能的 tag 系统等等。 3、丰富的特性 订阅发布 Pub / Sub 功能 Key 过期策略 事务 支持多个 DB 计数 … 并且在 Redis 5.0 增加了 Stream 功能，一个新的强大的支持多播的可持久化的消息队列，提供类似 Kafka 的功能。 4、持久化存储 Redis 提供 RDB 和 AOF 两种数据的持久化存储方案，解决内存数据库最担心的万一 Redis 挂掉，数据会消失掉。 Redis 有什么缺点？ 由于 Redis 是内存数据库，所以，单台机器，存储的数据量，跟机器本身的内存大小。虽然 Redis 本身有 Key 过期策略，但是还是需要提前预估和节约内存。如果内存增长过快，需要定期删除数据。 另外，可使用 Redis Cluster、Codis 等方案，对 Redis 进行分区，从单机 Redis 变成集群 Redis 。 如果进行完整重同步，由于需要生成 RDB 文件，并进行传输，会占用主机的 CPU ，并会消耗现网的带宽。不过 Redis2.8 版本，已经有部分重同步的功能，但是还是有可能有完整重同步的。比如，新上线的备机。 修改配置文件，进行重启，将硬盘中的数据加载进内存，时间比较久。在这个过程中，Redis 不能提供服务。 Redis 和 Memcached 的区别有哪些？1、Redis 支持复杂的数据结构 Memcached 仅提供简单的字符串。 Redis 提供复杂的数据结构，丰富的数据操作。 也因为 Redis 支持复杂的数据结构，Redis 即使往于 Memcached 推出，却获得更多开发者的青睐。 Redis 相比 Memcached 来说，拥有更多的数据结构，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作，Redis 会是不错的选择。 2、Redis 原生支持集群模式 在 Redis3.x 版本中，官方便能支持 Cluster 模式。 Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。 3、性能对比 Redis 只使用单核，而 Memcached 可以使用多核，所以平均每一个核上 Redis在存储小数据时比 Memcached 性能更高。 在 100k 以上的数据中，Memcached 性能要高于 Redis 。虽然 Redis 最近也在存储大数据的性能上进行优化，但是比起 Memcached，还是稍有逊色。 更多关于性能的对比，可以看看 《Memcached 与 Redis 的关键性能指标比较》 。 4、内存使用效率对比 简单的 Key-Value 存储的话，Memcached 的内存利用率更高，可以使用类似内存池。 如果 Redis 采用 hash 结构来做 key-value 存储，由于其组合式的压缩， 其内存利用率会高于 Memcached 。 Redis 和 Memcached 的内存管理方法不同，Redis 采用的是包装的 malloc/free ， 相较于 Memcached 的内存管理方法 tcmalloc / jmalloc 来说，要简单很多 。 5、网络 IO 模型 Memcached 是多线程，非阻塞 IO 复用的网络模型，原型上接近 Nignx 。 Redis 使用单线程的 IO 复用模型，自己封装了一个简单的 AeEvent 事件处理框架，主要实现了 epoll, kqueue 和 select ，更接近 Apache 早期的模式。 TODO 有点看不懂，找亚普表弟确认中。 6、持久化存储 Memcached 不支持持久化存储，重启时，数据被清空。 Redis 支持持久化存储，重启时，可以恢复已持久化的数据。 也推荐阅读下 《脚踏两只船的困惑 - Memcached 与 Redis》 。 请说说 Redis 的线程模型？ 艿艿：这个是我从网络上找的资料，讲的灰常不错。 redis 内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，所以 redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，根据 socket 上的事件来选择对应的事件处理器进行处理。 文件事件处理器的结构包含 4 个部分： 多个 socket IO 多路复用程序 文件事件分派器 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器） 多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将 socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。 来看客户端与 redis 的一次通信过程： 客户端 socket01 向 redis 的 server socket 请求建立连接，此时 server socket 会产生一个 AE_READABLE 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该事件压入队列中。文件事件分派器从队列中获取该事件，交给连接应答处理器。连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 AE_READABLE 事件与命令请求处理器关联。 假设此时客户端发送了一个 set key value 请求，此时 redis 中的 socket01 会产生 AE_READABLE 事件，IO 多路复用程序将事件压入队列，此时事件分派器从队列中获取到该事件，由于前面 socket01 的 AE_READABLE 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 key value 并在自己内存中完成 key value 的设置。操作完成后，它会将 socket01 的 AE_WRITABLE 事件与令回复处理器关联。 如果此时客户端准备好接收返回结果了，那么 redis 中的 socket01 会产生一个 AE_WRITABLE 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 ok，之后解除 socket01 的 AE_WRITABLE 事件与命令回复处理器的关联。 这样便完成了一次通信。😈 耐心理解一下，灰常重要。如果还是不能理解，可以在网络上搜一些资料，在理解理解。 为什么 Redis 单线程模型也能效率这么高？ 1、纯内存操作。 Redis 为了达到最快的读写速度，将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以 Redis 具有快速和数据持久化的特征。 如果不将数据放在内存中，磁盘 I/O 速度为严重影响 Redis 的性能。 2、核心是基于非阻塞的 IO 多路复用机制。 3、单线程反而避免了多线程的频繁上下文切换问题。 Redis 利用队列技术，将并发访问变为串行访问，消除了传统数据库串行控制的开销 4、Redis 全程使用 hash 结构，读取速度快，还有一些特殊的数据结构，对数据存储进行了优化，如压缩表，对短数据进行压缩存储，再如，跳表，使用有序的数据结构加快读取的速度。 Redis 有几种持久化方式？持久化方式Redis 提供了两种方式，实现数据的持久化到硬盘。 【全量】RDB 持久化，是指在指定的时间间隔内将内存中的数据集快照写入磁盘。实际操作过程是，fork 一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。 【增量】AOF持久化，以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。 二者的区别RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。 AOF持久化以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。 二者优缺点RDB存在哪些优势呢？ 一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。比如，你可能打算每个小时归档一次最近24小时的数据，同时还要每天归档一次最近30天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。 对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。 性能最大化。对于Redis的服务进程而言，在开始持久化时，它唯一需要做的只是fork出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行IO操作了。 相比于AOF机制，如果数据集很大，RDB的启动效率会更高。 RDB又存在哪些劣势呢？ .如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么RDB将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。 由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。 AOF的优势有哪些呢？ 该机制可以带来更高的数据安全性，即数据持久性。Redis中提供了3中同步策略，即每秒同步、每修改同步和不同步。事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而每修改同步，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。至于无同步，无需多言，我想大家都能正确的理解它。 由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据一致性的问题。 如果日志过大，Redis可以自动启用rewrite机制。即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行rewrite切换时可以更好的保证数据安全性。 AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，我们也可以通过该文件完成数据的重建。 AOF的劣势有哪些呢？ 对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。 根据同步策略的不同，AOF在运行效率上往往会慢于RDB。总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和RDB一样高效。 二者选择的标准，就是看系统是愿意牺牲一些性能，换取更高的缓存一致性（aof），还是愿意写操作频繁的时候，不启用备份来换取更高的性能，待手动运行save的时候，再做备份（rdb）。rdb这个就更有些 eventually consistent 的意思了。 常用配置RDB持久化配置 Redis会将数据集的快照dump到dump.rdb文件中。此外，我们也可以通过配置文件来修改Redis服务器dump快照的频率，在打开6379.conf文件之后，我们搜索save，可以看到下面的配置信息： 123save 900 1 # 在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照。save 300 10 # 在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照。save 60 10000 # 在60秒(1分钟)之后，如果至少有10000个key发生变化，则dump内存快照。 AOF持久化配置 在Redis的配置文件中存在三种同步方式，它们分别是： 123appendfsync always # 每次有数据修改发生时都会写入AOF文件。appendfsync everysec # 每秒钟同步一次，该策略为AOF的缺省策略。appendfsync no # 从不同步。高效但是数据不会被持久化。 如何选择 不要仅仅使用 RDB，因为那样会导致你丢失很多数据 也不要仅仅使用 AOF，因为那样有两个问题，第一，你通过 AOF 做冷备，没有 RDB 做冷备，来的恢复速度更快; 第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug 。 Redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。 如果同时使用 RDB 和 AOF 两种持久化机制，那么在 Redis 重启的时候，会使用 AOF 来重新构建数据，因为 AOF 中的数据更加完整。 一般来说， 如果想达到足以媲美 PostgreSQL 的数据安全性， 你应该同时使用两种持久化功能。如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失，那么你可以只使用 RDB 持久化。 有很多用户都只使用 AOF 持久化，但并不推荐这种方式：因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比AOF恢复的速度要快，除此之外，使用 RDB 还可以避免之前提到的 AOF 程序的 bug。 在 Redis4.0 版本开始，允许你使用 RDB-AOF 混合持久化方式，详细可见 《Redis4.0 之 RDB-AOF 混合持久化》 。也因此，RDB 和 AOF 同时使用，是希望达到安全的持久化的推荐方式。 自动化触发 RDB 持久化的方式 根据 redis.conf 配置中 SAVE m n 定时触发（使用的BGSAVE） 主从复制时，主节点自动触发 执行 Debug Reload 执行 Shutdown 且没有开启 AOF 持久化 BGSAVE 原理： 重要知识： bgsave 做镜像全量持久化，AOF 做增量持久化。因为 bgsave 会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要 AOF 来配合使用。在 Redis 实例重启时，会使用 bgsave 持久化文件重新构建内存，再使用 AOF 重放近期的操作指令来实现完整恢复重启之前的状态。 对方追问那如果突然机器掉电会怎样？取决于 AOF 日志 sync 属性的配置，如果不要求性能，在每条写指令时都 sync 一下磁盘，就不会丢失数据。但是在高性能的要求下每次都 sync 是不现实的，一般都使用定时 sync ，比如 1 秒 1 次，这个时候最多就会丢失 1 秒的数据。 对方追问 bgsave 的原理是什么？你给出两个词汇就可以了，fork 和 cow 。fork 是指 Redis 通过创建子进程来进行 bgsave 操作。cow 指的是 copy on write ，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。 Redis 有几种数据“过期”策略？Redis 的过期策略，就是指当 Redis 中缓存的 key 过期了，Redis 如何处理。 Redis 提供了 3 种数据过期策略： 被动删除：当读/写一个已经过期的 key 时，会触发惰性删除策略，直接删除掉这个过期 key 。 主动删除：由于惰性删除策略无法保证冷数据被及时删掉，所以 Redis 会定期主动淘汰一批已过期的 key 。 主动删除：当前已用内存超过 maxmemory 限定时，触发主动清理策略，即 「数据“淘汰”策略」 。 在 Redis 中，同时使用了上述 3 种策略，即它们非互斥的。 想要进一步了解，可以看看 《关于 Redis 数据过期策略》 文章。 Redis 有哪几种数据“淘汰”策略？Redis 内存数据集大小上升到一定大小的时候，就会进行数据淘汰策略。 Redis 提供了 6 种数据淘汰策略： volatile-lru volatile-ttl volatile-random allkeys-lru allkeys-random no-enviction 具体的 每种数据淘汰策略的定义，和 如何选择讨论策略，可见 《Redis实战（二） 内存淘汰机制》 。 Redis LRU 算法 另外，Redis 的 LRU 算法，并不是一个严格的 LRU 实现。这意味着 Redis 不能选择最佳候选键来回收，也就是最久未被访问的那些键。相反，Redis 会尝试执行一个近似的 LRU 算法，通过采样一小部分键，然后在采样键中回收最适合(拥有最久未被访问时间)的那个。 具体的可以看看 《使用 Redis 作为一个 LRU 缓存》 文章。 MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，如何保证 Redis 中的数据都是热点数据？ 艿艿：这个是从网络上找到的一个神奇的问题，并且看了答案之后，觉得有点莫名的对不上。 所以，感觉这个问题的目的是，如何保证热点数据不要被淘汰。 在 「Redis 有哪几种数据“淘汰”策略？」 问题中，我们已经看到，“Redis 内存数据集大小上升到一定大小的时候，就会进行数据淘汰策略。” 。 那么，如果我们此时要保证热点数据不被淘汰，那么需要选择 volatile-lru 或 allkeys-lru 这两个基于 LRU 算法的淘汰策略。 相比较来说，最终会选择 allkeys-lru 淘汰策略。原因是，如果我们的应用对缓存的访问符合幂律分布，也就是存在相对热点数据，或者我们不太清楚我们应用的缓存访问分布状况，我们可以选择 allkeys-lru 策略。 Redis 回收进程如何工作的？ 理解回收进程如何工作是非常重要的： 一个客户端运行了新的命令，添加了新的数据 Redis 检查内存使用情况，如果大于 maxmemory 的限制, 则根据设定好的策略进行回收。 Redis 执行新命令…… 所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下（跌宕起伏）。 如果有大量的 key 需要设置同一时间过期，一般需要注意什么？如果大量的 key 过期时间设置的过于集中，到过期的那个时间点，Redis可能会出现短暂的卡顿现象。 一般需要在时间上加一个随机值，使得过期时间分散一些。 Redis 有哪些数据结构？如果你是 Redis 普通玩家，可能你的回答是如下五种数据结构： 字符串 String 字典Hash 列表List 集合Set 有序集合 SortedSet 如果你是 Redis 中级玩家，还需要加上下面几种数据结构： HyperLogLog Geo Pub / Sub 如果你是 Redis 高端玩家，你可能玩过 Redis Module ，可以再加上下面几种数据结构： BloomFilter RedisSearch Redis-ML JSON 另外，在 Redis 5.0 增加了 Stream 功能，一个新的强大的支持多播的可持久化的消息队列，提供类似 Kafka 的功能。😈 默默跟面试官在装一波。 聊聊 Redis 使用场景Redis 可用的场景非常之多： 数据缓存 会话缓存 时效性数据 访问频率 计数器 社交列表 记录用户判定信息 交集、并集和差集 热门列表与排行榜 最新动态 消息队列 分布式锁 详细的介绍，可以看看如下文章： 《聊聊 Redis 使用场景》 《Redis 应用场景及实例》 《Redis 常见的应用场景解析》 《Redis 和 Memcached 各有什么优缺点，主要的应用场景是什么样的？》 请用 Redis 和任意语言实现一段恶意登录保护的代码，限制 1 小时内每用户 Id 最多只能登录 5 次。 用列表实现，列表中每个元素代表登陆时间，只要最后的第 5 次登陆时间和现在时间差不超过 1 小时就禁止登陆。 具体的代码实现，可以看看 《一道 Redis 面试题》 。 Redis 支持的 Java 客户端都有哪些？使用比较广泛的有三个 Java 客户端： Redisson Redisson ，是一个高级的分布式协调 Redis 客服端，能帮助用户在分布式环境中轻松实现一些 Java 的对象 (Bloom filter, BitSet, Set, SetMultimap, ScoredSortedSet, SortedSet, Map, ConcurrentMap, List, ListMultimap, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, ReadWriteLock, AtomicLong, CountDownLatch, Publish / Subscribe, HyperLogLog)。 Jedis Jedis 是 Redis 的 Java 实现的客户端，其 API 提供了比较全面的 Redis 命令的支持。 Redisson 实现了分布式和可扩展的 Java 数据结构，和 Jedis 相比，Jedis 功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等 Redis 特性。 Redisson 的宗旨是促进使用者对 Redis 的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。 Lettuce Lettuce 是一个可伸缩线程安全的 Redis 客户端。多个线程可以共享同一个 RedisConnection 。它利用优秀 Netty NIO 框架来高效地管理多个连接。 Redis 官方推荐使用 Redisson 或 Jedis 。 Spring Boot 2.x 内置使用 Lettuce 。 如何使用 Redis 实现分布式锁？ 方案一：set 指令 先拿 setnx 来争抢锁，抢到之后，再用 expire 给锁加一个过期时间防止锁忘记了释放。 这时候对方会告诉你说你回答得不错，然后接着问如果在 setnx 之后执行 expire 之前进程意外 crash 或者要重启维护了，那会怎么样？ 这时候你要给予惊讶的反馈：唉，是喔，这个锁就永远得不到释放了。紧接着你需要抓一抓自己得脑袋，故作思考片刻，好像接下来的结果是你主动思考出来的，然后回答：我记得 set 指令有非常复杂的参数，这个应该是可以同时把 setnx 和 expire 合成一条指令来用的！对方这时会显露笑容，心里开始默念：摁，这小子还不错。 所以，我们可以使用 set 指令，实现分布式锁。指令如下： 1SET key value [EX seconds] [PX milliseconds] [NX|XX] 可以使用 SET key value EX seconds NX 命令，尝试获得锁。 具体的实现，可以参考 《Redis 分布式锁的正确实现方式（Java版）》 文章。 方案二：redlock set 指令的方案，适合用于在单机 Redis 节点的场景下，在多 Redis 节点的场景下，会存在分布式锁丢失的问题。所以，Redis 作者 Antirez 基于分布式环境下提出了一种更高级的分布式锁的实现方式：Redlock 。 具体的方案，胖友可以看看老友飞哥的两篇博客： 《Redlock：Redis分布式锁最牛逼的实现》 《Redisson 实现 Redis 分布式锁的 N 种姿势》 对比 Zookeeper 分布式锁 从可靠性上来说，Zookeeper 分布式锁好于 Redis 分布式锁。 从性能上来说，Redis 分布式锁好于 Zookeeper 分布式锁。 所以，没有绝对的好坏，可以根据自己的业务来具体选择。 如何使用 Redis 实现消息队列？一般使用 list 结构作为队列，rpush 生产消息，lpop 消费消息。当 lpop 没有消息的时候，要适当 sleep 一会再重试。 如果对方追问可不可以不用 sleep 呢？list 还有个指令叫 blpop ，在没有消息的时候，它会阻塞住直到消息到来。 如果对方追问能不能生产一次消费多次呢？使用 pub / sub 主题订阅者模式，可以实现 1:N 的消息队列。 如果对方追问 pub / sub 有什么缺点？在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如 rabbitmq 等。 如果对方追问 redis 如何实现延时队列？我估计现在你很想把面试官一棒打死如果你手上有一根棒球棍的话，怎么问的这么详细。但是你很克制，然后神态自若的回答道：使用 sortedset ，拿时间戳作为 score ，消息内容作为 key 调用 zadd 来生产消息，消费者用 zrangebyscore 指令获取 N 秒之前的数据轮询进行处理。 到这里，面试官暗地里已经对你竖起了大拇指。但是他不知道的是此刻你却竖起了中指，在椅子背后。 当然，实际上 Redis 真的真的真的不推荐作为消息队列使用，它最多只是消息队列的存储层，上层的逻辑，还需要做大量的封装和支持。 另外，在 Redis 5.0 增加了 Stream 功能，一个新的强大的支持多播的可持久化的消息队列，提供类似 Kafka 的功能。 什么是 Redis Pipelining ？一次请求/响应服务器能实现处理新的请求即使旧的请求还未被响应。这样就可以将多个命令发送到服务器，而不用等待回复，最后在一个步骤中读取该答复。 这就是管道（pipelining），是一种几十年来广泛使用的技术。例如许多 POP3 协议已经实现支持这个功能，大大加快了从服务器下载新邮件的过程。 Redis 很早就支持管道（pipelining）技术，因此无论你运行的是什么版本，你都可以使用管道（pipelining）操作 Redis。 Redis 如何做大量数据插入？ Redis2.6 开始，Redis-cli 支持一种新的被称之为 pipe mode 的新模式用于执行大量数据插入工作。 具体可见 《Redis 大量数据插入》 文章。 什么是 Redis 事务？和众多其它数据库一样，Redis 作为 NoSQL 数据库也同样提供了事务机制。在Redis中，MULTI / EXEC / DISCARD / WATCH 这四个命令是我们实现事务的基石。相信对有关系型数据库开发经验的开发者而言这一概念并不陌生，即便如此，我们还是会简要的列出 Redis 中事务的实现特征： 1、在事务中的所有命令都将会被串行化的顺序执行，事务执行期间，Redis 不会再为其它客户端的请求提供任何服务，从而保证了事物中的所有命令被原子的执行。 2、和关系型数据库中的事务相比，在 Redis 事务中如果有某一条命令执行失败，其后的命令仍然会被继续执行。 3、我们可以通过 MULTI 命令开启一个事务，有关系型数据库开发经验的人可以将其理解为 &quot;BEGIN TRANSACTION&quot; 语句。在该语句之后执行的命令都，将被视为事务之内的操作，最后我们可以通过执行 EXEC / DISCARD 命令来提交 / 回滚该事务内的所有操作。这两个 Redis 命令，可被视为等同于关系型数据库中的 COMMIT / ROLLBACK 语句。 4、在事务开启之前，如果客户端与服务器之间出现通讯故障并导致网络断开，其后所有待执行的语句都将不会被服务器执行。然而如果网络中断事件是发生在客户端执行 EXEC 命令之后，那么该事务中的所有命令都会被服务器执行。 5、当使用 Append-Only 模式时，Redis 会通过调用系统函数 write 将该事务内的所有写操作在本次调用中全部写入磁盘。然而如果在写入的过程中出现系统崩溃，如电源故障导致的宕机，那么此时也许只有部分数据被写入到磁盘，而另外一部分数据却已经丢失。 Redis 服务器会在重新启动时执行一系列必要的一致性检测，一旦发现类似问题，就会立即退出并给出相应的错误提示。此时，我们就要充分利用 Redis 工具包中提供的 redis-check-aof 工具，该工具可以帮助我们定位到数据不一致的错误，并将已经写入的部分数据进行回滚。修复之后我们就可以再次重新启动Redis服务器了。 如何实现 Redis CAS 操作？ 在 Redis 的事务中，WATCH 命令可用于提供CAS(check-and-set)功能。 假设我们通过 WATCH 命令在事务执行之前监控了多个 keys ，倘若在 WATCH 之后有任何 Key 的值发生了变化，EXEC 命令执行的事务都将被放弃，同时返回 nil 应答以通知调用者事务执行失败。 具体的示例，可以看看 《Redis 事务锁 CAS 实现以及深入误区》 。 Redis 集群都有哪些方案？Redis 集群方案如下： 1、Redis Sentinel 2、Redis Cluster 3、Twemproxy 4、Codis 5、客户端分片 关于前四种，可以看看 《Redis 实战（四）集群机制》 这篇文章。 关于最后一种，客户端分片，在 Redis Cluster 出现之前使用较多，目前已经使用比较少了。实现方式如下： 在业务代码层实现，起几个毫无关联的 Redis 实例，在代码层，对 Key 进行 hash 计算，然后去对应的 Redis 实例操作数据。 这种方式对 hash 层代码要求比较高，考虑部分包括，节点失效后的替代算法方案，数据震荡后的自动脚本恢复，实例的监控，等等。 选择 目前一般在选型上来说： 体量较小时，选择 Redis Sentinel ，单主 Redis 足以支撑业务。 体量较大时，选择 Redis Cluster ，通过分片，使用更多内存。 Redis 集群如何扩容？ 这个问题，艿艿了解的也不是很多，建议在搜索有什么方案。 如果 Redis 被当做缓存使用，使用一致性哈希实现动态扩容缩容。 如果 Redis 被当做一个持久化存储使用，必须使用固定的 keys-to-nodes 映射关系，节点的数量一旦确定不能变化。否则的话(即Redis 节点需要动态变化的情况），必须使用可以在运行时进行数据再平衡的一套系统，而当前只有 Redis Cluster、Codis 可以做到这样。 什么是 Redis 主从同步？Redis 主从同步 Redis 的主从同步(replication)机制，允许 Slave 从 Master 那里，通过网络传输拷贝到完整的数据备份，从而达到主从机制。 主数据库可以进行读写操作，当发生写操作的时候自动将数据同步到从数据库，而从数据库一般是只读的，并接收主数据库同步过来的数据。 一个主数据库可以有多个从数据库，而一个从数据库只能有一个主数据库。 第一次同步时，主节点做一次 bgsave 操作，并同时将后续修改操作记录到内存 buffer ，待完成后将 RDB 文件全量同步到复制节点，复制节点接受完成后将 RDB 镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。 好处 通过 Redis 的复制功，能可以很好的实现数据库的读写分离，提高服务器的负载能力。主数据库主要进行写操作，而从数据库负责读操作。 Redis 主从同步，是很多 Redis 集群方案的基础，例如 Redis Sentinel、Redis Cluster 等等。 更多详细，可以看看 《Redis 主从架构》 。 如何使用 Redis Sentinel 实现高可用？可以看看 《Redis 哨兵集群实现高可用》 。 如果使用 Redis Cluster 实现高可用？可以看看 《Redis 集群教程》 完整版 《Redis 集群模式的工作原理能说一下么？》 精简版 说说 Redis 哈希槽的概念？ Redis Cluster 没有使用一致性 hash ，而是引入了哈希槽的概念。 Redis 集群有 16384 个哈希槽，每个 key 通过 CRC16 校验后对 16384 取模来决定放置哪个槽，集群的每个节点负责一部分 hash 槽。 因为最大是 16384 个哈希槽，所以考虑 Redis 集群中的每个节点都能分配到一个哈希槽，所以最多支持 16384 个 Redis 节点。 Redis Cluster 的主从复制模型是怎样的？ 为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型，每个节点都会有 N-1 个复制节点。 所以，Redis Cluster 可以说是 Redis Sentinel 带分片的加强版。也可以说： Redis Sentinel 着眼于高可用，在 master 宕机时会自动将 slave 提升为 master ，继续提供服务。 Redis Cluster 着眼于扩展性，在单个 Redis 内存不足时，使用Cluster 进行分片存储。 Redis Cluster 方案什么情况下会导致整个集群不可用？ 有 A，B，C 三个节点的集群，在没有复制模型的情况下，如果节点 B 宕机了，那么整个集群就会以为缺少 5501-11000 这个范围的槽而不可用。 Redis Cluster 会有写操作丢失吗？为什么？ Redis 并不能保证数据的强一致性，而是【异步复制】，这意味这在实际中集群在特定的条件下可能会丢失写操作。 Redis 集群如何选择数据库？ Redis 集群目前无法做数据库选择，默认在 0 数据库。 请说说生产环境中的 Redis 是怎么部署的？ 重点问题，仔细理解。 Redis Cluster，10 台机器，5 台机器部署了 redis 主实例，另外 5 台机器部署了 redis 的从实例，每个主实例挂了一个从实例，5 个节点对外提供读写服务，每个节点的读写高峰 qps 可能可以达到每秒 5 万，5 台机器最多是 25 万读写请求每秒。 机器是什么配置？32G 内存 + 8 核 CPU + 1T 磁盘，但是分配给 Redis 进程的是 10g 内存，一般线上生产环境，Redis 的内存尽量不要超过 10g，超过 10g 可能会有问题。那么，5 台机器对外提供读写，一共有 50g 内存。 因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，Redis 从实例会自动变成主实例继续提供读写服务。 你往内存里写的是什么数据？每条数据的大小是多少？商品数据，每条数据是 10kb 。100 条数据是 1mb ，10 万条数据是 1g 。常驻内存的是 200 万条商品数据，占用内存是 20g，仅仅不到总内存的 50%。目前高峰期每秒就是 3500 左右的请求量。 其实大型的公司，会有基础架构的 team 负责缓存集群的运维。 什么是 Redis 分区？ 这个问题，和 「Redis 集群都有哪些方案？」 是同类问题。 关于如下四个问题，直接看 《Redis 分区》 文章。 Redis 分区是什么？ 分区的优势？ 分区的不足？ 分区类型？ 可能有胖友会懵逼，又是 Redis 主从复制，又是 Redis 分区，又是 Redis 集群。傻傻分不清啊！ Redis 分区是一种模式，将数据分区到不同的 Redis 节点上，而 Redis 集群的 Redis Cluster、Twemproxy、Codis、客户端分片( 不包括 Redis Sentinel ) 这四种方案，是 Redis 分区的具体实现。 Redis 每个分区，如果想要实现高可用，需要使用到 Redis 主从复制。 你知道有哪些 Redis 分区实现方案？ Redis 分区方案，主要分成两种类型： 客户端分区，就是在客户端就已经决定数据会被存储到哪个 Redis 节点或者从哪个 Redis 节点读取。大多数客户端已经实现了客户端分区。 案例：Redis Cluster 和客户端分区。 代理分区，意味着客户端将请求发送给代理，然后代理决定去哪个节点写数据或者读数据。代理根据分区规则决定请求哪些 Redis 实例，然后根据 Redis 的响应结果返回给客户端。 案例：Twemproxy 和 Codis 。 查询路由(Query routing)的意思，是客户端随机地请求任意一个 Redis 实例，然后由 Redis 将请求转发给正确的 Redis 节点。Redis Cluster 实现了一种混合形式的查询路由，但并不是直接将请求从一个Redis 节点转发到另一个 Redis 节点，而是在客户端的帮助下直接 redirect 到正确的 Redis 节点。 分布式 Redis 是前期做还是后期规模上来了再做好？为什么？？ 如下是网络上的一个大答案： 既然 Redis 是如此的轻量（单实例只使用1M内存），为防止以后的扩容，最好的办法就是一开始就启动较多实例。即便你只有一台服务器，你也可以一开始就让 Redis 以分布式的方式运行，使用分区，在同一台服务器上启动多个实例。 一开始就多设置几个 Redis 实例，例如 32 或者 64 个实例，对大多数用户来说这操作起来可能比较麻烦，但是从长久来看做这点牺牲是值得的。 这样的话，当你的数据不断增长，需要更多的 Redis 服务器时，你需要做的就是仅仅将 Redis 实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区的问题）。一旦你添加了另一台服务器，你需要将你一半的 Redis 实例从第一台机器迁移到第二台机器。 和飞哥沟通了下，这个操作不是很合理。 无论怎么说，建议，需要搭建下 Redis Sentinel 高可用，至于拓展性，根据自己的情况，是否使用 Redis Cluster 集群 Redis 有哪些重要的健康指标？推荐阅读 《Redis 几个重要的健康指标》 存活情况 连接数 阻塞客户端数量 使用内存峰值 内存碎片率 缓存命中率 OPS 持久化 失效KEY 慢日志 如何提高 Redis 命中率？ 推荐阅读 《如何提高缓存命中率（Redis）》 。 怎么优化 Redis 的内存占用推荐阅读 《Redis 的内存优化》 redisObject 对象 缩减键值对象 共享对象池 字符串优化 编码优化 控制 key 的数量 一个 Redis 实例最多能存放多少的 keys？List、Set、Sorted Set 他们最多能存放多少元素？ 一个 Redis 实例，最多能存放多少的 keys ，List、Set、Sorted Set 他们最多能存放多少元素。 理论上，Redis 可以处理多达 2^32 的 keys ，并且在实际中进行了测试，每个实例至少存放了 2 亿 5 千万的 keys。 任何 list、set、和 sorted set 都可以放 2^32 个元素。 假如 Redis 里面有 1 亿个 key，其中有 10w 个 key 是以某个固定的已知的前缀开头的，如果将它们全部找出来？ 使用 keys 指令可以扫出指定模式的 key 列表。 对方接着追问：如果这个 Redis 正在给线上的业务提供服务，那使用keys指令会有什么问题？ 这个时候你要回答 Redis 关键的一个特性：Redis 的单线程的。keys 指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用 scan 指令，scan 指令可以无阻塞的提取出指定模式的 key 列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用 keys 指令长。 Redis 常见的性能问题都有哪些？如何解决？1、Master 最好不要做任何持久化工作，如 RDB 内存快照和 AOF 日志文件。 Master 写内存快照，save 命令调度 rdbSave 函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以 Master 最好不要写内存快照。 Master AOF 持久化，如果不重写 AOF 文件，这个持久化方式对性能的影响是最小的，但是 AOF 文件会不断增大，AOF 文件过大会影响 Master 重启的恢复速度。 所以，Master 最好不要做任何持久化工作，包括内存快照和 AOF 日志文件，特别是不要启用内存快照做持久化。如果数据比较关键，某个 Slave 开启AOF备份数据，策略为每秒同步一次 2、Master 调用 BGREWRITEAOF 重写 AOF 文件，AOF 在重写的时候会占大量的 CPU 和内存资源，导致服务 load 过高，出现短暂服务暂停现象。 3、尽量避免在压力很大的主库上增加从库。 4、主从复制不要用图状结构，用单向链表结构更为稳定，即：Master &lt;- Slave1 &lt;- Slave2 &lt;- Slave3... 。 这样的结构，也方便解决单点故障问题，实现 Slave 对 Master 的替换。如果 Master挂了，可以立刻启用 Slave1 做 Master ，其他不变。 5、Redis 主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave 和 Master 最好在同一个局域网内。 和飞哥沟通过后，他们主节点开启 AOF ，从节点开启 AOF + RDB 。 和晓峰沟通后，他们主节点开启 AOF ，从节点开启 RDB 居多，也有开启 AOF + RDB 的。 修改配置不重启 Redis 会实时生效吗？针对运行实例，有许多配置选项可以通过 CONFIG SET 命令进行修改，而无需执行任何形式的重启。 从 Redis 2.2 开始，可以从 AOF 切换到 RDB 的快照持久性或其他方式而不需要重启 Redis。检索 CONFIG GET * 命令获取更多信息。 但偶尔重新启动是必须的，如为升级 Redis 程序到新的版本，或者当你需要修改某些目前 CONFIG 命令还不支持的配置参数的时候。 其他问题有些比较凶残的面试官，可能会问我们一些 Redis 数据结构的问题，例如： Skiplist 插入和查询原理？ 压缩列表的原理？ Redis 底层为什么使用跳跃表而不是红黑树？ 跳跃表在范围查找的时候性能比较高。 参考链接 精尽 Redis 面试题]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java后端核心知识]]></title>
    <url>%2F2019%2F02%2F23%2FJava%E5%90%8E%E7%AB%AF%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[算法剑指 Offer 题解Leetcode 题解算法操作系统计算机操作系统Linux网络计算机网络HTTP Brief History of HTTP Socket面向对象设计模式面向对象思想数据库数据库系统原理SQLLeetcode-Database 题解MySQL MySQL数据类型及后面小括号的意义 RedisJavaJava 基础 聊聊引用和Threadlocal的那些事 Java 容器Java 并发 Java并发编程：volatile关键字解析 大白话聊聊Java并发面试问题之volatile到底是什么？ 大白话聊聊Java并发面试问题之Java 8如何优化CAS性能？ 大白话聊聊Java并发面试问题之谈谈你对AQS的理解？ 大白话聊聊Java并发面试问题之公平锁与非公平锁是啥？ 大白话聊聊Java并发面试问题之微服务注册中心的读写锁优化 Java 虚拟机 JVM中的新生代和老年代（Eden空间、两个Survior空间） Java对象结构与锁实现原理及MarkWord详解 Java I/O NIO 入门 框架Spring Spring事务传播行为详解 中间件Netty It’s all about buffers: zero-copy, mmap and Java NIO Efficient data transfer through zero copy Scalable IO in Java Netty 那些事儿 ——— Reactor模式详解 系统设计系统设计基础分布式集群攻击技术缓存消息队列工具GitDocker构建工具正则表达式]]></content>
      <categories>
        <category>知识图谱</category>
      </categories>
      <tags>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库]]></title>
    <url>%2F2019%2F02%2F22%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[数据库架构数据库架构可以分为存储文件系统和程序实例两大块，而程序实例根据不同的功能又可以分为如下小模块。 索引模块常见的问题有： 为什么要使用索引 什么样的信息能成为索引 索引的数据结构 密集索引和稀疏索引的区别 为什么要使用索引使用索引就像查字典一样，可以快速查询数据 什么样的信息能成为索引主键、唯一键以及普通键等 索引的数据结构 生成索引，建立二叉查找树进行二分查找 生成索引，建立 B Tree 结构结构进行查找 生成索引，建立 B+ Tree 结构进行查找 生成索引，建立 Hash 结构进行查找 什么是 B Tree 索引？B-Tree 是为磁盘等外存储设备设计的一种平衡查找树。因此在讲 B-Tree 之前先了解下磁盘的相关知识。 系统从磁盘读取数据到内存时是以磁盘块（block）为基本单位的，位于同一个磁盘块中的数据会被一次性读取出来，而不是需要什么取什么。 InnoDB存储引擎中有页（Page）的概念，页是其磁盘管理的最小单位。InnoDB 存储引擎中默认每个页的大小为 16 KB，可通过参数 innodb_page_size 将页的大小设置为 4K、8K、16K ，在 MySQL 中可通过如下命令查看页的大小： 1mysql&gt; show variables like 'innodb_page_size'; 而系统一个磁盘块的存储空间往往没有这么大，因此 InnoDB 每次申请磁盘空间时都会是若干地址连续磁盘块来达到页的大小 16KB 。InnoDB 在把磁盘数据读入到磁盘时会以页为基本单位，在查询数据时如果一个页中的每条数据都能有助于定位数据记录的位置，这将会减少磁盘 I/O 次数，提高查询效率。 B-Tree 结构的数据可以让系统高效的找到数据所在的磁盘块。为了描述B-Tree，首先定义一条记录为一个二元组 [key, data] ，key 为记录的键值，对应表中的主键值，data 为一行记录中除主键外的数据。对于不同的记录，key值互不相同。 一棵 m 阶的 B-Tree 有如下特性： 每个节点最多有 m 个孩子 除了根节点和叶子节点外，其它每个节点至少有 Ceil(m/2) 个孩子 若根节点不是叶子节点，则至少有 2 个孩子 所有叶子节点都在同一层，且不包含其它关键字信息 每个非叶子节点包含 n 个关键字信息（P0,P1,…Pn, k1,…kn） 关键字的个数 n 满足：ceil(m/2)-1 &lt;= n &lt;= m-1 ki(i=1,…n) 为关键字，且关键字升序排序 Pi(i=0,…n) 为指向子树根节点的指针。P(i-1) 指向的子树的所有节点关键字均小于 ki ，但都大于 k(i-1) B-Tree 中的每个节点根据实际情况可以包含大量的关键字信息和分支，如下图所示为一个 3 阶的 B-Tree： 每个节点占用一个盘块的磁盘空间，一个节点上有两个升序排序的 key 和三个指向子树根节点的 point ，point 存储的是子节点所在磁盘块的地址。两个 key 划分成的三个范围域，对应三个 point 指向的子树的数据的范围域。 以根节点为例，key 为 17 和 35 ，P1 指针指向的子树的数据范围为小于 17 ，P2 指针指向的子树的数据范围为 [17~35] ，P3 指针指向的子树的数据范围为大于 35 。 模拟查找 key 为 29 的过程： 1、根据根节点找到磁盘块 1 ，读入内存。【磁盘I/O操作第1次】 2、比较 key 29 在区间（17,35），找到磁盘块 1 的指针 P2 。 3、根据 P2 指针找到磁盘块 3 ，读入内存。【磁盘I/O操作第2次】 4、比较 key 29 在区间（26,30），找到磁盘块3的指针P2。 5、根据 P2 指针找到磁盘块 8 ，读入内存。【磁盘I/O操作第3次】 6、在磁盘块 8 中的 key 列表中找到 eky 29 。 分析上面过程，发现需要 3 次磁盘 I/O 操作，和 3 次内存查找操作。由于内存中的 key 是一个有序表结构，可以利用二分法查找提高效率。而 3 次磁盘 I/O 操作是影响整个 B-Tree 查找效率的决定因素。B-Tree 相对于 AVLTree 缩减了节点个数，使每次磁盘 I/O 取到内存的数据都发挥了作用，从而提高了查询效率。 什么是 B+Tree 索引？B+Tree 是在 B-Tree 基础上的一种优化，使其更适合实现外存储索引结构，InnoDB存储引擎就是用 B+Tree 实现其索引结构。 从上一节中的 B-Tree 结构图中可以看到，每个节点中不仅包含数据的 key 值，还有 data 值。而每一个页的存储空间是有限的，如果 data 数据较大时将会导致每个节点（即一个页）能存储的 key 的数量很小，当存储的数据量很大时同样会导致 B-Tree 的深度较大，增大查询时的磁盘 I/O 次数，进而影响查询效率。在 B+Tree 中，所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储 key 值信息，这样可以大大加大每个节点存储的 key 值数量，降低 B+Tree 的高度。 B+Tree 相对于 B-Tree 有几点不同： 非叶子节点只存储键值信息。 所有叶子节点之间都有一个链指针。 数据记录都存放在叶子节点中。 B+ Tree 更适合用来做存储索引： B+ 数的磁盘读写代价更低 B+ 数的查询效率更加稳定 B+ 数更有利于对数据库的扫描（范围查询） 将上一节中的 B-Tree 优化，由于 B+Tree 的非叶子节点只存储键值信息，假设每个磁盘块能存储 4 个键值及指针信息，则变成 B+Tree 后其结构如下图所示： 磁盘块4中的10数据，画错了，范围在[K[i], K[i+1])，左闭右开 通常在 B+Tree 上有两个头指针，一个指向根节点，另一个指向关键字最小的叶子节点，而且所有叶子节点（即数据节点）之间是一种链式环结构。因此可以对 B+Tree 进行两种查找运算：一种是对于主键的范围查找和分页查找，另一种是从根节点开始，进行随机查找。 可能上面例子中只有 22 条数据记录，看不出 B+Tree 的优点，下面做一个推算： InnoDB 存储引擎中页的大小为 16KB，一般表的主键类型为 INT（占用4个字节） 或 BIGINT（占用8个字节），指针类型也一般为 4 或 8 个字节，也就是说一个页（B+Tree 中的一个节点）中大概存储 16KB/(8B+8B)=1K 个键值（因为是估值，为方便计算，这里的 K 取值为〖10〗^3）。也就是说一个深度为 3 的 B+Tree 索引可以维护10^3 10^3 10^3 = 10亿 条记录。 实际情况中每个节点可能不能填充满，因此在数据库中，B+Tree 的高度一般都在 2~4 层。MySQL 的 InnoDB 存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要 1~3 次磁盘 I/O 操作。 什么是 hash 索引？基于哈希表实现，优点是查找非常快。如下图 ： 哈希索引就是采用一定的哈希算法，将键值换算成新的哈希值，检索时不需要想B+Tree那样从根结点开始查找，而是经过计算直接定位，所以速度很快。 但是也有限制： 只支持精确查找，不能用于部分查找和范围查找。无法排序和分组。因为原来有序的键值经过哈希算法很可能打乱。 如果哈希冲突很多，查找速度很慢。比如在有大量重复键值的情况下。 不能利用部分索引查询 不能 聚集索引与非聚集索引 MyISAM 索引与 InnoDB 索引的区别？ InnoDB 索引是聚簇索引，MyISAM 索引是非聚簇索引。 InnoDB 的主键索引的叶子节点存储着行数据，因此主键索引非常高效。 MyISAM 索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。 InnoDB 非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效 如何定位并优化慢查询的 Sql需要具体场景具体分析，其大致思路 根据慢日志定位到慢查询的 sql 使用 explain 等工具分析 sql 修改 sql 或者尽量让 sql 走索引 定位慢查询sql开启慢查询日志即可 文件方式配置 MySQL 慢查询的方法： 查询 MySQL 慢查询状态的方法： 1SHOW VARIABLES LIKE '%query%'; 在 mysql 配置文件 my.cnf 中增加： 123log-slow-queries=/opt/data/slowquery.loglong_query_time=2 log-queries-not-using-indexes 命令方式配置 MySQL 慢查询的方法： 123set global slow_query_log=on; set global long_query_time=1; set global slow_query_log_file=‘/opt/data/slow_query.log’; 解析 MySQL 慢查询日志的方法，按照 sql 执行时间最长的前 20 条 sql： 1mysqldumpslow -s t -t 20 -g &apos;select&apos; /opt/data/slowquery.log 在 log 中就能找到慢查询的 sql。 Explian 关键字 Explain命令在解决数据库性能上是第一推荐使用命令，大部分的性能问题可以通过此命令来简单的解决，Explain可以用来查看SQL语句的执行效 果，可以帮助选择更好的索引和优化查询语句，写出更好的优化语句。 Explain语法：explain select … from … [where …] 例如：explain select * from news; 输出： 123+----+-------------+-------+-------+-------------------+---------+---------+-------+------| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-------+-------+-------------------+---------+---------+-------+------ 下面对各个属性进行了解： 1、id：这是SELECT的查询序列号 2、select_type：select_type就是select的类型，可以有以下几种： SIMPLE：简单SELECT(不使用UNION或子查询等) PRIMARY：最外面的SELECT UNION：UNION中的第二个或后面的SELECT语句 DEPENDENT UNION：UNION中的第二个或后面的SELECT语句，取决于外面的查询 UNION RESULT：UNION的结果。 SUBQUERY：子查询中的第一个SELECT DEPENDENT SUBQUERY：子查询中的第一个SELECT，取决于外面的查询 DERIVED：导出表的SELECT(FROM子句的子查询) 3、table：显示这一行的数据是关于哪张表的 4、type：这列最重要，显示了连接使用了哪种类别,有无使用索引，是使用Explain命令分析性能瓶颈的关键项之一。 结果值从好到坏依次是： system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL 一般来说，得保证查询至少达到range级别，最好能达到ref，否则就可能会出现性能问题。 5、possible_keys：列指出MySQL能使用哪个索引在该表中找到行 6、key：显示MySQL实际决定使用的键（索引）。如果没有选择索引，键是NULL 7、key_len：显示MySQL决定使用的键长度。如果键是NULL，则长度为NULL。使用的索引的长度。在不损失精确性的情况下，长度越短越好 8、ref：显示使用哪个列或常数与key一起从表中选择行。 9、rows：显示MySQL认为它执行查询时必须检查的行数。 10、Extra：包含MySQL解决查询的详细信息，也是关键参考项之一。 Distinct一旦MYSQL找到了与行相联合匹配的行，就不再搜索了 Not existsMYSQL 优化了LEFT JOIN，一旦它找到了匹配LEFT JOIN标准的行， 就不再搜索了 Range checked for each Record（index map:#）没有找到理想的索引，因此对于从前面表中来的每一 个行组合，MYSQL检查使用哪个索引，并用它来从表中返回行。这是使用索引的最慢的连接之一 Using filesort看 到这个的时候，查询就需要优化了。MYSQL需要进行额外的步骤来发现如何对返回的行排序。它根据连接类型以及存储排序键值和匹配条件的全部行的行指针来 排序全部行 Using index列数据是从仅仅使用了索引中的信息而没有读取实际的行动的表返回的，这发生在对表 的全部的请求列都是同一个索引的部分的时候 Using temporary看到这个的时候，查询需要优化了。这 里，MYSQL需要创建一个临时表来存储结果，这通常发生在对不同的列集进行ORDER BY上，而不是GROUP BY上 Using where使用了WHERE从句来限制哪些行将与下一张表匹配或者是返回给用户。如果不想返回表中的全部行，并且连接类型ALL或index， 这就会发生，或者是查询有问题 其他一些Tip： 当type 显示为 “index” 时，并且Extra显示为 “Using Index”， 表明使用了覆盖索引。 联合索引的最左匹配原则的成因看看如下博客即可 联合索引的最左前缀匹配原则 mysql索引最左匹配原则的理解? 索引是建立得越多越好的吗 数据量小的表不需要建立索引，建立会增加额外的索引开销 数据变更需要维护索引，因此更多的索引意味着更多的维护成本 更多的索引意味着也需要更多的空间 锁模块常见问题 MyISAM 与 InnoDB 关于锁方面的区别是什么 数据库事务的四大特性 事务隔离级别以及各级别下的并发访问问题 InnoDB 可重复读隔离级别下如何避免幻读 RC、RR 级别下的 InnoDB 的非堵塞如果实现 MyISAM 与 InnoDB 关于锁方面的区别是什么 MyISAM 默认用的是表级锁，不支持行级锁 InnoDB 默认用的是行级锁，也支持表级锁 数据库锁的分类 按锁的粒度划分，可分为表级锁、行级锁和页级锁 按锁的级别划分，可分为共享锁和排他锁 按加锁的方式划分，可分为自动锁和显示锁 按操作划分，可分为 DML 锁和 DDL 锁 按使用方式划分，可分为乐观锁和悲观锁 ACID1. 原子性（Atomicity）事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。 回滚可以用回滚日志来实现，回滚日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。 2. 一致性（Consistency）数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的。 3. 隔离性（Isolation）一个事务所做的修改在最终提交以前，对其它事务是不可见的。 4. 持久性（Durability）一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。 使用重做日志来保证持久性。 并发一致性问题在并发环境下，事务的隔离性很难保证，因此会出现很多并发一致性问题。 丢失修改T1 和 T2 两个事务都对一个数据进行修改，T1 先修改，T2 随后修改，T2 的修改覆盖了 T1 的修改。 读脏数据T1 修改一个数据，T2 随后读取这个数据。如果 T1 撤销了这次修改，那么 T2 读取的数据是脏数据。 不可重复读T2 读取一个数据，T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。 幻影读T1 读取某个范围的数据，T2 在这个范围内插入新的数据，T1 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。 隔离级别未提交读（READ UNCOMMITTED）事务中的修改，即使没有提交，对其它事务也是可见的。 提交读（READ COMMITTED）一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。 可重复读（REPEATABLE READ）保证在同一个事务中多次读取同样数据的结果是一样的。 可串行化（SERIALIZABLE）强制事务串行执行。 隔离级别 脏读 不可重复读 幻影读 加锁读 未提交读 √ √ √ × 提交读 × √ √ × 可重复读 × × √ × 可串行化 × × × √ 参考链接 数据库系统原理]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络]]></title>
    <url>%2F2019%2F02%2F19%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[计算机网络体系结构 OSI其中表示层和会话层用途如下： 表示层 ：数据压缩、加密以及数据描述，这使得应用程序不必关心在各台主机中数据内部格式不同的问题。 会话层 ：建立及管理会话。 五层协议没有表示层和会话层，而是将这些功能留给应用程序开发者处理。 五层协议 应用层 ：为特定应用程序提供数据传输服务，例如 HTTP、DNS 等。数据单位为报文。 传输层 ：为进程提供通用数据传输服务。由于应用层协议很多，定义通用的传输层协议就可以支持不断增多的应用层协议。运输层包括两种协议：传输控制协议 TCP，提供面向连接、可靠的数据传输服务，数据单位为报文段；用户数据报协议 UDP，提供无连接、尽最大努力的数据传输服务，数据单位为用户数据报。TCP 主要提供完整性服务，UDP 主要提供及时性服务。 网络层 ：为主机提供数据传输服务。而传输层协议是为主机中的进程提供数据传输服务。网络层把传输层传递下来的报文段或者用户数据报封装成分组。 数据链路层 ：网络层针对的还是主机之间的数据传输服务，而主机之间可以有很多链路，链路层协议就是为同一链路的主机提供数据传输服务。数据链路层把网络层传下来的分组封装成帧。 物理层 ：考虑的是怎样在传输媒体上传输数据比特流，而不是指具体的传输媒体。物理层的作用是尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异。 TCP/IP它只有四层，相当于五层协议中数据链路层和物理层合并为网络接口层。 TCP/IP 体系结构不严格遵循 OSI 分层概念，应用层可能会直接使用 IP 层或者网络接口层。 TCP/IP 是 Internet上的标准通信协议集，该协议集由数十个具有层次结构的协议组成，其中 TCP 和 IP 是该协议集中的两个最重要的核心协议。TCP/IP协议族按层次可分为以下四层：应用层、传输层、网络层和网络接口层，各层对应的 PDU 数据单元的名称如下图所示。 小结OSI 七层体系结构具有概念清楚、理论完整的特点，是一个理论上的国际标准，但却不是事实上的国际标准；而具有简单易用特点的 TCP/IP 四层体系结构则是事实上的标准。 需要指出的是，五层体系结构虽然综合了 OSI 和 TCP/IP 的优点，但其只是为了学术学习研究而提出的，没有具体的实际意义。 说说 TCP 的三次握手这一到很常见的面试题。 传输控制协议 TCP 简介 面向连接的、可靠的基于字节流的传输层通信协议 将应用层的数据流分割成报文段并发送给目标节点的 TCP 层 数据包都是由序号，对方收到则发送 ACK 确认，未收到则重传 使用校验和来检验数据在传输过程中是否有误 TCP 报文头 源端口、目的端口 ：标记进程。 序号 ：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。 确认号 ：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。 数据偏移 ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。 连接标志（TCP Flags）：表示控制功能，下面是常见的连接标志。 确认 ACK ：当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。 同步 SYN ：在连接建立时用来同步序号。当 SYN=a1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。 终止 FIN ：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。 窗口 ：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。 三次握手 在 TCP/IP 协议中， TCP 协议提供可靠的连接服务，采用三次握手建立一个连接。 假设 A 为客户端，B 为服务器端。 首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。 A 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。 B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。 A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。 B 收到 A 的确认后，连接建立。 对于建链接的3次握手主要是要初始化Sequence Number 的初始值。通信的双方要互相通知对方自己的初始化的 Sequence Number（缩写为ISN：Inital Sequence Number）——所以叫SYN，全称Synchronize Sequence Numbers。也就上图中的 x 和 y。这个号要作为以后的数据通信的序号，以保证应用层接收到的数据不会因为网络上的传输的问题而乱序（TCP会用这个序号来拼接数据）。 关于建连接时SYN超时试想一下，如果server端接到了 client 发的 SYN 后回了 SYN-ACK 后 client 掉线了，server 端没有收到 client 回来的ACK，那么，这个连接处于一个中间状态，即没成功，也没失败。于是，server 端如果在一定时间内没有收到的TCP会重发 SYN-ACK。在Linux下，默认重试次数为5次，重试的间隔时间从 1s 开始每次都翻售，5 次的重试时间间隔为1s, 2s, 4s, 8s, 16s，总共31s，第5次发出后还要等32s都知道第5次也超时了，所以，总共需要 1s + 2s + 4s+ 8s+ 16s + 32s = 2^6 -1 = 63s，TCP才会把断开这个连接。 关于SYN Flood攻击一些恶意的人就为此制造了SYN Flood攻击，给服务器发了一个SYN后，就下线了，于是服务器需要默认等 63s 才会断开连接，这样，攻击者就可以把服务器的 syn 连接的队列耗尽，让正常的连接请求不能处理。于是，Linux下给了一个叫 tcp_syncookies 的参数来应对这个事——当SYN队列满了后，TCP会通过源地址端口、目标地址端口和时间戳打造出一个特别的Sequence Number发回去（又叫cookie），如果是攻击者则不会有响应，如果是正常连接，则会把这个 SYN Cookie发回来，然后服务端可以通过cookie建连接（即使你不在SYN队列中）。 请注意，请先千万别用 tcp_syncookies 来处理正常的大负载的连接的情况。因为，synccookies 是妥协版的TCP协议，并不严谨。对于正常的请求，你应该调整三个TCP参数可供你选择。 第一个是：tcp_synack_retries 可以用他来减少重试次数； 第二个是：tcp_max_syn_backlog，可以增大SYN连接数； 第三个是：tcp_abort_on_overflow 处理不过来干脆就直接拒绝连接了 ； 保活机制 向对方发送保活探测报文，如果未收到响应则继续发送 尝试次数达到保活探测数仍然未收到响应则中断连接 谈谈四次挥手 以下描述不讨论序号和确认号，因为序号和确认号的规则比较简单。并且不讨论 ACK，因为 ACK 在连接建立之后都为 1。 A 发送连接释放报文，FIN=1。 B 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。 当 B 不再需要连接时，发送连接释放报文，FIN=1。 A 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接。 B 收到 A 的确认后释放连接。 四次挥手的原因客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。 TCP连接是全双工的，服务端可以发送数据到客户端，客户端也可以发送数据到服务端，发送方和接收方都需要两次挥手才能关闭 。 TIME_WAIT客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由： 确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。 TCP 和 UDP 的区别前面我们说了 TCP 现在我们来认识一下 UDP。 UPD 的特点 面向非连接的 不维护连接状态，支持同时向多个客户端传输相同的消息 数据包报头只有 8 个字节，额外开销较小 吞吐量只受限于数据生成率、传输速率以及机器性能 尽最大努力交付，不保证可靠交付，不需要维持复杂的链接状态表 面向报文，不对应用程序提交的报文信息进行拆分或则合并 对比 TCP 是面向连接的；UDP 是无连接的。 TCP 是可靠的；UDP 是不可靠的。 TCP 只支持点对点通信；UDP 支持一对一、一对多、多对一、多对多的通信模式。 TCP 是面向字节流的；UDP 是面向报文的。 TCP 有拥塞控制机制；UDP 没有拥塞控制，适合媒体通信。 TCP 首部开销(20 个字节)，比 UDP 的首部开销(8 个字节)要大。 TCP 的滑动窗口首先明确： TCP滑动窗口分为接受窗口，发送窗口。 滑动窗口协议是传输层进行流控的一种措施，接收方通过通告发送方自己的窗口大小，从而控制发送方的发送速度，从而达到防止发送方发送速度过快而导致自己被淹没的目的。 重要概念对ACK的再认识，ack通常被理解为收到数据后给出的一个确认ACK，ACK包含两个非常重要的信息： 一是期望接收到的下一字节的序号n，该n代表接收方已经接收到了前n-1字节数据，此时如果接收方收到第n+1字节数据而不是第n字节数据，接收方是不会发送序号为n+2的ACK的。举个例子，假如接收端收到1-1024字节，它会发送一个确认号为1025的ACK,但是接下来收到的是2049-3072，它是不会发送确认号为3072的ACK,而依旧发送1025的ACK。 二是当前的窗口大小m，如此发送方在接收到ACK包含的这两个数据后就可以计算出还可以发送多少字节的数据给对方，假定当前发送方已发送到第x字节，则可以发送的字节数就是y=m-(x-n).这就是滑动窗口控制流量的基本原理 重点：发送方根据收到ACK当中的期望收到的下一个字节的序号n以及窗口m，还有当前已经发送的字节序号x，算出还可以发送的字节数。 发送端窗口的第一个字节序号一定是ACK中期望收到的下一个字节序号，比如下图： 上图52 53 54 55 字节都是可以新发送的字节序。 接受端窗口的第一个字节序之前一定是已经完全接收的，后面窗口里面的数据都是希望接受的，窗口后面的数据都是不希望接受的。 TCP的滑动窗口分为接收窗口和发送窗口 不分析这两种窗口就讨论是不妥当的。 TCP的滑动窗口主要有两个作用，一是提供TCP的可靠性，二是提供TCP的流控特性。同时滑动窗口机制还体现了TCP面向字节流的设计思路。TCP 段中窗口的相关字段。 TCP的Window是一个16bit位字段，它代表的是窗口的字节容量，也就是TCP的标准窗口最大为2^16-1=65535个字节。 另外在TCP的选项字段中还包含了一个TCP窗口扩大因子，option-kind为3，option-length为3个字节，option-data取值范围0-14。窗口扩大因子用来扩大TCP窗口，可把原来16bit的窗口，扩大为31bit。 滑动窗口基本原理对于TCP会话的发送方，任何时候在其发送缓存内的数据都可以分为4类，“已经发送并得到对端ACK的”，“已经发送但还未收到对端ACK的”，“未发送但对端允许发送的”，“未发送且对端不允许发送”。“已经发送但还未收到对端ACK的”和“未发送但对端允许发送的”这两部分数据称之为发送窗口。 当收到接收方新的ACK对于发送窗口中后续字节的确认是，窗口滑动，滑动原理如下图。 当收到ACK=36时窗口滑动。 2）对于TCP的接收方，在某一时刻在它的接收缓存内存在3种。“已接收”，“未接收准备接收”，“未接收并未准备接收”（由于ACK直接由TCP协议栈回复，默认无应用延迟，不存在“已接收未回复ACK”）。其中“未接收准备接收”称之为接收窗口。 发送窗口与接收窗口关系TCP是双工的协议，会话的双方都可以同时接收、发送数据。TCP会话的双方都各自维护一个“发送窗口”和一个“接收窗口”。其中各自的“接收窗口”大小取决于应用、系统、硬件的限制（TCP传输速率不能大于应用的数据处理速率）。各自的“发送窗口”则要求取决于对端通告的“接收窗口”，要求相同。 滑动窗口实现面向流的可靠性 最基本的传输可靠性来源于“确认重传”机制。 TCP的滑动窗口的可靠性也是建立在“确认重传”基础上的。 发送窗口只有收到对端对于本段发送窗口内字节的ACK确认，才会移动发送窗口的左边界。 接收窗口只有在前面所有的段都确认的情况下才会移动左边界。当在前面还有字节未接收但收到后面字节的情况下，窗口不会移动，并不对后续字节确认。以此确保对端会对这些数据重传。 滑动窗口的流控特性TCP的滑动窗口是动态的，我们可以想象成小学常见的一个数学题，一个水池，体积V，每小时进水量V1，出水量V2。当水池满了就不允许再注入了，如果有个液压系统控制水池大小，那么就可以控制水的注入速率和量。这样的水池就类似TCP的窗口。应用根据自身的处理能力变化，通过本端TCP接收窗口大小控制来对对对端的发送窗口流量限制。 应用程序在需要（如内存不足）时，通过API通知TCP协议栈缩小TCP的接收窗口。然后TCP协议栈在下个段发送时包含新的窗口大小通知给对端，对端按通知的窗口来改变发送窗口，以此达到减缓发送速率的目的。 HTTPHTTP 协议，是 Hyper Text Transfer Protocol（超文本传输协议）的缩写，是用于从万维网（WWW:World Wide Web ）服务器传输超文本到本地浏览器的传送协议。 主要特点如下： 简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有 GET、HEAD、POST 等等。每种方法规定了客户与服务器联系的类型不同。由于 HTTP 协议简单，使得 HTTP 服务器的程序规模小，因而通信速度很快。 数据格式灵活：HTTP 允许传输任意类型的数据对象。正在传输的类型由Content-Type 加以标记。 无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 无状态：HTTP 协议是无状态协议。无状态，是指协议对于事务处理没有记忆能力。无状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 支持 B/S 及 C/S 模式。 GET 和 POST 区别从三个层面来解答： Http 报文层面：GET 将请求信息放在 URL中，POST 方法报文中 数据库层面：GET 符合幂等性和安全性，POST 不符合 其他层面：GET 可以被缓存、被存储（书签），而 POST 不行 Cookie 和 Session 的区别Cookie 简介： 是由服务器发给客户端的特殊信息，以文本的形式存放在客户端 客户端再次请求的时候，会把 Cookie 回发给服务端 服务器接收到后，会解析 Cookie 生成与客户端相对的内容 Cookiet 的设置以及发送过程： Session 简介： 服务端的机制，在服务端保存的信息 解析客户端请求并操作 Session id ，按需保存状态信息 Session 的实现方式： 使用 Cookie 来实现 使用 URL 回写来实现，每次在 URL 添加 Session id 信息 区别： Cookie 数据存放在客户端的浏览器上，Session 数据存放在服务器上 Session 相对于 Cookie 更安全 若考虑减轻服务器负担，应当使用 Cookie HTTP 和 HTTPs 的区别 SSL (Security Sockets Layer) 安全套接层 为网络通信提供安全及数据完整性的一种安全协议 是操作系统对外的 API，SSL 3.0 更名为 TLS 采用身份验证和数据加密来保证网络的通信的安全和数据的完整性 区别 HTTPS 需要到 CA 申请证书，HTTP 不需要 HTTPS 密文传输，HTTP 明文传输 连接方式不同，HTTPS 默认使用 443 端口，HTTP 使用 80 端口 HTTPS = HTTP + 加密 + 认证 + 完整性保护，较 HTTP 安全 其他内容 一 、基础概念 URI 请求和响应报文 二、HTTP 方法 GET HEAD POST PUT PATCH DELETE OPTIONS CONNECT TRACE 三、HTTP 状态码 1XX 信息 2XX 成功 3XX 重定向 4XX 客户端错误 5XX 服务器错误 四、HTTP 首部 通用首部字段 请求首部字段 响应首部字段 实体首部字段 五、具体应用 连接管理 Cookie 缓存 内容协商 内容编码 范围请求 分块传输编码 多部分对象集合 虚拟主机 通信数据转发 六、HTTPs 加密 认证 完整性保护 HTTPs 的缺点 七、HTTP/2.0 HTTP/1.x 缺陷 二进制分帧层 服务端推送 首部压缩 八、HTTP/1.1 新特性 九、GET 和 POST 比较 作用 参数 安全 幂等性 可缓存 XMLHttpRequest 浏览器输入地址回车后发生的事情 DNS解析 TCP连接 发送HTTP请求 服务器处理请求并返回HTTP报文 浏览器解析渲染页面 连接结束 Socket 通信TCP/IP（Transmission Control Protocol/Internet Protocol）即传输控制协议/网间协议，是一个工业标准的协议集，它是为广域网（WANs）设计的。UDP（User Data Protocol，用户数据报协议）是与TCP相对应的协议。它是属于 TCP/IP 协议族中的一种。 这里有一张图，表明了这些协议的关系。 TCP/IP协议族包括运输层、网络层、链路层。现在你知道TCP/IP与UDP的关系了吧。 Socket在哪里呢？ 上图我们没有看到 Socket 的影子，那么它到底在哪里呢？还是用图来说话，一目了然。 Socket 是什么呢？ Socket 是应用层与 TCP/IP 协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket 其实就是一个门面模式，它把复杂的 TCP/IP 协议族隐藏在 Socket 接口后面，对用户来说，一组简单的接口就是全部，让Socket去组织数据，以符合指定的协议。 Socket 通信原理 先从服务器端说起。服务器端先初始化Socket，然后与端口绑定(bind)，对端口进行监听(listen)，调用accept阻塞，等待客户端连接。在这时如果有个客户端初始化一个Socket，然后连接服务器(connect)，如果连接成功，这时客户端与服务器端的连接就建立了。客户端发送数据请求，服务器端接收请求并处理请求，然后把回应数据发送给客户端，客户端读取数据，最后关闭连接，一次交互结束。 TCP 实现服务端 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * @Author: cuzz * @Date: 2019/2/19 22:36 * @Description: */public class TCPServer &#123; public static void main(String[] args) throws IOException &#123; // 创建socket，并将socket绑定到65000端口 ServerSocket serverSocket = new ServerSocket(65000); // 死循环，使socket一直等待并处理客户端发过来的请求 while (true) &#123; // 监听6500端口，直到客户端返回连接信息后才返回 Socket socket = serverSocket.accept(); // 获取客户端请求信息后，执行相关逻辑 new LengthCalculator(socket).start(); &#125; &#125;&#125;class LengthCalculator extends Thread &#123; private Socket socket; public LengthCalculator(Socket socket) &#123; this.socket = socket; &#125; @Override public void run() &#123; try &#123; // 获取socket的输出流 OutputStream os = socket.getOutputStream(); // 获取socket的输入流 InputStream is = socket.getInputStream(); byte[] bytes = new byte[1024]; int len = 0; StringBuilder sb = new StringBuilder(); while ((len = is.read(bytes)) != -1) &#123; os.write(bytes, 0 , len); System.out.println(new String(bytes, 0 , len)); &#125; // 不要忘记关闭输入输出流 os.close(); is.close(); socket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 客服端 12345678910111213141516171819public class TCPClinet &#123; public static void main(String[] args) throws IOException &#123; // 创建socket，并指定连接的是ip和端口号 Socket socket = new Socket("127.0.0.1", 65000); // 获取输出流 OutputStream os = socket.getOutputStream(); // 获取输入流 InputStream is = socket.getInputStream(); os.write("hello world".getBytes()); int len = 0; byte[] bytes = new byte[1024]; len = is.read(bytes); String content = new String(bytes, 0, len); System.out.println(content); is.close(); os.close(); socket.close(); &#125;&#125; UDP 实现服务端 12345678910111213141516171819202122public class UDPServer &#123; public static void main(String[] args) throws Exception &#123; // 服务端接受客户端发送的数据报 DatagramSocket socket = new DatagramSocket(65001); //监听的端口号 byte[] buff = new byte[100]; //存储从客户端接受到的内容 DatagramPacket packet = new DatagramPacket(buff, buff.length); //接受客户端发送过来的内容，并将内容封装进DatagramPacket对象中 socket.receive(packet); byte[] data = packet.getData(); //从DatagramPacket对象中获取到真正存储的数据 //将数据从二进制转换成字符串形式 String content = new String(data, 0, packet.getLength()); System.out.println(content); //将要发送给客户端的数据转换成二进制 byte[] sendedContent = String.valueOf(content.length()).getBytes(); // 服务端给客户端发送数据报 //从DatagramPacket对象中获取到数据的来源地址与端口号 DatagramPacket packetToClient = new DatagramPacket(sendedContent, sendedContent.length, packet.getAddress(), packet.getPort()); socket.send(packetToClient); //发送数据给客户端 &#125;&#125; 客服端 1234567891011121314151617181920212223242526public class UDPClient &#123; public static void main(String[] args) throws Exception &#123; // 客户端发数据报给服务端 DatagramSocket socket = new DatagramSocket(); // 要发送给服务端的数据 byte[] buf = "Hello World".getBytes(); // 将IP地址封装成InetAddress对象 InetAddress address = InetAddress.getByName("127.0.0.1"); // 将要发送给服务端的数据封装成DatagramPacket对象 需要填写上ip地址与端口号 DatagramPacket packet = new DatagramPacket(buf, buf.length, address, 65001); // 发送数据给服务端 socket.send(packet); // 客户端接受服务端发送过来的数据报 byte[] data = new byte[100]; // 创建DatagramPacket对象用来存储服务端发送过来的数据 DatagramPacket receivedPacket = new DatagramPacket(data, data.length); // 将接受到的数据存储到DatagramPacket对象中 socket.receive(receivedPacket); // 将服务器端发送过来的数据取出来并打印到控制台 String content = new String(receivedPacket.getData(), 0, receivedPacket.getLength()); System.out.println(content); &#125;&#125; 参考链接 计算机网络 计算机网络体系结构综述（下） TCP 的那些事儿 TCP协议的滑动窗口具体是怎样控制流量的？ Socket通信原理]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 中是如何实现线程通信？]]></title>
    <url>%2F2019%2F02%2F14%2FJava%20%E4%B8%AD%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E7%BA%BF%E7%A8%8B%E9%80%9A%E4%BF%A1%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[正常情况下，每个子线程完成各自的任务就可以结束了。不过有的时候，我们希望多个线程协同工作来完成某个任务，这时就涉及到了线程间通信了。 本文涉及到的知识点：thread.join(), object.wait(), object.notify(), CountdownLatch, CyclicBarrier, FutureTask, Callable 等。 原文链接：Java 中是如何实现线程通信？ 本文涉及代码：https://github.com/wingjay/HelloJava/blob/master/multi-thread/src/ForArticle.java 下面我从几个例子作为切入点来讲解下 Java 里有哪些方法来实现线程间通信。 如何让两个线程依次执行？ 那如何让两个线程按照指定方式有序交叉运行呢？ 四个线程 A B C D，其中 D 要等到 A B C 全执行完毕后才执行，而且 A B C 是同步运行的 三个运动员各自准备，等到三个人都准备好后，再一起跑 子线程完成某件任务后，把得到的结果回传给主线程 如何让两个线程依次执行？假设有两个线程，一个是线程 A，另一个是线程 B，两个线程分别依次打印 1-3 三个数字即可。我们来看下代码： 123456789101112131415161718private static void demo1() &#123; Thread A = new Thread(new Runnable() &#123; @Override public void run() &#123; printNumber("A"); &#125; &#125;); Thread B = new Thread(new Runnable() &#123; @Override public void run() &#123; printNumber("B"); &#125; &#125;); A.start(); B.start();&#125; 其中的 printNumber(String) 实现如下，用来依次打印 1, 2, 3 三个数字： 1234567891011private static void printNumber(String threadName) &#123; int i=0; while (i++ &lt; 3) &#123; try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(threadName + " print: " + i); &#125;&#125; 这时我们得到的结果是： B print: 1A print: 1B print: 2A print: 2B print: 3A print: 3 可以看到 A 和 B 是同时打印的。 那么，如果我们希望 B 在 A 全部打印完后再开始打印呢？我们可以利用 thread.join() 方法，代码如下: 12345678910111213141516171819202122232425private static void demo2() &#123; Thread A = new Thread(new Runnable() &#123; @Override public void run() &#123; printNumber("A"); &#125; &#125;); Thread B = new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("B 开始等待 A"); try &#123; A.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; printNumber("B"); &#125; &#125;); B.start(); A.start();&#125; 得到的结果如下： B 开始等待 AA print: 1A print: 2A print: 3 B print: 1B print: 2B print: 3 A.join 把指定的线程加入到当前线程，可以将两个交替执行的线程合并为顺序执行的线程。比如在线程B中调用了线程A的 join() 方法，直到线程A执行完毕后，才会继续执行线程B。 t.join(); 调用 join 方法，等待线程 t 执行完毕 t.join(1000); 等待 t 线程，等待时间是1000毫秒。 所以我们能看到 A.join() 方法会让 B 一直等待直到 A 运行完毕。 那如何让两个线程按照指定方式有序交叉运行呢？还是上面那个例子，我现在希望 A 在打印完 1 后，再让 B 打印 1, 2, 3，最后再回到 A 继续打印 2, 3。这种需求下，显然 Thread.join() 已经不能满足了。我们需要更细粒度的锁来控制执行顺序。 这里，我们可以利用 object.wait() 和 object.notify() 两个方法来实现。代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940/** * A 1, B 1, B 2, B 3, A 2, A 3 */private static void demo3() &#123; Object lock = new Object(); Thread A = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lock) &#123; System.out.println("A 1"); try &#123; lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("A 2"); System.out.println("A 3"); &#125; &#125; &#125;); Thread B = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lock) &#123; System.out.println("B 1"); System.out.println("B 2"); System.out.println("B 3"); lock.notify(); &#125; &#125; &#125;); A.start(); B.start();&#125; 打印结果如下： A 1A waiting… B 1B 2B 3A 2A 3 正是我们要的结果。 那么，这个过程发生了什么呢？ 首先创建一个 A 和 B 共享的对象锁 lock = new Object(); 当 A 得到锁后，先打印 1，然后调用 lock.wait() 方法，交出锁的控制权，进入 wait 状态； 对 B 而言，由于 A 最开始得到了锁，导致 B 无法执行；直到 A 调用 lock.wait() 释放控制权后， B 才得到了锁； B 在得到锁后打印 1， 2， 3；然后调用 lock.notify() 方法，唤醒正在 wait 的 A; A 被唤醒后，继续打印剩下的 2，3。 为了更好理解，我在上面的代码里加上 log 方便读者查看。 12345678910111213141516171819202122232425262728293031323334353637383940private static void demo3() &#123; Object lock = new Object(); Thread A = new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("INFO: A 等待锁 "); synchronized (lock) &#123; System.out.println("INFO: A 得到了锁 lock"); System.out.println("A 1"); try &#123; System.out.println("INFO: A 准备进入等待状态，放弃锁 lock 的控制权 "); lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("INFO: 有人唤醒了 A, A 重新获得锁 lock"); System.out.println("A 2"); System.out.println("A 3"); &#125; &#125; &#125;); Thread B = new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("INFO: B 等待锁 "); synchronized (lock) &#123; System.out.println("INFO: B 得到了锁 lock"); System.out.println("B 1"); System.out.println("B 2"); System.out.println("B 3"); System.out.println("INFO: B 打印完毕，调用 notify 方法 "); lock.notify(); &#125; &#125; &#125;); A.start(); B.start();&#125; 打印结果如下: INFO: A 等待锁INFO: A 得到了锁 lockA 1INFO: A 准备进入等待状态，调用 lock.wait() 放弃锁 lock 的控制权INFO: B 等待锁INFO: B 得到了锁 lockB 1B 2B 3INFO: B 打印完毕，调用 lock.notify() 方法INFO: 有人唤醒了 A, A 重新获得锁 lockA 2A 3 四个线程 A B C D，其中 D 要等到 A B C 全执行完毕后才执行，而且 A B C 是同步运行的最开始我们介绍了 thread.join()，可以让一个线程等另一个线程运行完毕后再继续执行，那我们可以在 D 线程里依次 join A B C，不过这也就使得 A B C 必须依次执行，而我们要的是这三者能同步运行。 或者说，我们希望达到的目的是：A B C 三个线程同时运行，各自独立运行完后通知 D；对 D 而言，只要 A B C 都运行完了，D 再开始运行。针对这种情况，我们可以利用 CountdownLatch 来实现这类通信方式。它的基本用法是： 创建一个计数器，设置初始值，CountdownLatch countDownLatch = new CountDownLatch(2); 在 等待线程里调用 countDownLatch.await() 方法，进入等待状态，直到计数值变成 0； 在 其他线程里，调用 countDownLatch.countDown() 方法，该方法会将计数值减小 1； 当 其他线程的 countDown() 方法把计数值变成 0 时，等待线程 里的 countDownLatch.await() 立即退出，继续执行下面的代码。 实现代码如下： 123456789101112131415161718192021222324252627282930313233343536private static void runDAfterABC() &#123; int worker = 3; CountDownLatch countDownLatch = new CountDownLatch(worker); new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("D is waiting for other three threads"); try &#123; countDownLatch.await(); System.out.println("All done, D starts working"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); for (char threadName='A'; threadName &lt;= 'C'; threadName++) &#123; final String tN = String.valueOf(threadName); new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(tN + " is working"); try &#123; Thread.sleep(100); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; System.out.println(tN + " finished"); countDownLatch.countDown(); &#125; &#125;).start(); &#125;&#125; 下面是运行结果： D is waiting for other three threadsA is workingB is workingC is working A finishedC finishedB finishedAll done, D starts working 其实简单点来说，CountDownLatch 就是一个倒计数器，我们把初始计数值设置为3，当 D 运行时，先调用 countDownLatch.await() 检查计数器值是否为 0，若不为 0 则保持等待状态；当A B C 各自运行完后都会利用countDownLatch.countDown()，将倒计数器减 1，当三个都运行完后，计数器被减至 0；此时立即触发 D的 await() 运行结束，继续向下执行。 因此，CountDownLatch 适用于一个线程去等待多个线程的情况。 三个运动员各自准备，等到三个人都准备好后，再一起跑上面是一个形象的比喻，针对 线程 A B C 各自开始准备，直到三者都准备完毕，然后再同时运行。也就是要实现一种线程之间互相等待的效果，那应该怎么来实现呢？ 上面的 CountDownLatch 可以用来倒计数，但当计数完毕，只有一个线程的 await() 会得到响应，无法让多个线程同时触发。 为了实现线程间互相等待这种需求，我们可以利用 CyclicBarrier 数据结构，它的基本用法是： 先创建一个公共 CyclicBarrier 对象，设置 同时等待的线程数，CyclicBarrier cyclicBarrier = new CyclicBarrier(3); 这些线程同时开始自己做准备，自身准备完毕后，需要等待别人准备完毕，这时调用 cyclicBarrier.await(); 即可开始等待别人； 当指定的 同时等待的线程数都调用了 cyclicBarrier.await();时，意味着这些线程都准备完毕好，然后这些线程才 同时继续执行。 实现代码如下，设想有三个跑步运动员，各自准备好后等待其他人，全部准备好后才开始跑： 1234567891011121314151617181920212223242526272829303132private static void runABCWhenAllReady() &#123; int runner = 3; CyclicBarrier cyclicBarrier = new CyclicBarrier(runner); final Random random = new Random(); for (char runnerName='A'; runnerName &lt;= 'C'; runnerName++) &#123; final String rN = String.valueOf(runnerName); new Thread(new Runnable() &#123; @Override public void run() &#123; long prepareTime = random.nextInt(10000) + 100; System.out.println(rN + " is preparing for time: " + prepareTime); try &#123; Thread.sleep(prepareTime); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; try &#123; System.out.println(rN + " is prepared, waiting for others"); cyclicBarrier.await(); // 当前运动员准备完毕，等待别人准备好 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; System.out.println(rN + " starts running"); // 所有运动员都准备好了，一起开始跑 &#125; &#125;).start(); &#125;&#125; 打印的结果如下： A is preparing for time: 4131B is preparing for time: 6349C is preparing for time: 8206 A is prepared, waiting for others B is prepared, waiting for others C is prepared, waiting for others C starts runningA starts runningB starts running 子线程完成某件任务后，把得到的结果回传给主线程实际的开发中，我们经常要创建子线程来做一些耗时任务，然后把任务执行结果回传给主线程使用，这种情况在 Java 里要如何实现呢？ 回顾线程的创建，我们一般会把 Runnable 对象传给 Thread 去执行。Runnable定义如下： 123public interface Runnable &#123; public abstract void run();&#125; 可以看到 run() 在执行完后不会返回任何结果。那如果希望返回结果呢？这里可以利用另一个类似的接口类 Callable： 12345678910@FunctionalInterfacepublic interface Callable&lt;V&gt; &#123; /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;&#125; 可以看出 Callable 最大区别就是返回范型 V 结果。 那么下一个问题就是，如何把子线程的结果回传回来呢？在 Java 里，有一个类是配合 Callable 使用的：FutureTask，不过注意，它获取结果的 get 方法会阻塞主线程。 举例，我们想让子线程去计算从 1 加到 100，并把算出的结果返回到主线程。 1234567891011121314151617181920212223242526272829private static void doTaskWithResultInWorker() &#123; Callable&lt;Integer&gt; callable = new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; System.out.println("Task starts"); Thread.sleep(1000); int result = 0; for (int i=0; i&lt;=100; i++) &#123; result += i; &#125; System.out.println("Task finished and return result"); return result; &#125; &#125;; FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(callable); new Thread(futureTask).start(); try &#123; System.out.println("Before futureTask.get()"); System.out.println("Result: " + futureTask.get()); System.out.println("After futureTask.get()"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125;&#125; 打印结果如下： Before futureTask.get() Task startsTask finished and return result Result: 5050After futureTask.get() 可以看到，主线程调用 futureTask.get() 方法时阻塞主线程；然后 Callable 内部开始执行，并返回运算结果；此时 futureTask.get() 得到结果，主线程恢复运行。 这里我们可以学到，通过 FutureTask 和 Callable 可以直接在主线程获得子线程的运算结果，只不过需要阻塞主线程。当然，如果不希望阻塞主线程，可以考虑利用 ExecutorService，把 FutureTask 放到线程池去管理执行。 小结多线程是现代语言的共同特性，而线程间通信、线程同步、线程安全是很重要的话题。本文针对 Java 的线程间通信进行了大致的讲解，后续还会对线程同步、线程安全进行讲解。]]></content>
      <categories>
        <category>Java 基础</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>多线程</tag>
        <tag>线程通信</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 中的锁]]></title>
    <url>%2F2019%2F02%2F13%2FJava%20%E4%B8%AD%E7%9A%84%E9%94%81%2F</url>
    <content type="text"><![CDATA[Java中的锁分类在读很多并发文章中，会提及各种各样锁如公平锁，乐观锁等等，这篇文章介绍各种锁的分类。介绍的内容如下： 公平锁/非公平锁 可重入锁 独享锁/共享锁 互斥锁/读写锁 乐观锁/悲观锁 分段锁 偏向锁/轻量级锁/重量级锁 自旋锁 上面是很多锁的名词，这些分类并不是全是指锁的状态，有的指锁的特性，有的指锁的设计，下面总结的内容是对每个锁的名词进行一定的解释。 公平锁/非公平锁公平锁是指多个线程按照申请锁的顺序来获取锁。非公平锁是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。有可能，会造成优先级反转或者饥饿现象。对于Java ReentrantLock而言，通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。对于Synchronized而言，也是一种非公平锁。由于其并不像ReentrantLock是通过AQS的来实现线程调度，所以并没有任何办法使其变成公平锁。 可重入锁/不可重入锁最近正在阅读Java ReentrantLock源码，始终对可重入和不可重入概念理解不透彻，进行学习后记录在这里。 基础知识Java多线程的 wait() 方法和 notify() 方法。这两个方法是成对出现和使用的，要执行这两个方法，有一个前提就是，当前线程必须获其对象的monitor（俗称“锁”），否则会抛出 IllegalMonitorStateException 异常，所以这两个方法必须在同步块代码里面调用。 wait()：阻塞当前线程 notify()：唤起被wait()阻塞的线程 不可重入锁所谓不可重入锁，即若当前线程执行某个方法已经获取了该锁，那么在方法中尝试再次获取锁时，就会获取不到被阻塞。我们尝试设计一个不可重入锁： 12345678910111213public class Lock&#123; private boolean isLocked = false; public synchronized void lock() throws InterruptedException &#123; while(isLocked)&#123; wait(); &#125; isLocked = true; &#125; public synchronized void unlock()&#123; isLocked = false; notify(); &#125;&#125; 使用该锁： 12345678910111213public class Count&#123; Lock lock = new Lock(); public void print()&#123; lock.lock(); doAdd(); lock.unlock(); &#125; public void doAdd()&#123; lock.lock(); //do something lock.unlock(); &#125;&#125; 当前线程执行print()方法首先获取lock，接下来执行doAdd()方法就无法执行doAdd()中的逻辑，必须先释放锁。这个例子很好的说明了不可重入锁。 可重入锁接下来，我们设计一种可重入锁 123456789101112131415161718192021222324public class Lock&#123; boolean isLocked = false; Thread lockedBy = null; int lockedCount = 0; public synchronized void lock() throws InterruptedException&#123; Thread thread = Thread.currentThread(); while(isLocked &amp;&amp; lockedBy != thread)&#123; wait(); &#125; isLocked = true; lockedCount++; lockedBy = thread; &#125; public synchronized void unlock()&#123; if(Thread.currentThread() == this.lockedBy)&#123; lockedCount--; if(lockedCount == 0)&#123; isLocked = false; notify(); &#125; &#125; &#125;&#125; 所谓可重入，意味着线程可以进入它已经拥有的锁的同步代码块儿。 我们设计两个线程调用 print() 方法，第一个线程调用 print() 方法获取锁，进入 lock() 方法，由于初始 lockedBy 是 null，所以不会进入 while 而挂起当前线程，而是是增量 lockedCount 并记录 lockBy 为第一个线程。接着第一个线程进入 doAdd() 方法，由于同一进程，所以不会进入 while 而挂起，接着增量 lockedCount，当第二个线程尝试lock，由于 isLocked=true，所以他不会获取该锁，直到第一个线程调用两次 unlock() 将 lockCount 递减为0，才将标记为 isLocked 设置为 false。 可重入锁的概念和设计思想大体如此，Java 中的可重入锁 ReentrantLock 设计思路也是这样。 独享锁/共享锁独享锁是指该锁一次只能被一个线程所持有。共享锁是指该锁可被多个线程所持有。 对于Java ReentrantLock而言，其是独享锁。但是对于Lock的另一个实现类ReadWriteLock，其读锁是共享锁，其写锁是独享锁。 读锁的共享锁可保证并发读是非常高效的，读写，写读 ，写写的过程是互斥的。 独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。 对于Synchronized而言，当然是独享锁。 互斥锁/读写锁上面讲的独享锁/共享锁就是一种广义的说法，互斥锁/读写锁就是具体的实现。 互斥锁在Java中的具体实现就是ReentrantLock 读写锁在Java中的具体实现就是ReadWriteLock 乐观锁/悲观锁乐观锁与悲观锁不是指具体的什么类型的锁，而是指看待并发同步的角度。悲观锁认为对于同一个数据的并发操作，一定是会发生修改的，哪怕没有修改，也会认为修改。因此对于同一个数据的并发操作，悲观锁采取加锁的形式。悲观的认为，不加锁的并发操作一定会出问题。乐观锁则认为对于同一个数据的并发操作，是不会发生修改的。在更新数据的时候，会采用尝试更新，不断重新的方式更新数据。乐观的认为，不加锁的并发操作是没有事情的。 从上面的描述我们可以看出，悲观锁适合写操作非常多的场景，乐观锁适合读操作非常多的场景，不加锁会带来大量的性能提升。 悲观锁在Java中的使用，就是利用各种锁。 乐观锁在Java中的使用，是无锁编程，常常采用的是CAS算法，典型的例子就是原子类，通过CAS自旋实现原子操作的更新。 分段锁分段锁其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap 而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。 我们以ConcurrentHashMap来说一下分段锁的含义以及设计思想，ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap（JDK7与JDK8中HashMap的实现）的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock)。当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过 hashcode 来知道他要放在那一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入。但是，在统计size的时候，可就是获取 hashmap 全局信息的时候，就需要获取所有的分段锁才能统计。分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。 偏向锁/轻量级锁/重量级锁偏向锁在没有实际竞争的情况下，还能够针对部分场景继续优化。如果不仅仅没有实际竞争，自始至终，使用锁的线程都只有一个，那么，维护轻量级锁都是浪费的。偏向锁的目标是，减少无竞争且只有一个线程使用锁的情况下，使用轻量级锁产生的性能消耗。轻量级锁每次申请、释放锁都至少需要一次CAS，但偏向锁只有初始化时需要一次CAS。 “偏向”的意思是，偏向锁假定将来只有第一个申请锁的线程会使用锁（不会有任何线程再来申请锁），因此，只需要在Mark Word中 CAS 记录owner（本质上也是更新，但初始值为空），如果记录成功，则偏向锁获取成功，记录锁状态为偏向锁，以后当前线程等于owner就可以零成本的直接获得锁；否则，说明有其他线程竞争，膨胀为轻量级锁。 偏向锁无法使用自旋锁优化，因为一旦有其他线程申请锁，就破坏了偏向锁的假定。 缺点： 同样的，如果明显存在其他线程申请锁，那么偏向锁将很快膨胀为轻量级锁。 不过这个副作用已经小的多。 如果需要，使用参数-XX:-UseBiasedLocking禁止偏向锁优化（默认打开）。 轻量级锁自旋锁的目标是降低线程切换的成本。如果锁竞争激烈，我们不得不依赖于重量级锁，让竞争失败的线程阻塞；如果完全没有实际的锁竞争，那么申请重量级锁都是浪费的。轻量级锁的目标是，减少无实际竞争情况下，使用重量级锁产生的性能消耗，包括系统调用引起的内核态与用户态切换、线程阻塞造成的线程切换等。 顾名思义，轻量级锁是相对于重量级锁而言的。使用轻量级锁时，不需要申请互斥量，仅仅将 Mark Word 中的部分字节CAS更新指向线程栈中的Lock Record，如果更新成功，则轻量级锁获取成功，记录锁状态为轻量级锁；否则，说明已经有线程获得了轻量级锁，目前发生了锁竞争（不适合继续使用轻量级锁），接下来膨胀为重量级锁。 Mark Word是对象头的一部分；每个线程都拥有自己的线程栈（虚拟机栈），记录线程和函数调用的基本信息。二者属于JVM的基础内容，此处不做介绍。 当然，由于轻量级锁天然瞄准不存在锁竞争的场景，如果存在锁竞争但不激烈，仍然可以用自旋锁优化，自旋失败后再膨胀为重量级锁。 重量级锁内置锁在Java中被抽象为监视器锁（monitor）。在JDK 1.6之前，监视器锁可以认为直接对应底层操作系统中的互斥量（mutex）。这种同步方式的成本非常高，包括系统调用引起的内核态与用户态切换、线程阻塞造成的线程切换等。因此，后来称这种锁为“重量级锁”。 小结 偏向锁、轻量级锁、重量级锁分配和膨胀的详细过程见后。会涉及一些Mark Word与CAS的知识。 偏向锁、轻量级锁、重量级锁适用于不同的并发场景： 偏向锁：无实际竞争，且将来只有第一个申请锁的线程会使用锁。 轻量级锁：无实际竞争，多个线程交替使用锁；允许短时间的锁竞争。 重量级锁：有实际竞争，且锁竞争时间长。 另外，如果锁竞争时间短，可以使用自旋锁进一步优化轻量级锁、重量级锁的性能，减少线程切换。 如果锁竞争程度逐渐提高（缓慢），那么从偏向锁逐步膨胀到重量锁，能够提高系统的整体性能。 自旋锁首先，内核态与用户态的切换上不容易优化。但通过自旋锁，可以减少线程阻塞造成的线程切换（包括挂起线程和恢复线程）。 如果锁的粒度小，那么锁的持有时间比较短（尽管具体的持有时间无法得知，但可以认为，通常有一部分锁能满足上述性质）。那么，对于竞争这些锁的而言，因为锁阻塞造成线程切换的时间与锁持有的时间相当，减少线程阻塞造成的线程切换，能得到较大的性能提升。具体如下： 当前线程竞争锁失败时，打算阻塞自己 不直接阻塞自己，而是自旋（空等待，比如一个空的有限for循环）一会 在自旋的同时重新竞争锁 如果自旋结束前获得了锁，那么锁获取成功；否则，自旋结束后阻塞自己 如果在自旋的时间内，锁就被旧owner释放了，那么当前线程就不需要阻塞自己（也不需要在未来锁释放时恢复），减少了一次线程切换。 “锁的持有时间比较短“这一条件可以放宽。实际上，只要锁竞争的时间比较短（比如线程1快释放锁的时候，线程2才会来竞争锁），就能够提高自旋获得锁的概率。这通常发生在锁持有时间长，但竞争不激烈的场景中。 典型的自旋锁实现的例子，可以参考自旋锁的实现 锁分配和膨胀过程 参考链接 Java中的锁分类 Java不可重入锁和可重入锁理解 浅谈偏向锁、轻量级锁、重量级锁]]></content>
      <categories>
        <category>Java 基础</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 反射]]></title>
    <url>%2F2019%2F02%2F11%2FJava%20%E5%8F%8D%E5%B0%84%2F</url>
    <content type="text"><![CDATA[类加载器当程序有使用某个类时，如果该类还没有被加载到内存中，则系统会通过加载，连接，初始化三步来实现对这个类进行初始化 加载就是指将class文件读入内存，并为之创建一个Class对象，任何类被使用时系统都会建立一个Class对象 连接验证 是否有正确的内部结构，并和其他类协调一致准备 负责为类的静态成员分配内存，并设置默认初始化值解析 将类的二进制数据中的符号引用替换为直接引用 初始化对类的静态变量，静态代码块执行初始化操作类初始化时机 创建类的实例 类的静态变量，或者为静态变量赋值 类的静态方法 使用反射方式来强制创建某个类或接口对应的java.lang.Class对象 初始化某个类的子类 直接使用java.exe命令来运行某个主类类加载器 负责将.class文件加载到内在中，并为之生成对应的Class对象 虽然我们不需要关心类加载机制，但是了解这个机制我们就能更好的理解程序的运行类加载器的组成 Bootstrap ClassLoader 根类加载器也被称为引导类加载器，负责Java核心类的加载比如System，String等。在 JDK 中 JRE 的 lib 目录下 rt.jar 文件中 Extension ClassLoader扩展类加载器负责 JRE 的扩展目录中 jar 包的加载。在 JDK 中 JRE 的 lib 目录下 ext 目录 System ClassLoader系统类加载器负责在JVM启动时加载来自java命令的class文件，以及classpath环境变量所指定的jar包和类路径 通过这些描述就可以知道我们常用的类，都是由谁来加载完成的。 到目前为止我们已经知道把class文件加载到内存了，那么，如果我们仅仅站在这些class文件的角度，我们如何来使用这些class文件中的内容呢? 这就是我们反射要研究的内容 反射JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。要想解剖一个类,必须先要获取到该类的字节码文件对象。而解剖使用的就是Class类中的方法.所以先要获取到每一个字节码文件对应的Class类型的对象 Class类阅读API的Class类得知，Class 没有公共构造方法。Class 对象是在加载类时由 Java 虚拟机以及通过调用类加载器中的 defineClass 方法自动构造的 获取Class对象的三种方式方式一: 通过Object类中的getObject()方法12Person p = new Person();Class c = p.getClass(); 方式二: 通过 类名.class 获取到字节码文件对象（任意数据类型都具备一个class静态属性,看上去要比第一种方式简单）1Class c2 = Person.class; 方式三: 通过Class类中的方法（将类名作为字符串传递给Class类中的静态方法forName即可）1Class c3 = Class.forName("cn.cuzz.Person"); 注意：第三种和前两种的区别 前两种你必须明确Person类型 后面是指定这种类型的字符串就行(要包含包名)，这种扩展更强，我不需要知道你的类，我只提供字符串，按照配置文件加载就可以了 Person类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class Person &#123; // 成员变量 public String name; public int age; private String address; // 构造方法 public Person() &#123; System.out.println("空参数构造方法"); &#125; public Person(String name) &#123; this.name = name; System.out.println("带有String的构造方法"); &#125; // 私有的构造方法 private Person(String name, int age)&#123; this.name = name; this.age = age; System.out.println("带有String，int的构造方法"); &#125; public Person(String name, int age, String address)&#123; this.name = name; this.age = age; this.address = address; System.out.println("带有String, int, String的构造方法"); &#125; // 成员方法 // 没有返回值没有参数的方法 public void method1()&#123; System.out.println("没有返回值没有参数的方法"); &#125; // 没有返回值，有参数的方法 public void method2(String name)&#123; System.out.println("没有返回值，有参数的方法 name= "+ name); &#125; // 有返回值，没有参数 public int method3()&#123; System.out.println("有返回值，没有参数的方法"); return 123; &#125; // 有返回值，有参数的方法 public String method4(String name)&#123; System.out.println("有返回值，有参数的方法"); return "哈哈" + name; &#125; // 私有方法 private void method5()&#123; System.out.println("私有方法"); &#125; @Override public String toString() &#123; return "Person [name=" + name + ", age=" + age + ", address=" + address+ "]"; &#125;&#125; 通过反射获取构造方法并使用在反射机制中，把类中的成员（构造方法、成员方法、成员变量）都封装成了对应的类进行表示。其中，构造方法使用类Constructor表示。可通过Class类中提供的方法获取构造方法： 返回一个构造方法 public Constructor&lt;T&gt; getConstructor(Class&lt;?&gt;... parameterTypes) 获取public修饰, 指定参数类型所对应的构造方法 public Constructor&lt;T&gt; getDeclaredConstructor(Class&lt;?&gt;... parameterTypes) 获取指定参数类型所对应的构造方法(包含私有的) 返回多个构造方法 public Constructor&lt;?&gt;[] getConstructors()获取所有的public 修饰的构造方法 public Constructor&lt;?&gt;[] getDeclaredConstructors() 获取所有的构造方法(包含私有的)123456789101112131415161718192021222324252627282930313233package cn.cuzz;import java.lang.reflect.Constructor;public class Test &#123; public static void main(String[] args) throws ClassNotFoundException, NoSuchMethodException, SecurityException &#123; // 获取Class对象 包名.类 Class c = Class.forName("cn.cuzz.Person"); // 获取所有构造方法 // 只包括public Constructor[] cons = c.getConstructors(); // 即包括public也包括private Constructor[] conss = c.getDeclaredConstructors(); // 获取一个构造方法 // public Person() Constructor con1 = c.getConstructor(null); System.out.println(con1); // public Person(String name) Constructor con2 = c.getConstructor(String.class); System.out.println(con2); // private Person(String name, int age) Constructor con3 = c.getDeclaredConstructor(String.class, int.class); System.out.println(con3); // public Person(String name, int age, String address) Constructor con4 = c.getDeclaredConstructor(String.class, int.class, String.class); System.out.println(con4); &#125;&#125; 通过反射方式，获取构造方法，创建对象获取构造方法，步骤如下： 获取到Class对象 获取指定的构造方法 通过构造方法类Constructor中的方法，创建对象public T newInstance(Object... initargs)123456789101112131415161718package cn.cuzz;import java.lang.reflect.Constructor;public class Test2 &#123; public static void main(String[] args) throws Exception &#123; // 获取Class对象 Class c = Class.forName("cn.cuzz.Person"); // 获取指定构造器 Constructor con = c.getConstructor(String.class, int.class, String.class); // 通过构造方法中的Constructor的方法 创建对象 Object obj = con.newInstance("cuzz", 18, "武汉"); System.out.println(obj); // Person [name=cuzz, age=18, address=武汉] &#125;&#125; 通过反射获取成员变量并使用在反射机制中，把类中的成员变量使用类Field表示。可通过Class类中提供的方法获取成员变量： 返回一个成员变量 public Field getField(String name) 获取指定的public修饰的变量 public Field getDeclaredField(String name) 获取指定的任意变量 返回多个成员变量 public Field[] getFields() 获取所有public 修饰的变量 public Field[] getDeclaredFields() 获取所有的 变量 (包含私有)1234567891011121314151617181920212223package cn.cuzz;import java.lang.reflect.Field;public class Test3 &#123; public static void main(String[] args) throws Exception &#123; // 获取Class对象 Class c = Class.forName("cn.cuzz.Person"); // 获取多个成员变量 Field[] fields = c.getFields(); Field[] fieldss = c.getDeclaredFields(); // 一个变量 // public int age Field ageField = c.getField("age"); System.out.println(ageField); // public int cn.cuzz.Person.age // private String address Field addressField = c.getDeclaredField("address"); System.out.println(addressField); // private java.lang.String cn.cuzz.Person.address &#125;&#125; 通过反射，创建对象，获取指定的成员变量，进行赋值与获取值操作获取成员变量，步骤如下： 获取Class对象 获取构造方法 通过构造方法，创建对象 获取指定的成员变量（私有成员变量，通过setAccessible(boolean flag)方法暴力访问） 通过方法，给指定对象的指定成员变量赋值或者获取值public void set(Object obj, Object value)在指定对象obj中，将此 Field 对象表示的成员变量设置为指定的新值public Object get(Object obj)返回指定对象obj中，此 Field 对象表示的成员变量的值123456789101112131415161718192021222324252627282930package cn.cuzz;import java.lang.reflect.Constructor;import java.lang.reflect.Field;public class Test4 &#123; public static void main(String[] args) throws IllegalAccessException, Exception &#123; // 获取Class对象 Class c = Class.forName("cn.cuzz.Person"); // 获取构造方法 Constructor con = c.getConstructor(String.class); // 通过构造方法 创建对象 Object obj = con.newInstance("cuzz"); // 获取指定成员变量 // public String name Field nameField = c.getField("name"); // public int age Field ageField = c.getField("age"); // 赋值 nameField.set(obj, "Cuzz"); ageField.set(obj, 23); System.out.println("name = "+ nameField.get(obj)); // name = Cuzz System.out.println("age = "+ ageField.get(obj)); // age = 23 &#125;&#125; 通过反射获取成员方法并使用在反射机制中，把类中的成员方法使用类Method表示。可通过Class类中提供的方法获取成员方法： 返回获取一个方法： public Method getMethod(String name, Class&lt;?&gt;... parameterTypes) 获取 public 修饰的方法 public Method getDeclaredMethod(String name, Class&lt;?&gt;... parameterTypes) 获取任意的方法，包含私有的 参数1: name 要查找的方法名称； 参数2： parameterTypes 该方法的参数类型 返回获取多个方法： public Method[] getMethods() 获取本类与父类中所有public 修饰的方法 public Method[] getDeclaredMethods() 获取本类中所有的方法(包含私有的)12345678910111213141516171819202122232425262728package cn.cuzz;import java.lang.reflect.Method;public class Test5 &#123; public static void main(String[] args) throws Exception &#123; // 获取Class对象 Class c = Class.forName("cn.cuzz.Person"); // 获取多个方法 Method[] methods = c.getMethods(); Method[] methodss = c.getDeclaredMethods(); // 获取一个方法： // public void method1() Method method = c.getMethod("method1", null); System.out.println(method); // public String method4(String name)&#123; method = c.getMethod("method4", String.class); System.out.println(method); // 私有方法 // private void method5() method = c.getDeclaredMethod("method5", null); System.out.println(method); &#125;&#125; 通过反射，创建对象，调用指定的方法获取成员方法，步骤如下： 获取Class对象 获取构造方法 通过构造方法，创建对象 获取指定的方法 执行找到的方法(如果获取的是私有方法则要开启暴力访问m5.setAccessible(true))public Object invoke(Object obj, Object... args) 执行指定对象obj中，当前Method对象所代表的方法，方法要传入的参数通过args指定12345678910111213141516171819202122232425package cn.cuzz;import java.lang.reflect.Constructor;import java.lang.reflect.Method;public class Test6 &#123; public static void main(String[] args) throws Exception &#123; // 获取Class对象 Class c = Class.forName("cn.cuzz.Person"); // 获取指定构造器 Constructor con = c.getConstructor(String.class, int.class, String.class); // 通过构造方法中的Constructor的方法 创建对象 Object obj = con.newInstance("cuzz", 18, "武汉"); // 获取指定的方法 Method m4 = c.getMethod("method4", String.class); // 执行找到的方法 Object result = m4.invoke(obj, "2018/03/19"); System.out.println("result = " + result); // result = 哈哈2018/03/19 &#125;&#125; 反射练习下面展示一下反射的利用场景。 泛型擦除思考，将已存在的ArrayList&lt;Integer&gt;集合中添加一个字符串数据，如何实现呢？ 我来告诉大家，其实程序编译后产生的.class文件中是没有泛型约束的，这种现象我们称为泛型的擦除。那么，我们可以通过反射技术，来完成向有泛型约束的集合中，添加任意类型的元素123456789101112131415161718192021222324252627package cn.cuzz;import java.lang.reflect.Method;import java.util.ArrayList;public class Test7 &#123; public static void main(String[] args) throws Exception, SecurityException &#123; ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(); // 添加元素 list.add("cuzz"); // list.add(23); 报错 // 通过反射技术，实现添加任意类型的元素 // 获取字节码文件对象 Class c = Class.forName("java.util.ArrayList"); // 找到add()方法 Method addMethod = c.getMethod("add", Object.class); // 执行add()方法 addMethod.invoke(list, 23); System.out.println(list); //[cuzz, 23] &#125;&#125; 反射配置文件通过配置文件得到类名和要运行的方法名,用反射的操作类名得到对象和调用方法 实现步骤: 准备配置文件,键值对 IO流读取配置文件 Reader 文件中的键值对存储到集合中 Properties集合保存的键值对,就是类名和方法名 反射获取指定类的class文件对象 class文件对象,获取指定的方法 运行方法1234567891011121314151617181920public class Test8 &#123; public static void main(String[] args) throws Exception&#123; // IO流读取配置文件 FileReader r = new FileReader("config.properties"); // 创建集合对象 Properties pro = new Properties(); // 调用集合方法load,传递流对象 pro.load(r); r.close(); // 通过键获取值 String className = pro.getProperty("className"); String methodName = pro.getProperty("methodName"); // 反射获取指定类的class文件对象 Class c = Class.forName(className); Object obj = c.newInstance(); // 获取指定的方法名 Method method = c.getMethod(methodName); method.invoke(obj); &#125;&#125; 配置文件123456# className=cn.cuzz.Student# methodName=studyclassName=cn.cuzz.TeachermethodName=teach# className=cn.cuzz.Worker# methodName=work]]></content>
      <categories>
        <category>Java 基础</category>
      </categories>
      <tags>
        <tag>反射</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring注解驱动开发（四）]]></title>
    <url>%2F2019%2F02%2F10%2FSpring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[AOP面向切面编程AOP（Aspect Oriented Programming），即面向切面编程，可以说是OOP（Object Oriented Programming，面向对象编程）的补充和完善。OOP引入封装、继承、多态等概念来建立一种对象层次结构，用于模拟公共行为的一个集合。不过OOP允许开发者定义纵向的关系，但并不适合定义横向的关系，例如日志功能。日志代码往往横向地散布在所有对象层次中，而与它对应的对象的核心功能毫无关系对于其他类型的代码，如安全性、异常处理和透明的持续性也都是如此，这种散布在各处的无关的代码被称为横切（cross cutting），在OOP设计中，它导致了大量代码的重复，而不利于各个模块的重用。 底层实现Spring 的 AOP 的底层用到两种代理机制： JDK 的动态代理 ：类必须实现接口，所以是针对实现了接口的类产生代理. Cglib 的动态代理：针对没有实现接口的类产生代理，应用的是底层的字节码增强的技术生成当前类的子类对象 JDK 的动态代理 UserService接口，实现增删改查的功能 12345678package com.cuzz.service;public interface UserService &#123; void add(); void delete(); void update(); void get();&#125; UserService接口的实现的类 12345678910111213141516171819202122public class UserServiceImpl implements UserService &#123; @Override public void add() &#123; System.out.println("添加一个user"); &#125; @Override public void delete() &#123; System.out.println("删除一个user"); &#125; @Override public void update() &#123; System.out.println("更新一个user"); &#125; @Override public void get() &#123; System.out.println("查询一个user"); &#125;&#125; 实现动态代理 123456789101112131415161718192021222324252627282930313233package com.cuzz.service;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;public class UserServiceProxyFactory implements InvocationHandler&#123; private UserService us; public UserServiceProxyFactory(UserService us) &#123; super(); this.us = us; &#125; // 获得动态代理 public UserService getUserServiceProxy() &#123; // 生成动态代理 UserService usProxy = (UserService) Proxy.newProxyInstance(UserServiceProxyFactory.class.getClassLoader(), UserServiceImpl.class.getInterfaces(), this); // 这个 this 就是实现 InvocationHandler 的对象 return usProxy; &#125; @Override public Object invoke(Object arg0, Method method, Object[] arg2) throws Throwable &#123; System.out.println("打开事务!"); Object invoke = method.invoke(us, arg2); System.out.println("提交事务!"); return invoke; &#125;&#125; 测试 123456789public class TestDemo &#123; @Test public void test01()&#123; UserService us = new UserServiceImpl(); UserServiceProxyFactory factory = new UserServiceProxyFactory(us); UserService usProxy = factory.getUserServiceProxy(); usProxy.add(); &#125;&#125; 输出 123打开事务!添加一个user提交事务! Cglib 的动态代理 Cglib 的动态代理的代码实现 123456789101112131415161718192021222324252627282930313233package com.cuzz.service;import java.lang.reflect.Method;import org.springframework.cglib.proxy.Enhancer;import org.springframework.cglib.proxy.MethodInterceptor;import org.springframework.cglib.proxy.MethodProxy;public class UserServiceProxyFactory2 implements MethodInterceptor &#123; public UserService getUserServiceProxy()&#123; // 帮我们生成代理对象 Enhancer en = new Enhancer(); // 设置对谁进行代理 en.setSuperclass(UserServiceImpl.class); // 代理要做什么 en.setCallback(this); // 创建代理对象 UserService us = (UserService) en.create(); return us; &#125; @Override public Object intercept(Object prxoyobj, Method method, Object[] arg, MethodProxy methodProxy) throws Throwable &#123; // 打开事务 System.out.println("打开事务!"); // 调用原有方法 Object returnValue = methodProxy.invokeSuper(prxoyobj, arg); // 提交事务 System.out.println("提交事务!"); return returnValue; &#125;&#125; 测试 123456@Testpublic void test02() &#123; UserServiceProxyFactory2 factory = new UserServiceProxyFactory2(); UserService usProxy = factory.getUserServiceProxy(); usProxy.add();&#125; Spring的AOP开发(基于AspectJ)AOP的开发中的相关术语： Joinpoint(连接点)：所谓连接点是指那些被拦截到的点，在 spring 中这些点指的是方法，因为 spring 只支持方法类型的连接点 Pointcut(切入点)：所谓切入点是指我们要对哪些 Joinpoint 进行拦截的定义 Advice(通知/增强)：所谓通知是指拦截到 Joinpoint 之后所要做的事情就是通知.通知分为前置通知,后置通知,异常通知,最终通知,环绕通知(切面要完成的功能) Introduction(引介)：引介是一种特殊的通知在不修改类代码的前提下, Introduction 可以在运行期为类动态地添加一些方法或 Field Target(目标对象)：代理的目标对象 Weaving(织入)：是指把增强应用到目标对象来创建新的代理对象的过程，spring 采用动态代理织入，而 AspectJ 采用编译期织入和类装在期织入 Proxy（代理）：一个类被 AOP 织入增强后，就产生一个结果代理类 Aspect(切面)：是切入点和通知（引介）的结合 通知类型 前置通知 ：在目标方法执行之前执行 后置通知 ：在目标方法执行之后执行 环绕通知 ：在目标方法执行前和执行后执行 异常抛出通知：在目标方法执行出现异常的时候执行 最终通知 ：无论目标方法是否出现异常 最终通知都会执行 代码演示通知类，给切面的目标方法标注何时地运行，必须告诉 Spring 哪个类是切面类，添加注解 @Aspect 12345678910111213141516171819202122232425262728293031323334@Aspect // 表示该类是一个通知类public class MyAdvice &#123; // 前置通知 @Before("execution(* com.cuzz.service..*ServiceImpl.*(..))") public void before()&#123; System.out.println("这是前置通知!!"); &#125; // 后置通知 @AfterReturning("execution(* com.cuzz.service..*ServiceImpl.*(..))") public void afterReturning()&#123; System.out.println("这是后置通知(如果出现异常不会调用)!!"); &#125; // 环绕通知 @Around("execution(* com.cuzz.service..*ServiceImpl.*(..))") public Object around(ProceedingJoinPoint pjp) throws Throwable &#123; System.out.println("这是环绕通知之前的部分!!"); // 调用目标方法 Object proceed = pjp.proceed(); System.out.println("这是环绕通知之后的部分!!"); return proceed; &#125; // 异常通知 @AfterThrowing("execution(* com.cuzz.service..*ServiceImpl.*(..))") public void afterException()&#123; System.out.println("出事啦!出现异常了!!"); &#125; // 后置通知 @After("execution(* com.cuzz.service..*ServiceImpl.*(..))") public void after()&#123; System.out.println("这是后置通知(出现异常也会调用)!!"); &#125;&#125; 配置类，将切面类和业务逻辑类都加入到容器中，给配置类加 @EnableAspectJAutoProxy 注解 12345678910111213141516171819/** * @Author: cuzz * @Date: 2019/2/10 20:43 * @Description: */@Configuration@EnableAspectJAutoProxypublic class MainConfigOfAOP &#123; @Bean public UserService userService() &#123; return new UserServiceImpl(); &#125; @Bean public MyAdvice myAdvice() &#123; return new MyAdvice(); &#125;&#125; 测试 12345678910@Testpublic void test03() &#123; AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfAOP.class); UserService userService = (UserService) applicationContext.getBean("userService"); userService.add(); userService.delete(); userService.update(); userService.get();&#125; 如果报错添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.4&lt;/version&gt; &lt;/dependency&gt;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>Spring</tag>
        <tag>注解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解Java虚拟机（三）]]></title>
    <url>%2F2019%2F02%2F06%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Java 字节码代码编译结果从本地机器码转变为字节码，是存储格式发展的一小步，确是编程语言发展的一大步。 字节码文件剖析我们从一段简单的代码来入手 123456789101112public class MyTest01 &#123; private int a = 0; public int getA() &#123; return a; &#125; public void setA(int a) &#123; this.a = a; &#125;&#125; 我要要看一下 java 文件对应的 class 文件的结构，定位到工程的 out\production\classes 下边执行： javap -c com.cuzz.jvm.bytecode.Mytest01 12345678910111213141516171819202122232425警告: 二进制文件com.cuzz.jvm.bytecode.Mytest01包含com.cuzz.jvm.bytecode.MyTest01Compiled from &quot;MyTest01.java&quot;public class com.cuzz.jvm.bytecode.MyTest01 &#123; public com.cuzz.jvm.bytecode.MyTest01(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: aload_0 5: iconst_0 6: putfield #2 // Field a:I 9: return public int getA(); Code: 0: aload_0 1: getfield #2 // Field a:I 4: ireturn public void setA(int); Code: 0: aload_0 1: iload_1 2: putfield #2 // Field a:I 5: return&#125; 我们如果需要获得更多信息可以使用如下命令： javap -verbose com.cuzz.jvm.bytecode.Mytest01 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384警告: 二进制文件com.cuzz.jvm.bytecode.Mytest01包含com.cuzz.jvm.bytecode.MyTest01Classfile /E:/project/learn-demo/demo-10-jvm-lecture/out/production/classes/com/cuzz/jvm/bytecode/Mytest01.class Last modified 2019-2-3; size 492 bytes MD5 checksum cceeac51ae7b6fc46c60faf834de5932 Compiled from &quot;MyTest01.java&quot;public class com.cuzz.jvm.bytecode.MyTest01 minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 = Methodref #4.#20 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Fieldref #3.#21 // com/cuzz/jvm/bytecode/MyTest01.a:I #3 = Class #22 // com/cuzz/jvm/bytecode/MyTest01 #4 = Class #23 // java/lang/Object #5 = Utf8 a #6 = Utf8 I #7 = Utf8 &lt;init&gt; #8 = Utf8 ()V #9 = Utf8 Code #10 = Utf8 LineNumberTable #11 = Utf8 LocalVariableTable #12 = Utf8 this #13 = Utf8 Lcom/cuzz/jvm/bytecode/MyTest01; #14 = Utf8 getA #15 = Utf8 ()I #16 = Utf8 setA #17 = Utf8 (I)V #18 = Utf8 SourceFile #19 = Utf8 MyTest01.java #20 = NameAndType #7:#8 // &quot;&lt;init&gt;&quot;:()V #21 = NameAndType #5:#6 // a:I #22 = Utf8 com/cuzz/jvm/bytecode/MyTest01 #23 = Utf8 java/lang/Object&#123; public com.cuzz.jvm.bytecode.MyTest01(); descriptor: ()V flags: ACC_PUBLIC Code: stack=2, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: aload_0 5: iconst_0 6: putfield #2 // Field a:I 9: return LineNumberTable: line 8: 0 line 10: 4 LocalVariableTable: Start Length Slot Name Signature 0 10 0 this Lcom/cuzz/jvm/bytecode/MyTest01; public int getA(); descriptor: ()I flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: getfield #2 // Field a:I 4: ireturn LineNumberTable: line 13: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Lcom/cuzz/jvm/bytecode/MyTest01; public void setA(int); descriptor: (I)V flags: ACC_PUBLIC Code: stack=2, locals=2, args_size=2 0: aload_0 1: iload_1 2: putfield #2 // Field a:I 5: return LineNumberTable: line 17: 0 line 18: 5 LocalVariableTable: Start Length Slot Name Signature 0 6 0 this Lcom/cuzz/jvm/bytecode/MyTest01; 0 6 1 a I&#125;SourceFile: &quot;MyTest01.java&quot; 我们也可以使用二进制文件查看器查看class文件的16进制信息（winhex下载）： 16文件查看器里边第一行的CA 就是一个字节的容量（8位bit）: 使用 javap -verbos 命令分析一个字节码文件时，将会分析该字节码文件的魔数、版本号、常量池、类信息、类的构造方法信息、类变量与成员变量等信息。 魔数：所有的.class字节码文件的前4个字节都是魔数，魔数值为固定值：0xCAFEBABE (詹姆斯.高斯林设计的，蕴意：咖啡宝贝，java 的图标是咖啡。 魔数之后的4个字节为版本信息，前2个字节表示 minor versio（次版本号），后两个字节表示 major version（主版本号）。 这里的版本号为 00 00 00 34，换算成十进制，表示次版本号为0，主版本号为52。 字节常量池剖析常量池（constant pool）：紧接着主版本号之后的就是常量池入口。一个 Java 类中定义的很多信息都是由常量池来维护和描述的，可以将常量池看作是 Class 文件的资源仓库，比如说 Java 类中定义的方法与变量信息，都是存储在常量池中。常量池中的主要储存两类常量：字面量与符号引用。字面量如文本字符串，Java 中声明为 final 的常量值等，而符号引用如类和接口的全局限定名，字段的名称和描述符，方法的名称和描述符等。 常量池的总体结构：Java 类所对应的常量池主要由常量池数量与常量池数组（常量表）这两部分共同构成。常量池数量紧跟在主版本号后面，占据 2 个字节；常量池数组紧跟在常量池数量之后。常量池数组与一般的数组不同的是，常量池数组中不同的元素类型、结构都是不同的，长度当然也就不同；但是，每一种元素的第一个数据都是一个 u1 类型，该字节是一个标志位，占据 1 个字节。JVM 在解析常量池时，会根据这个 u1 类型来获取元素的具体类型。 值得注意的是，常量池数组中元素的个数 = 常量池数 - 1 （其中0暂时不使用）。对应的是 00 18 转化为十进制为24个常量，而我们看到只有23个。目的是满足某些常量池索引值的数据在特定情况下需要表达“不引用任何一个常量”的含义；根本原因在于，索引 0 也是一个常量（保留常量），只不过它不位于常量表中，这个常量就对应 null 值，所以，常量池的索引从 1 开始而不是 0 。 123456789101112131415161718192021222324Constant pool: #1 = Methodref #4.#20 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Fieldref #3.#21 // com/cuzz/jvm/bytecode/MyTest01.a:I #3 = Class #22 // com/cuzz/jvm/bytecode/MyTest01 #4 = Class #23 // java/lang/Object #5 = Utf8 a #6 = Utf8 I #7 = Utf8 &lt;init&gt; #8 = Utf8 ()V #9 = Utf8 Code #10 = Utf8 LineNumberTable #11 = Utf8 LocalVariableTable #12 = Utf8 this #13 = Utf8 Lcom/cuzz/jvm/bytecode/MyTest01; #14 = Utf8 getA #15 = Utf8 ()I #16 = Utf8 setA #17 = Utf8 (I)V #18 = Utf8 SourceFile #19 = Utf8 MyTest01.java #20 = NameAndType #7:#8 // &quot;&lt;init&gt;&quot;:()V #21 = NameAndType #5:#6 // a:I #22 = Utf8 com/cuzz/jvm/bytecode/MyTest01 #23 = Utf8 java/lang/Object Class 文件结构中常量池数据类型的结构表 在 JVM 规范中，每一个变量/字段都有描述信息，描述信息主要的作用是描述字段的数据类型、方法的参数列表（包括数量、类型与顺序）与返回值。根据描述符规则，基本数据类型和代表无返回的 void 类型都是用一个大写字符来表示，对象类型则使用字符 L 加对象的全限定名称来表示。为了压缩字节码文件的体积，对于基本数据类型，JVM 都只使用一个大写字母来表示，如下所示：B - byte，C - char，D - double，F - float，I - int，J - long，S - short，Z - boolean，V - void，L - 对象类型，如 Ljava/lang/String;。 对于数组类型来说，没一个维度使用前置 [ 来表示，如 int [] 被记录为 [I ，String[][] 被记录为 [[Ljava/lang/String;。 用描述符描述方法时，按照先参数列表，后返回值的顺序来描述。参数列表按照参数的严格顺序放在一组括号内，如方法：String getRealNameByIdAndNickName(int id, String name) 的描述符为：(I, Ljava/lang/String;) Ljava/lang/String; 我们来分析前面几个常量，如图： 我反编译出来的文件对比： 123456789101112131415161718192021222324Constant pool: #1 = Methodref #4.#20 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Fieldref #3.#21 // com/cuzz/jvm/bytecode/MyTest01.a:I #3 = Class #22 // com/cuzz/jvm/bytecode/MyTest01 #4 = Class #23 // java/lang/Object #5 = Utf8 a #6 = Utf8 I #7 = Utf8 &lt;init&gt; #8 = Utf8 ()V #9 = Utf8 Code#10 = Utf8 LineNumberTable#11 = Utf8 LocalVariableTable#12 = Utf8 this#13 = Utf8 Lcom/cuzz/jvm/bytecode/MyTest01;#14 = Utf8 getA#15 = Utf8 ()I#16 = Utf8 setA#17 = Utf8 (I)V#18 = Utf8 SourceFile#19 = Utf8 MyTest01.java#20 = NameAndType #7:#8 // &quot;&lt;init&gt;&quot;:()V#21 = NameAndType #5:#6 // a:I#22 = Utf8 com/cuzz/jvm/bytecode/MyTest01#23 = Utf8 java/lang/Object 0A 00 04 00 14，如图中的标注出来，0A 对应值为10，在上表的常量中 CONSTANT_Methodref_info 中，那么后边的2个字节 00 04 （十进制4）就是 U2（第一个index），即指向声明方法的类描述符 CONSTANT_Class_info 的索引项，而第二个索引（第二个index）00 14（十进制20） 指向名称及类型描述符 CONSTANT_NameAndType_info 的索引项。类描述指向 #4 ，#4 又指向 #23，所以描述为 java/lang/Object，而名称以及类型描述符指向 #20，#20 有指向 #7 和 #8，&quot;&lt;init&gt;&quot;:()V 表示为构造方法。 09 00 03 00 15 ，09 是标志位对用的是 CONSTANT_Fieldref_info，第一个索引指向的是声明字段的类或接口描述符，CONSTANT_Class_info 的索引项，根上面一样分析。 07 00 16 ， 00 16 十进制是22 ，07是常量 CONSTANT_CLass_info，只有一个index，指向的是指定权限定名常量项的索引， 00 16 是十进制22。 07 00 17 ，07是常量 CONSTANT_CLass_info，只有一个index，指向的是指定权限定名常量项的索引，00 17 十进制是23。 01 00 01 61，01 是 CONSTANT_Utf8_info，后面 00 01 这两个字节表示长度，最后 61 （十进制为97）的表示 ASCII 中带索引，在 ASCII 中为字母 a。 01 00 01 为 I。 等等 Java 字节码结构 Class 字节码中有两种数据类型 字节数据直接量：这是基本的数据类型，共细分为 u1、u2、u4、u8 这四种，分别代表连续的 1 个字节、2 个字节、4 个字节和8 个字节。 表（数组）：表示有多个基本数据或其他表，按照既定顺序组成的大的数据集合。表示有结构的，它的结构体现在，组成表的成分所在的位置和顺序都已经严格定义好的。 访问标志访问标志（Access_Flag）信息包括该 Class 文件是类还是接口，是否被定义成 public，是否是 abstract，如果是类，是否被声明成 final。通过上面的源代码，我们可以知道该文件是类并且是 public。 常量池之后两个字节就是访问标志，我们这个类中是 0x 00 21 ，从上面来看并没有，原来它是 0x 00 20 和 0x 00 01 的并集，表示 ACC_PUBLIC 与 ACC_SUPER。 类索引、父类索引与接口索引 00 03 是类索引，指向 #3 表示是一个类，其名字为 com/cuzz/jvm/bytecode/MyTest01 00 04 是父亲索引，指向 #4 表示是一个类，其名字是 java/lang/Object 00 00 是接口，表示没有接口 字段表集合字段表用于描述类和接口中声明的变量。这里的字段包含了类级别变量以及实例变量，但不包括方法内部声明的局部变量。 如下图 00 01 是成员变量的数量，后面接着就是 field_info 成员变量信息 1234567field_info &#123; u2 access_flags; // 0002 表示私有 private u2 name_index; // 0005 表示 a u2 descriptor_index; // 0006 表示 I u2 attributes_count; // 0000 没有 attribute_info attributes[attributes_count];&#125; 方法表刚开始的 00 03 表示有三个方法，除了getter/setter 还有默认构造方法 1234567methods_count &#123; u2 access_flags; // 0001 表示 public u2 name_index; // 0007 指向常量池中 #7 的常量为 &lt;init&gt; u2 descriptor_index; // 0008 指向常量池中 #8 的常量为 ()V u2 attributes_count; // 0001 表示一个属性 attribute_info attributes[attributes_count];&#125; 方法中的属性结构 12345attribute_info &#123; u2 attribute_name_index; // 0009 指向常量池中 #9 为 Code u4 attribute_length; // 0000 0038 表示长度为 0x38 为 56 长度的字节 u1 info[attribute_length];&#125; Code 结构Code attribute 的作用是保存该方法的结构，如所对应的字节码 1234567891011121314151617Code_attribute &#123; u2 attribute_name_index; u4 attribute_length; u2 max_stack; u2 max_locals; u4 code_length; u1 code[code_length]; u2 exception_table_length; &#123; u2 start_pc; u2 end_pc; u2 handler_pc; u2 catch_type; &#125; exception_table[exception_table_length]; u2 attributes_count; attribute_info attributes[attributes_count];&#125; attribute_length 表示 attribute 所包含的字节数，不包含 attribute_name_index 和 attribute_length 字段 max_stack 表示这个方法运行的任何时刻所能达到的操作数栈的最大深度 max_locals 表示方法执行期间创建的局部变量的数目，包含用来表示传入的参数的局部变量 code_length 表示该方法所包含的字节码的字节数以及具体的指令码，具体字节码即是该方法被调用时，虚拟机所执行的字节码 exception_table 表示存放的是处理异常的信息 每个 exception_table 表由 start_pc，end_pc，handler_pc，catch_type 组成 start_pc 和 end_pc 表示在 code 数组中的从 start_pc 到 end_pc 处（包含 start_pc，不包含 end_pc）的指令抛出的异常会由这个表项来处理 handler_pc 表示处理异常的代码的开始处，catch_type 表示会被处理的异常类型，它指向常量池中的一个异常类，当 catch_type 为 0 时，表示处理所有的异常 字节码查看工具https://github.com/ingokegel/jclasslib]]></content>
      <categories>
        <category>深入理解Java虚拟机</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解Java虚拟机（二）]]></title>
    <url>%2F2019%2F01%2F29%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[ClassLoader文档：https://docs.oracle.com/javase/7/docs/api/java/lang/ClassLoader.html public abstract class ClassLoader extends Object A class loader is an object that is responsible for loading classes. The class ClassLoader is an abstract class. Given the binary name of a class, a class loader should attempt to locate or generate data that constitutes a definition for the class. A typical strategy is to transform the name into a file name and then read a “class file” of that name from a file system. Every Class object contains a reference) to the ClassLoader that defined it. Class objects for array classes are not created by class loaders, but are created automatically as required by the Java runtime. The class loader for an array class, as returned by Class.getClassLoader()) is the same as the class loader for its element type; if the element type is a primitive type, then the array class has no class loader. Applications implement subclasses of ClassLoader in order to extend the manner in which the Java virtual machine dynamically loads classes. Class loaders may typically be used by security managers to indicate security domains. The ClassLoader class uses a delegation model to search for classes and resources. Each instance of ClassLoader has an associated parent class loader. When requested to find a class or resource, a ClassLoader instance will delegate the search for the class or resource to its parent class loader before attempting to find the class or resource itself. The virtual machine’s built-in class loader, called the “bootstrap class loader”, does not itself have a parent but may serve as the parent of a ClassLoader instance. Class loaders that support concurrent loading of classes are known as parallel capable class loaders and are required to register themselves at their class initialization time by invoking the ClassLoader.registerAsParallelCapable) method. Note that the ClassLoader class is registered as parallel capable by default. However, its subclasses still need to register themselves if they are parallel capable. In environments in which the delegation model is not strictly hierarchical, class loaders need to be parallel capable, otherwise class loading can lead to deadlocks because the loader lock is held for the duration of the class loading process (see loadClass) methods). Normally, the Java virtual machine loads classes from the local file system in a platform-dependent manner. For example, on UNIX systems, the virtual machine loads classes from the directory defined by the CLASSPATH environment variable. However, some classes may not originate from a file; they may originate from other sources, such as the network, or they could be constructed by an application. The method defineClass) converts an array of bytes into an instance of class Class. Instances of this newly defined class can be created using Class.newInstance). The methods and constructors of objects created by a class loader may reference other classes. To determine the class(es) referred to, the Java virtual machine invokes the loadClass) method of the class loader that originally created the class. For example, an application could create a network class loader to download class files from a server. Sample code might look like: 1234&gt; ClassLoader loader = new NetworkClassLoader(host, port);&gt; Object main = loader.loadClass(&quot;Main&quot;, true).newInstance();&gt; . . .&gt; &gt; The network class loader subclass must define the methods findClass) and loadClassData to load a class from the network. Once it has downloaded the bytes that make up the class, it should use the method defineClass) to create a class instance. A sample implementation is: 123456789101112131415&gt; class NetworkClassLoader extends ClassLoader &#123;&gt; String host;&gt; int port;&gt; &gt; public Class findClass(String name) &#123;&gt; byte[] b = loadClassData(name);&gt; return defineClass(name, b, 0, b.length);&gt; &#125;&gt; &gt; private byte[] loadClassData(String name) &#123;&gt; // load the class data from the connection&gt; . . .&gt; &#125;&gt; &#125;&gt; &gt; Binary names Any class name provided as a String parameter to methods in ClassLoader must be a binary name as defined by The Java™ Language Specification. Examples of valid class names include: 12345&gt; &quot;java.lang.String&quot; // 一个类&gt; &quot;javax.swing.JSpinner$DefaultEditor&quot; // 一个内部类&gt; &quot;java.security.KeyStore$Builder$FileBuilder$1&quot; // 内部类的匿名类&gt; &quot;java.net.URLClassLoader$3$1&quot; // 匿名类的匿名类&gt; 我们知道类的加载是双亲委派机制，我们先来看一个例子 12345678910public class MyTest15 &#123; public static void main(String[] args) &#123; ClassLoader loader = MyTest15.class.getClassLoader(); System.out.println(loader); ClassLoader loader1 = loader.getParent(); System.out.println(loader1); ClassLoader loader2 = loader1.getParent(); System.out.println(loader2); &#125;&#125; 输出 123sun.misc.Launcher$AppClassLoader@dad5dcsun.misc.Launcher$ExtClassLoader@16d3586null 当为根加载器时，返回null 看了文档，写一个自定义 ClassLoader 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * @Author: cuzz * @Date: 2019/1/28 12:39 * @Description: */public class MyClassLoader extends ClassLoader&#123; private String classLoaderName; private final String fileExtension = ".class"; public MyClassLoader(String classLoaderName) &#123; super(); // 将系统类加载当做该类加载器的父加载器 this.classLoaderName = classLoaderName; &#125; public MyClassLoader(ClassLoader parent, String classLoaderName) &#123; super(parent); // 显示指定该类加载的父加载器 this.classLoaderName = classLoaderName; &#125; @Override protected Class&lt;?&gt; findClass(String className) throws ClassNotFoundException &#123; byte[] data = loadClassData(className); return defineClass(className, data,0, data.length); &#125; private byte[] loadClassData(String name) &#123; InputStream is = null; byte[] data = null; ByteArrayOutputStream baos = null; try &#123; this.classLoaderName = this.classLoaderName.replace(".", "/"); is = new FileInputStream(new File(name, this.fileExtension)); baos = new ByteArrayOutputStream(); int ch; while (-1 != (ch = is.read())) &#123; baos.write(ch); &#125; data = baos.toByteArray(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; is.close(); baos.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; return data; &#125; public static void main(String[] args) throws Exception&#123; MyClassLoader myClassLoader = new MyClassLoader("myLoader"); Class&lt;?&gt; clazz = myClassLoader.loadClass("com.cuzz.jvm.classloader.MyTest01"); Object o = clazz.newInstance(); // 获取实例对象 System.out.println("类加载器：" + clazz.getClassLoader()); System.out.println(o); &#125;&#125; 输出 12类加载器：sun.misc.Launcher$AppClassLoader@dad5dccom.cuzz.jvm.classloader.MyTest01@16d3586 我们编写的类加载器不起作用，因为双亲委派机制，当我们尝试使用自己编写的类加载器去加载时，它会委派自己的双亲去加载，刚好系统类加载器（应用类加载器）就能加载，所以不会使用我们自己编写的类加载器，而使用系统类加载器 如果我们把路径换一下，把项目路径下 classes 中的 MyTest01.class 文件移动在别的地方，让系统类加载器找不到，然后它就会调用我们自己编写的类加载器加载 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class MyClassLoader extends ClassLoader&#123; private String classLoaderName; private final String fileExtension = ".class"; private String path; public MyClassLoader(String classLoaderName) &#123; super(); // 将系统类加载当做该类加载器的父加载器 this.classLoaderName = classLoaderName; &#125; public MyClassLoader(ClassLoader parent, String classLoaderName) &#123; super(parent); // 显示指定该类加载的父加载器 this.classLoaderName = classLoaderName; &#125; public void setPath(String path) &#123; this.path = path; &#125; @Override protected Class&lt;?&gt; findClass(String className) throws ClassNotFoundException &#123; byte[] data = loadClassData(className); return defineClass(className, data,0, data.length); &#125; private byte[] loadClassData(String name) &#123; InputStream is = null; byte[] data = null; ByteArrayOutputStream baos = null; name = name.replace(".", "\\"); try &#123; is = new FileInputStream(new File(this.path + name + this.fileExtension)); baos = new ByteArrayOutputStream(); int ch; while (-1 != (ch = is.read())) &#123; baos.write(ch); &#125; data = baos.toByteArray(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; is.close(); baos.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; return data; &#125; public static void main(String[] args) throws Exception&#123; MyClassLoader myClassLoader = new MyClassLoader("myLoader"); // Class&lt;?&gt; clazz = myClassLoader.loadClass("com.cuzz.jvm.classloader.MyTest01"); String path = "C:/Users/my/Desktop/"; myClassLoader.setPath(path); Class&lt;?&gt; clazz = myClassLoader.loadClass("com.cuzz.jvm.classloader.MyTest01"); Object o = clazz.newInstance(); // 获取实例对象 System.out.println("类加载器：" + clazz.getClassLoader()); System.out.println("父类加载器：" + myClassLoader.getParent()); System.out.println(o); &#125;&#125; 输出 123类加载器：com.cuzz.jvm.classloader.MyClassLoader@16d3586父类加载器：sun.misc.Launcher$AppClassLoader@dad5dccom.cuzz.jvm.classloader.MyTest01@a14482 defineClasjava.lang.ClassLoader#defineClass(java.lang.String, byte[], int, int) 123protected final Class&lt;?&gt; defineClass(String name, byte[] b, int off, int len) throws ClassFormatError &#123; return defineClass(name, b, off, len, null);&#125; 通过一个字节数组返回一个 Class 的实例 loadClassjava.lang.ClassLoader#loadClass(java.lang.String, boolean) 文档： java.lang.ClassLoaderprotected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundExceptionLoads the class with the specified binary name. The default implementation of this method searches for classes in the following order: Invoke findLoadedClass(String) to check if the class has already been loaded. Invoke the loadClass method on the parent class loader. If the parent is null the class loader built-in to the virtual machine is used, instead. Invoke the findClass(String) method to find the class. If the class was found using the above steps, and the resolve flag is true, this method will then invoke the resolveClass(Class) method on the resulting Class object.Subclasses of ClassLoader are encouraged to override findClass(String), rather than this method.Unless overridden, this method synchronizes on the result of getClassLoadingLock method during the entire class loading process.Parameters: name - The binary name of the class resolve - If true then resolve the class 12345678910111213141516171819202122232425262728293031323334353637protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException&#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // 我们只需要重写这个方法就可以 // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125;&#125; 命名空间每一个类加载器斗鱼自己的命名空间，命名空间由该加载器及所有父类加载器所加载的类组成，在同一个命名空间中，不会出现类的完整名字（包括类的包名）相同的两个类，在不同的命名空间中，有可能会出现类的完整名字（包括类的包名）相同的两个类 1234567891011public static void main(String[] args) throws Exception&#123; MyClassLoader myClassLoader = new MyClassLoader("myLoader"); MyClassLoader myClassLoader1 = new MyClassLoader("myLoader1"); String path = "C:/Users/my/Desktop/"; myClassLoader.setPath(path); myClassLoader1.setPath(path); Class&lt;?&gt; clazz = myClassLoader.loadClass("com.cuzz.jvm.classloader.MyTest01"); Class&lt;?&gt; clazz1 = myClassLoader1.loadClass("com.cuzz.jvm.classloader.MyTest01"); System.out.println("clazz: " + clazz.hashCode()); System.out.println("clazz1: " + clazz1.hashCode());&#125; 输出 12clazz: 24324022clazz1: 21685669 说明类被加载了两次，这就是由不同的命名空间导致的 如果我们给 myClassLoader1 添加一个父加载器 123456789101112public static void main(String[] args) throws Exception&#123; MyClassLoader myClassLoader = new MyClassLoader("myLoader"); // 把 myClassLoader 当做父加载器 MyClassLoader myClassLoader1 = new MyClassLoader(myClassLoader,"myLoader1"); String path = "C:/Users/my/Desktop/"; myClassLoader.setPath(path); myClassLoader1.setPath(path); Class&lt;?&gt; clazz = myClassLoader.loadClass("com.cuzz.jvm.classloader.MyTest01"); Class&lt;?&gt; clazz1 = myClassLoader1.loadClass("com.cuzz.jvm.classloader.MyTest01"); System.out.println("clazz: " + clazz.hashCode()); System.out.println("clazz1: " + clazz1.hashCode());&#125; 输出 12clazz: 10568834clazz1: 10568834 由于父加载器已经加载过了，所以就不会加载了 类的卸载由 Java 虚拟机自带的类加载器所加载的类，在虚拟机的生命周期中，始终不会被卸载。前面已经介绍过，Java 虚拟机自带的类加载器包括根类加载器、扩展类加载器和系统类加载器。Java 虚拟机本身会始终引用这些类加载器，而这些类加载器则会始终引用它们所加载类的 Class 对象，因此这些 Class 对象始终是可触及的 而由用户自定义的类加载器所加载的类是可以被卸载的 类加载器命名空间深度解析通过一个例子来分析 MyCat 12345public class MyCat &#123; public MyCat() &#123; System.out.println("MyCat is loaded by: " + this.getClass().getClassLoader()); &#125;&#125; MySample 123456public class MySample &#123; public MySample () &#123; System.out.println("MySample is loaded by:" + this.getClass().getClassLoader()); new MyCat (); &#125;&#125; MyClassLoader 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class MyClassLoader extends ClassLoader&#123; private String classLoaderName; private final String fileExtension = ".class"; private String path; public MyClassLoader(String classLoaderName) &#123; super(); // 将系统类加载当做该类加载器的父加载器 this.classLoaderName = classLoaderName; &#125; public MyClassLoader(ClassLoader parent, String classLoaderName) &#123; super(parent); // 显示指定该类加载的父加载器 this.classLoaderName = classLoaderName; &#125; public void setPath(String path) &#123; this.path = path; &#125; @Override protected Class&lt;?&gt; findClass(String className) throws ClassNotFoundException &#123; byte[] data = loadClassData(className); return defineClass(className, data,0, data.length); &#125; private byte[] loadClassData(String name) &#123; InputStream is = null; byte[] data = null; ByteArrayOutputStream baos = null; name = name.replace(".", "\\"); try &#123; is = new FileInputStream(new File(this.path + name + this.fileExtension)); baos = new ByteArrayOutputStream(); int ch; while (-1 != (ch = is.read())) &#123; baos.write(ch); &#125; data = baos.toByteArray(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; is.close(); baos.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; return data; &#125; public static void main(String[] args) throws Exception&#123; MyClassLoader myClassLoader = new MyClassLoader("myLoader"); String path = "C:/Users/my/Desktop/"; myClassLoader.setPath(path); Class&lt;?&gt; clazz = myClassLoader.loadClass("com.cuzz.jvm.classloader.MySample"); Object object = clazz.newInstance(); &#125;&#125; 输出 12MySample is loaded by: sun.misc.Launcher$AppClassLoader@dad5dcMyCat is loaded by: sun.misc.Launcher$AppClassLoader@dad5dc 我们知道我们自己写的 ClassLoader 与委托父类加载器去加载，所以是系统加载器加载的 现在我们把项目下 classes 路径中的 MySample.class 和 MyCat.class 删除，并复制一份到桌面 则输出 12MySample is loaded by: com.cuzz.jvm.classloader.MyClassLoader@16d3586MyCat is loaded by: com.cuzz.jvm.classloader.MyClassLoader@16d3586 由于委托父类加载器加载不到就用自己加载器加载 如果我们只把当前类路径下 MySample.class 这给文件删掉，保留 MyCat.class 文件，则输出 12MySample is loaded by: com.cuzz.jvm.classloader.MyClassLoader@16d3586MyCat is loaded by: sun.misc.Launcher$AppClassLoader@dad5dc 我们知道 MySample 是我们自定义类加载加载出来的，MyCat 是有系统类加载加载的 1234567public class MySample &#123; public MySample () &#123; System.out.println(&quot;MySample is loaded by: &quot; + this.getClass().getClassLoader()); new MyCat (); System.out.println(MyCat.class); &#125;&#125; 输出 123MySample is loaded by: com.cuzz.jvm.classloader.MyClassLoader@16d3586MyCat is loaded by: sun.misc.Launcher$AppClassLoader@dad5dcclass com.cuzz.jvm.classloader.MyCat 说明自定义类加载加载的类，可以访问系统类加载加载的类 如果我们在系统类加载的类中访问自定义类加载器加载的类 123456public class MyCat &#123; public MyCat() &#123; System.out.println(&quot;MyCat is loaded by: &quot; + this.getClass().getClassLoader()); System.out.println(MySample.class); &#125;&#125; 输出 1234567891011121314151617MySample is loaded by: com.cuzz.jvm.classloader.MyClassLoader@16d3586MyCat is loaded by: sun.misc.Launcher$AppClassLoader@dad5dcException in thread &quot;main&quot; java.lang.NoClassDefFoundError: com/cuzz/jvm/classloader/MySample at com.cuzz.jvm.classloader.MyCat.&lt;init&gt;(MyCat.java:6) at com.cuzz.jvm.classloader.MySample.&lt;init&gt;(MySample.java:6) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:422) at java.lang.Class.newInstance(Class.java:442) at com.cuzz.jvm.classloader.MyClassLoader.main(MyClassLoader.java:68)Caused by: java.lang.ClassNotFoundException: com.cuzz.jvm.classloader.MySample at java.net.URLClassLoader.findClass(URLClassLoader.java:381) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ... 8 more 报错，说明系统加载器加载的类不能访问自定义加载器加载的类 说明当我现在加载 MySample 这个类时，使用的是我们自己定义的类加载器，然后初始实例化这个类时，需要初始化 MyCat 这个类，所以会先委托父加载器（系统加载器）去加载 但是如果我们把当前路径下的 MyCat.class 文件删掉，保留 MySample.class 文件，则报错 123456789101112131415Exception in thread &quot;main&quot; MySample is loaded by: sun.misc.Launcher$AppClassLoader@dad5dcjava.lang.NoClassDefFoundError: com/cuzz/jvm/classloader/MyCat at com.cuzz.jvm.classloader.MySample.&lt;init&gt;(MySample.java:6) at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.lang.reflect.Constructor.newInstance(Constructor.java:422) at java.lang.Class.newInstance(Class.java:442) at com.cuzz.jvm.classloader.MyClassLoader.main(MyClassLoader.java:68)Caused by: java.lang.ClassNotFoundException: com.cuzz.jvm.classloader.MyCat at java.net.URLClassLoader.findClass(URLClassLoader.java:381) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ... 7 more 我要加载 MySample 先委托系统类加载加载，发现能加载到，然后再想加载 MyCat 这个类，此时它会调用系统加载器的父类去加载，发现加载不到，自己也不能加载，就报错了。 通过上面的例子，我们可以得出以下结论： 子类加载器所加载的类能够访问到父加载器所加载的类 父类加载器所加载的类无法访问到子加载器所加载的类 类加载器的双亲委托模型的好处可以确保 Java 核心库的类型安全：所有的 Java 应用都至少会引用 java.lang.Object 类，也就是说在运行期，java.lang.Object 这个类会被加载到 Java 虚拟机中；如果这个加载过程是由 Java 应用自己的类加载所完成的，那么很可能就会在 JVM 中存在多个版本的 java.lang.Object 了，而这些类之间还是不兼容的，相互不可见（正是命名空间发挥着作用）。可以确保 Java 核心类库所提供的类不会被自定义的类所取代。不同的类加载器可以为相同的名称（binary name）的类创建额外的命名空间。相同的名称的类可以并存在 Java 虚拟机中，只要用不同的类加载器来加载它们即可（可是是不同的类加载器，也可以是相同类加载器的不同实例）。不同的类加载器所加载的类之间是不兼容的，就相同于在 Java 虚拟机内部创建了一个又一个相互隔离的 Java 类空间，这类技术在很多框架中都得到了实际的应用。 内建于 JVM 中的启动类加载器会加载 java.lang.ClassLoader 以及其他的 Java 平台类，当 JVM 启动时，一块特殊的机器码会运行，它会加载扩展类加载器和系统类加载器，这块特殊的机器码叫做启动类加载器（Bootstrap），启动类加载器并不是 Java 类，而其它加载器则都是 Java 类，启动类加载器是特定于平台的机器指令，它负责开启整个加载过程。启动类加载器还会负责加载 JRE 正常运行所需要的基本组件，这包括 java.util 与 java.lang 包中的类等等。 Launcher 类源码分析前面我们分析类 ClassLoader，里面有一个静态方法 getSystemClassLoader，发现 ClassLoader 是 Launcher 中一个成员变量 12345678910111213141516171819202122232425262728293031323334353637 @CallerSensitive public static ClassLoader getSystemClassLoader() &#123; initSystemClassLoader(); // 初始化 if (scl == null) &#123; return null; &#125; SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; checkClassLoaderPermission(scl, Reflection.getCallerClass()); &#125; return scl; &#125; private static synchronized void initSystemClassLoader() &#123; if (!sclSet) &#123; if (scl != null) throw new IllegalStateException(&quot;recursive invocation&quot;); // 获取一个 Launcher 类 sun.misc.Launcher l = sun.misc.Launcher.getLauncher(); if (l != null) &#123; Throwable oops = null; // scl 表示 SystemClassLoader scl = l.getClassLoader(); try &#123; scl = AccessController.doPrivileged( new SystemClassLoaderAction(scl)); &#125; catch (PrivilegedActionException pae) &#123; oops = pae.getCause(); if (oops instanceof InvocationTargetException) &#123; oops = oops.getCause(); &#125; &#125; ... &#125; &#125; &#125;&#125; 我们在idea里边看到的 sun.misc.Launcher.getLauncher() 的实现是反编译工具给出的，oracle并没有给出源码，可以到网上查找相关代码 1234567891011121314151617181920212223242526272829303132333435363738394041private static Launcher launcher = new Launcher();private static String bootClassPath = System.getProperty("sun.boot.class.path"); public static Launcher getLauncher() &#123; return launcher; &#125; private ClassLoader loader; public Launcher() &#123; // Create the extension class loader ClassLoader extcl; try &#123; extcl = ExtClassLoader.getExtClassLoader(); &#125; catch (IOException e) &#123; throw new InternalError( "Could not create extension class loader"); &#125; // Now create the class loader to use to launch the application try &#123; loader = AppClassLoader.getAppClassLoader(extcl); &#125; catch (IOException e) &#123; throw new InternalError( "Could not create application class loader"); &#125; // Also set the context class loader for the primordial thread. Thread.currentThread().setContextClassLoader(loader); // Finally, install a security manager if requested String s = System.getProperty("java.security.manager"); ...... &#125; /* * Returns the class loader used to launch the main application. */ public ClassLoader getClassLoader() &#123; return loader; &#125; 可以看到 Launcher 类初始化时，先初始化了个 ExtClassLoader，然后又初始化了个 AppClassLoader，然后把ExtClassLoader 作为 AppClassLoader的父 loader，ExtClassLoader 没有指定父类，即表明，父类是BootstrapClassLoader。把初始化 的AppClassLoader 作为全局变量保存起来，并设置到当前线程contextClassLoader，每个线程实例可以设置一个 contextClassLoader 。 先回到 initSystemClassLoader 方法中，有这一段代码 123456789try &#123; scl = AccessController.doPrivileged( new SystemClassLoaderAction(scl));&#125; catch (PrivilegedActionException pae) &#123; oops = pae.getCause(); if (oops instanceof InvocationTargetException) &#123; oops = oops.getCause(); &#125;&#125; 我们把系统加载传入到 doPrivileged 中的 SystemClassLoaderAction 中又返回了系统加载器，我们看看 SystemClassLoaderAction 这个类 12345678910111213141516171819202122class SystemClassLoaderAction implements PrivilegedExceptionAction&lt;ClassLoader&gt; &#123; private ClassLoader parent; SystemClassLoaderAction(ClassLoader parent) &#123; this.parent = parent; &#125; public ClassLoader run() throws Exception &#123; String cls = System.getProperty("java.system.class.loader"); if (cls == null) &#123; return parent; &#125; Constructor&lt;?&gt; ctor = Class.forName(cls, true, parent) .getDeclaredConstructor(new Class&lt;?&gt;[] &#123; ClassLoader.class &#125;); ClassLoader sys = (ClassLoader) ctor.newInstance( new Object[] &#123; parent &#125;); Thread.currentThread().setContextClassLoader(sys); return sys; &#125;&#125; 这块逻辑的作用是看看是否设置了系统属性 java.system.class.loader，即自定义的系统类加载器，如果设置了那么实例化自定义的系统类加载器返回，替代之前获取的系统类加载器，如果没有设置直接返回默认的系统类加载器。 Class.forName()java.lang.Class#forName(java.lang.String, boolean, java.lang.ClassLoader) 文档： java.lang.Classpublic static Class&lt;?&gt; forName(@NonNls String name, boolean initialize, ClassLoader loader) throws ClassNotFoundExceptionReturns the Class object associated with the class or interface with the given string name, using the given class loader. Given the fully qualified name for a class or interface (in the same format returned by getName) this method attempts to locate, load, and link the class or interface. The specified class loader is used to load the class or interface. If the parameter loader is null, the class is loaded through the bootstrap class loader. The class is initialized only if the initialize parameter is true and if it has not been initialized earlier.If name denotes a primitive type or void, an attempt will be made to locate a user-defined class in the unnamed package whose name is name. Therefore, this method cannot be used to obtain any of the Class objects representing primitive types or void.If name denotes an array class, the component type of the array class is loaded but not initialized.For example, in an instance method the expression:Class.forName(“Foo”)is equivalent to:Class.forName(“Foo”, true, this.getClass().getClassLoader())Note that this method throws errors related to loading, linking or initializing as specified in Sections 12.2, 12.3 and 12.4 of The Java Language Specification. Note that this method does not check whether the requested class is accessible to its caller.If the loader is null, and a security manager is present, and the caller’s class loader is not null, then this method calls the security manager’s checkPermission method with a RuntimePermission(“getClassLoader”) permission to ensure it’s ok to access the bootstrap class loader.Parameters: name - fully qualified name of the desired class initialize - if true the class will be initialized. See Section 12.4 of The Java Language Specification. loader - class loader from which the class must be loaded 代码： 123456789101112131415161718192021public static Class&lt;?&gt; forName(String name, boolean initialize, ClassLoader loader) throws ClassNotFoundException&#123; Class&lt;?&gt; caller = null; SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; // Reflective call to get caller class is only needed if a security manager // is present. Avoid the overhead of making this call otherwise. // 获取调用 forName 方法的的那个类 caller = Reflection.getCallerClass(); if (sun.misc.VM.isSystemDomainLoader(loader)) &#123; ClassLoader ccl = ClassLoader.getClassLoader(caller); if (!sun.misc.VM.isSystemDomainLoader(ccl)) &#123; sm.checkPermission( SecurityConstants.GET_CLASSLOADER_PERMISSION); &#125; &#125; &#125; return forName0(name, initialize, loader, caller);&#125; 线程上下文类加载器分析与实现接下来我们来分析一下线程上下文类加载的作用 前言看一个程序来一下感性的认识： 123456public class MyTest24 &#123; public static void main(String[] args) System.out.println(Thread.currentThread().getContextClassLoader()); System.out.println(Thread.class.getClassLoader()); &#125;&#125; 这个程序的输出是： 12sun.misc.Launcher$AppClassLoader@18b4aac2null 解析：第一行当前的线程是运行MyTest24 的线程，而MyTest24 是由系统类加载器加载，所以打印的是系统类加载器第二行Thread类是java核心库的类，是由启动类加载器加载，所以不打印 null 当前类加载器(Current ClassLoader) 每个类都会使用自己的类加载器(即加载自身的类加载器) 来去加载其他类(指的是所依赖的类) ，如果ClassA引用了ClassY，那么ClassX的类加载器就会加载ClassY（前提是ClassY尚未被加载） 线程上下文加载器（Context ClassLoader）线程上下文类加载器是从jdk1.2开始引入的，类Thread中的 getContextCLassLoader() 与setContextClassLoader(ClassLoader classloader) 分别用来获取和设置上下文类加载器，如果没有通过与setContextClassLoader(ClassLoader classloader)进行设置的话，线程将继承其父线程的上下文类加载器。 Java应用运行时的初始线程的上下文加载器是系统类加载器，在线程中运行的代码可以通过该类加载器来加载类与资源。 我们在使用jdbc的时候，不同的数据库的驱动都是由每个厂商自己去实现，开发者在使用的时候，只需要把驱动jar包 ，放到当前path下边就可以了，这些驱动是由系统类加载器加载，而 java.sql 下边的一些Class在使用的时候不可避免的 ，要去使用厂商自定义的实现的逻辑，但是这些 java.sql 下的类的加载器是由启动类加载器完成的加载，由于父加载器(启动类加载器)加载的类无法访问子加载器（系统类加载器或者应用类加载器）加载的类，所以就无法在有些 java.sql 的类去访问具体的厂商实现，这个是双亲委托模型尴尬的一个局面。 线程上下文加载器的重要性： SPI (Service Provider Interface) 父 ClassLoader 可以使用当前线程 Thread.currentThread().getContextClassLoader() 所指定的 classloader 加载的类。 这就改变了父 ClassLoader 不能使用子 ClassLoader 或是其他没有直接父子关系的 CLassLoader 加载的类的情况，即改变了双亲委托模型。 线程上下文加载器就是当前线程的 Current ClassLoader 在双亲委托模型下，类加载器由下至上的，即下层的类加载器会委托上层进行加载。但是对于 SPI 来说，有些接口是 java 核心库所提供的，而java核心库是由启动类加器来加载的，而这些接口的实现来自于不同的jar包（厂商提供），java 的启动类加载器是不会加载其他来源的jar包，这样传统的双亲委托模型就无法满足SPI的要求，而通过给当前线程设置上下文加载器，就可以设置上下文类加载器来实现对于接口实现类的加载。 线程上下文的一般使用模式线程上下文的一般使用模式分为3步，获取、使用和还原，下面是伪代码 12345678910// 获取ClassLoader classLoader = Thread.currentThread().getContextClassLoader();try &#123; // 使用 Thread.currentThread().setContextClassLoader(targetClassLoader); method();&#125; finally &#123; // 还原 Thread.currentThread().setContextClassLoader(classLoader);&#125; method 里面调用了 Thread.currentThread().getContextClassLoader()，获取当前线程上下文类加载器做某些事情。如果一个类由类加载器 A 加载，那么这个类的依赖也是有相同的类加载器加载的（如果该依赖类之前没有加载过的话），ContextClassLoader 的作用就是为了破坏 Java 的类加载委托机制。 当高层提供了统一的接口让底层去实现，同时又要在高层加载（或实例化）底层类时，就必须要通过线程上下文类加载器来帮助高层的 ClassLoader 找到并加载该类。 ServiceLoader我们先引入驱动依赖 12345678910111213141516group &apos;com.cuzz.jvm&apos;version &apos;1.0&apos;apply plugin: &apos;java&apos;sourceCompatibility = 1.8repositories &#123; mavenCentral()&#125;dependencies &#123; compile ( &quot;mysql:mysql-connector-java:5.1.34&quot; )&#125; 我们先来看一个例子 123456789101112131415161718192021/** * @Author: cuzz * @Date: 2019/2/1 14:46 * @Description: */public class MyTest26 &#123; public static void main(String[] args) &#123; ServiceLoader&lt;Driver&gt; serviceLoader = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; iterator = serviceLoader.iterator(); while(iterator.hasNext())&#123; Driver driver = iterator.next(); System.out.println("driver: "+driver.getClass() + "loader: "+ driver.getClass().getClassLoader() ); &#125; System.out.println("当前线程上下文类加载器: " + Thread.currentThread().getContextClassLoader()); System.out.println("ServiceLoader的类加载器: "+ServiceLoader.class.getClassLoader()); &#125;&#125; 输出 1234driver: class com.mysql.jdbc.Driverloader: sun.misc.Launcher$AppClassLoader@dad5dcdriver: class com.mysql.fabric.jdbc.FabricMySQLDriverloader: sun.misc.Launcher$AppClassLoader@dad5dc当前线程上下文类加载器: sun.misc.Launcher$AppClassLoader@dad5dcServiceLoader的类加载器: null 我们可以看到 ServiceLoader 找到了 mysql 的两个驱动，这两个驱动都是由系统类加载器加载的，当前线程的上下文加载器默认也是系统类加载器，ServiceLoader是由启动类加载器加载，但是程序是怎样找到 mysql 的两个驱动的呢？我们没有在程序里边设置任何的属性或者路径之类的东西让程序能找到 mysql 的驱动，那么我们只能研究一下 ServiceLoader 的源码和文档看一下他们的原理： 1234&gt; public final class ServiceLoader&lt;S&gt;&gt; extends Object&gt; implements Iterable&lt;S&gt;&gt; &gt; A simple service-provider loading facility.A service is a well-known set of interfaces and (usually abstract) classes. A service provider is a specific implementation of a service. The classes in a provider typically implement the interfaces and subclass the classes defined in the service itself. Service providers can be installed in an implementation of the Java platform in the form of extensions, that is, jar files placed into any of the usual extension directories. Providers can also be made available by adding them to the application’s class path or by some other platform-specific means.For the purpose of loading, a service is represented by a single type, that is, a single interface or abstract class. (A concrete class can be used, but this is not recommended.) A provider of a given service contains one or more concrete classes that extend this service type with data and code specific to the provider. The provider class is typically not the entire provider itself but rather a proxy which contains enough information to decide whether the provider is able to satisfy a particular request together with code that can create the actual provider on demand. The details of provider classes tend to be highly service-specific; no single class or interface could possibly unify them, so no such type is defined here. The only requirement enforced by this facility is that provider classes must have a zero-argument constructor so that they can be instantiated during loading.A service provider is identified by placing a provider-configuration file in the resource directory META-INF/services. The file’s name is the fully-qualified binary name of the service’s type. The file contains a list of fully-qualified binary names of concrete provider classes, one per line. Space and tab characters surrounding each name, as well as blank lines, are ignored. The comment character is ‘#’ (‘\u0023’, NUMBER SIGN); on each line all characters following the first comment character are ignored. The file must be encoded in UTF-8.If a particular concrete provider class is named in more than one configuration file, or is named in the same configuration file more than once, then the duplicates are ignored. The configuration file naming a particular provider need not be in the same jar file or other distribution unit as the provider itself. The provider must be accessible from the same class loader that was initially queried to locate the configuration file; note that this is not necessarily the class loader from which the file was actually loaded.Providers are located and instantiated lazily, that is, on demand. A service loader maintains a cache of the providers that have been loaded so far. Each invocation of the iterator method returns an iterator that first yields all of the elements of the cache, in instantiation order, and then lazily locates and instantiates any remaining providers, adding each one to the cache in turn. The cache can be cleared via the reload method.Service loaders always execute in the security context of the caller. Trusted system code should typically invoke the methods in this class, and the methods of the iterators which they return, from within a privileged security context.Instances of this class are not safe for use by multiple concurrent threads.Unless otherwise specified, passing a null argument to any method in this class will cause a NullPointerException to be thrown.Example Suppose we have a service type com.example.CodecSet which is intended to represent sets of encoder/decoder pairs for some protocol. In this case it is an abstract class with two abstract methods: public abstract Encoder getEncoder(String encodingName); public abstract Decoder getDecoder(String encodingName);Each method returns an appropriate object or null if the provider does not support the given encoding. Typical providers support more than one encoding.If com.example.impl.StandardCodecs is an implementation of the CodecSet service then its jar file also contains a file named META-INF/services/com.example.CodecSetThis file contains the single line: com.example.impl.StandardCodecs # Standard codecsThe CodecSet class creates and saves a single service instance at initialization:` 12&gt; private static ServiceLoader&lt;CodecSet&gt; codecSetLoader = ServiceLoader.load(CodecSet.class);&gt; &gt; To locate an encoder for a given encoding name it defines a static factory method which iterates through the known and available providers, returning only when it has located a suitable encoder or has run out of providers. 123456789&gt; public static Encoder getEncoder(String encodingName) &#123;&gt; for (CodecSet cp : codecSetLoader) &gt; Encoder enc = cp.getEncoder(encodingName);&gt; if (enc != null)&gt; return enc;&gt; &#125;&gt; return null;&gt; &#125;&gt; &gt; A getDecoder method is defined similarly.Usage Note If the class path of a class loader that is used for provider loading includes remote network URLs then those URLs will be dereferenced in the process of searching for provider-configuration files.This activity is normal, although it may cause puzzling entries to be created in web-server logs. If a web server is not configured correctly, however, then this activity may cause the provider-loading algorithm to fail spuriously.A web server should return an HTTP 404 (Not Found) response when a requested resource does not exist. Sometimes, however, web servers are erroneously configured to return an HTTP 200 (OK) response along with a helpful HTML error page in such cases. This will cause a ServiceConfigurationError to be thrown when this class attempts to parse the HTML page as a provider-configuration file. The best solution to this problem is to fix the misconfigured web server to return the correct response code (HTTP 404) along with the HTML error page. 我们先看源码 1234567891011121314151617181920public final class ServiceLoader&lt;S&gt; implements Iterable&lt;S&gt; &#123; // 前缀 private static final String PREFIX = "META-INF/services/"; // The class or interface representing the service being loaded private final Class&lt;S&gt; service; // The class loader used to locate, load, and instantiate providers private final ClassLoader loader; // The access control context taken when the ServiceLoader is created private final AccessControlContext acc; // Cached providers, in instantiation order private LinkedHashMap&lt;String,S&gt; providers = new LinkedHashMap&lt;&gt;(); // The current lazy-lookup iterator private LazyIterator lookupIterator; ...&#125; 该类中有个常量 PREFIX ，根据文档我们可以知道这是一个目录，我们看看 mysql-connnector-java 中也有 其下的文件名字就是服务的名字，比如数据库驱动的服务是java.sql.Drive，我们在mysql的jar包下可以看到这个文件，文件里边的内容是具体的实现类的全限定名： 12com.mysql.jdbc.Drivercom.mysql.fabric.jdbc.FabricMySQLDriver 与前面打印出来的驱动是一样的 ServiceLoader 是由启动类加载器加载的，为什么 mysql 的驱动是由系统类加载器加载呢？ 前面代码中 ServiceLoader serviceLoader = ServiceLoader.load(Driver.class); 这段代码是怎么起作用的呢，跟进源码 12345678910public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) &#123; // 获取当前上下文类加载，并使用上下文类加载器去加载 ClassLoader cl = Thread.currentThread().getContextClassLoader(); return ServiceLoader.load(service, cl);&#125;public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service, ClassLoader loader) &#123; // 调用一个构造方法 return new ServiceLoader&lt;&gt;(service, loader);&#125; 既然 ServiceLoader 是由启动类加载器加载，那么 ServiceLoader 里边的类都会用启动类加载器去加载，但是呢我们的 mysql 驱动不在启动类加载器加载的目录下边，我们的 mysql 驱动位于 classpath 下边，无法用启动类加载器加载，这个时候，我们可以看到 load 方法使用了线程上下文加载器，线程上下文加载器默认是系统类加载器 我们来看看这个构造方法 12345678910111213 private ServiceLoader(Class&lt;S&gt; svc, ClassLoader cl) &#123; service = Objects.requireNonNull(svc, "Service interface cannot be null"); loader = (cl == null) ? ClassLoader.getSystemClassLoader() : cl; acc = (System.getSecurityManager() != null) ? AccessController.getContext() : null; reload(); &#125;// 调用reload() 方法 public void reload() &#123; // 清空缓存 providers = new LinkedHashMap&lt;&gt;(); providers.clear(); // 懒加载 lookupIterator = new LazyIterator(service, loader); &#125; LazyIterator 类 java.util.ServiceLoader.LazyIterator 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091private class LazyIterator implements Iterator&lt;S&gt; &#123; Class&lt;S&gt; service; ClassLoader loader; Enumeration&lt;URL&gt; configs = null; Iterator&lt;String&gt; pending = null; String nextName = null; private LazyIterator(Class&lt;S&gt; service, ClassLoader loader) &#123; this.service = service; this.loader = loader; &#125; private boolean hasNextService() &#123; if (nextName != null) &#123; return true; &#125; if (configs == null) &#123; try &#123; String fullName = PREFIX + service.getName(); if (loader == null) configs = ClassLoader.getSystemResources(fullName); else configs = loader.getResources(fullName); &#125; catch (IOException x) &#123; fail(service, "Error locating configuration files", x); &#125; &#125; while ((pending == null) || !pending.hasNext()) &#123; if (!configs.hasMoreElements()) &#123; return false; &#125; pending = parse(service, configs.nextElement()); &#125; nextName = pending.next(); return true; &#125; private S nextService() &#123; if (!hasNextService()) throw new NoSuchElementException(); String cn = nextName; nextName = null; Class&lt;?&gt; c = null; try &#123; c = Class.forName(cn, false, loader); &#125; catch (ClassNotFoundException x) &#123; fail(service, "Provider " + cn + " not found"); &#125; if (!service.isAssignableFrom(c)) &#123; fail(service, "Provider " + cn + " not a subtype"); &#125; try &#123; S p = service.cast(c.newInstance()); providers.put(cn, p); return p; &#125; catch (Throwable x) &#123; fail(service, "Provider " + cn + " could not be instantiated", x); &#125; throw new Error(); // This cannot happen &#125; public boolean hasNext() &#123; if (acc == null) &#123; return hasNextService(); &#125; else &#123; PrivilegedAction&lt;Boolean&gt; action = new PrivilegedAction&lt;Boolean&gt;() &#123; public Boolean run() &#123; return hasNextService(); &#125; &#125;; return AccessController.doPrivileged(action, acc); &#125; &#125; public S next() &#123; if (acc == null) &#123; return nextService(); &#125; else &#123; PrivilegedAction&lt;S&gt; action = new PrivilegedAction&lt;S&gt;() &#123; public S run() &#123; return nextService(); &#125; &#125;; return AccessController.doPrivileged(action, acc); &#125; &#125; public void remove() &#123; throw new UnsupportedOperationException(); &#125;&#125; 这样就把驱动加载出来了，则前面代码输出 1234driver: class com.mysql.jdbc.Driverloader: sun.misc.Launcher$AppClassLoader@dad5dcdriver: class com.mysql.fabric.jdbc.FabricMySQLDriverloader: sun.misc.Launcher$AppClassLoader@dad5dc当前线程上下文类加载器: sun.misc.Launcher$AppClassLoader@dad5dcServiceLoader的类加载器: null 如果我们把前面代码改一下，设置当前线程的上下文类加载器为扩展类加载器 1234567891011121314151617public class MyTest26 &#123; public static void main(String[] args) &#123; // 把当前线程设置为扩展类加载器 Thread.currentThread().setContextClassLoader(MyTest26.class.getClassLoader().getParent()); ServiceLoader&lt;Driver&gt; serviceLoader = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; iterator = serviceLoader.iterator(); while(iterator.hasNext())&#123; Driver driver = iterator.next(); System.out.println("driver: "+driver.getClass() + "loader: "+ driver.getClass().getClassLoader() ); &#125; System.out.println("当前线程上下文类加载器: " + Thread.currentThread().getContextClassLoader()); System.out.println("ServiceLoader的类加载器: "+ServiceLoader.class.getClassLoader()); &#125;&#125; 则输出 12当前线程上下文类加载器: sun.misc.Launcher$ExtClassLoader@a14482ServiceLoader的类加载器: null 可以看到循环没有去执行，上下文类加载器是扩展类加载器没啥问题，因为系统类加载器的上级是扩展类加载器，但是为什么循环是空的呢？原因就是扩展类加载器无法加载 classpath下边的类，mysql 的 jar 包是放在 classpath下边的。 ##]]></content>
      <categories>
        <category>深入理解Java虚拟机</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解Java虚拟机（一）]]></title>
    <url>%2F2019%2F01%2F27%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[类加载机制在 Java 代码中，类型（类，接口，枚举）的加载、连接（验证，准备，解析）与初始化过程都是在程序运行期间完成的，提供了更大的灵活性，增加了更多的可能性 类加载器深入剖析Java 虚拟机与程序的生命周期 在如下几种情况下，Java 虚拟机将结束生命周期 执行了 System.exit() 方法 程序正常执行结束 程序在执行的过程中遇到了异常或则错误而异常终止 由于操作系统出现了错误，导致 Java 虚拟机进程结束 类的加载、连接与初始化 加载：查找并加载类的二进制数据 连接 验证：确保被加载的类的正确性 准备：为类的静态变量分配内存，并将其初始化为默认值 解析：把类中的符号引用转化为直接引用 初始化：为静态变量赋予正确的初始值 使用（类的实例化）： 为新的对象分配内存 为实例变量赋默认值 为实例变量赋予正确的初始值 Java 编译器为它编译的每一个类都至少生成一个实例初始化方法，在 Java 的 class 文件中，这这实例初始方法被称为 &lt;init&gt; ，对源代码中的每一个类的构造方法，java 编译器都产生一个 &lt;init&gt; 方法 Java 程序对类的使用方式可以分为两种： 主动使用 创建类的实例 访问某个类或接口的静态变量，或则对该静态变量赋值 调用类的静态方法 反射（如 Class.forName(&quot;com.cuzz.Test&quot;)） 初始化一个子类 Java 虚拟机启动时被标明为启动类的类 被动使用 所有的 Java 虚拟机实现必须在每个类或接口被 Java 程序首次主动使用时才初始化他们 我们来看一段代码 12345678910111213141516171819public class MyTest01 &#123; public static void main(String[] args) &#123; System.out.println(Child1.str); &#125;&#125;class Parent1 &#123; public static String str = "hello world"; static &#123; System.out.println("Parent1 static block"); &#125;&#125;class Child1 extends Parent1 &#123; static &#123; System.out.println("Child1 static block"); &#125;&#125; 输出 12Parent1 static blockhello world 对于静态代码块，只有定义该字段的类才会被初始化，这个 Child1.str 是子类调用父类的静态字段，所以子类不会被初始化，父类才会被初始化，这是对 Parent1 的主动使用，对于这个例子只是用了 Child1 的名字，并没有主动使用 Child1 这个类 我们在来看看有没有被加载到虚拟机中，在 VM options : -XX:+TraceClassLoading 在运行 1234567...[Loaded com.cuzz.jvm.classloader.Parent1 from file:/E:/project/learn-demo/demo-10-jvm-lecture/out/production/classes/][Loaded com.cuzz.jvm.classloader.Child1 from file:/E:/project/learn-demo/demo-10-jvm-lecture/out/production/classes/]Parent1 static blockhello world[Loaded java.lang.Shutdown from E:\deployer\jdk8\jre\lib\rt.jar][Loaded java.lang.Shutdown$Lock from E:\deployer\jdk8\jre\lib\rt.jar] 发现这两个类已经被加载到虚拟中 再看一个例子 1234567891011121314151617181920public class MyTest01 &#123; public static void main(String[] args) &#123; System.out.println(Child1.str2); &#125;&#125;class Parent1 &#123; public static String str = "hello world"; static &#123; System.out.println("Parent1 static block"); &#125;&#125;class Child1 extends Parent1 &#123; public static String str2 = "welcome"; static &#123; System.out.println("Child1 static block"); &#125;&#125; 输出 123Parent1 static blockChild1 static blockwelcome 当我们初始一个子类，我们会先初始化父类，所以会线输出父类的静态代码块 如果我们加上 final 变为常量 12345678910111213141516/** * @Author: cuzz * @Date: 2019/1/25 19:16 * @Description: */public class MyTest02 &#123; public static void main(String[] args) &#123; System.out.println(Parent2.str); &#125;&#125;class Parent2 &#123; public static final String str = "hello world"; static &#123; System.out.println("Parent2 static block"); &#125;&#125; 输出 1hello world 常量在编译阶段会存入到调用这个常量的方法所在的类的常量池中（也就是说会存入MyTest02这个类中），本质上，调用类并没有直接引用到定义常量的类，因此并不会触发定义常量的类的初始化 注意：这里指的是将常量存放到了 MyTest02 的常量池中，之后 MyTest02 与 Parent2 就没有任何关系了，甚至我们可以将 Parent 的 class 文件删除 我们进入 classes 目录下使用：javap -c com.cuzz.jvm.classloader.MyTest02 命令反编译一下 123456789101112131415Compiled from &quot;MyTest02.java&quot;public class com.cuzz.jvm.classloader.MyTest02 &#123; public com.cuzz.jvm.classloader.MyTest02();// (1) Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public static void main(java.lang.String[]); Code: 0: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #4 (2) // String hello world (3) 5: invokevirtual #5 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return&#125; 是构造方法 ldc 助记符表示将 int，float 或 String 类型的值从常量池中推送至栈顶 可以看出Parent2.str 已经转化为 hello world 注：当 int 取值-1~5采用iconst指令，取值-128~127采用 bipush 指令，取值-32768~32767采用 sipush 指令，取值-2147483648~2147483647采用 ldc 指令 我们在看一个例子 1234567891011public class MyTest03 &#123; public static void main(String[] args) &#123; System.out.println(Parent3.str); &#125;&#125;class Parent3 &#123; public static final String str = UUID.randomUUID().toString(); static &#123; System.out.println("Parent3 static block"); &#125;&#125; 输出 12Parent3 static blockbee2f54d-8960-46d0-b5d7-02666fcf4a14 相比于上一个例子，我们发现输出了静态代码块，说明 Parent3 这个类被初始化了，当一个常量的值并非编译期间可以确定的，那么器值就不会放到调用类的常量池中，这是在程序运行时，会导致主动使用这个常量所在的类，会导致这给类初始化 再看一个例子 123456789101112131415161718public class MyTest04 &#123; public static void main(String[] args) &#123; Parent4[] parent4s = new Parent4[1]; System.out.println("---------"); System.out.println(parent4s.getClass()); System.out.println(parent4s.getClass().getSuperclass()); System.out.println("---------"); int[] ints = new int[1]; System.out.println(ints.getClass()); System.out.println(ints.getClass().getSuperclass()); &#125;&#125;class Parent4 &#123; static &#123; System.out.println("Parent4 static block"); &#125;&#125; 输出 12345678---------class [Lcom.cuzz.jvm.classloader.Parent4;class java.lang.Object---------class [Iclass java.lang.ObjectProcess finished with exit code 0 对于数组实例来说，其类型是由 JVM 在运行期动态生成的，表示为 [Lcom.cuzz.jvm.classloader.Parent4 这种形式，动态生成的类型，其父类型就是 Object 对于数组来说，JavaDoc 经常将构成的数组元素称为 Component，实际上就是将数组降低一个维度的类型 我们使用 javap -c com.cuzz.jvm.classloader.MyTest04 进行反编译 1234567891011121314151617181920212223242526272829303132333435363738394041public class com.cuzz.jvm.classloader.MyTest04 &#123; public com.cuzz.jvm.classloader.MyTest04(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public static void main(java.lang.String[]); Code: 0: iconst_1 1: anewarray #2 // class com/cuzz/jvm/classloader/Parent4 4: astore_1 5: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 8: ldc #4 // String --------- 10: invokevirtual #5 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 13: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 16: aload_1 17: invokevirtual #6 // Method java/lang/Object.getClass:()Ljava/lang/Class; 20: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/Object;)V 23: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 26: aload_1 27: invokevirtual #6 // Method java/lang/Object.getClass:()Ljava/lang/Class; 30: invokevirtual #8 // Method java/lang/Class.getSuperclass:()Ljava/lang/Class; 33: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/Object;)V 36: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 39: ldc #4 // String --------- 41: invokevirtual #5 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 44: iconst_1 45: newarray int 47: astore_2 48: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 51: aload_2 52: invokevirtual #6 // Method java/lang/Object.getClass:()Ljava/lang/Class; 55: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/Object;)V 58: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 61: aload_2 62: invokevirtual #6 // Method java/lang/Object.getClass:()Ljava/lang/Class; 65: invokevirtual #8 // Method java/lang/Class.getSuperclass:()Ljava/lang/Class; 68: invokevirtual #7 // Method java/io/PrintStream.println:(Ljava/lang/Object;)V 71: return&#125; 里面有两个助记符 anewarray ：表示创建一个引用类型的（如类、接口、数组）数组，并将其值压入栈顶 newarray：表示创建一个指定的原始类型（如int、float、char等）数组，并将其引用值压入栈顶 下一个例子 123456789101112public class MyTest05 &#123; public static void main(String[] args) &#123; System.out.println(Child5.j); &#125;&#125;interface Parent5 &#123; int i = 5;&#125;interface Child5 extends Parent5 &#123; int j = 55;&#125; 编译之后我们把 Parent5.class 文件删掉，还能打印出 55，说明当一个接口在初始化时，并不要求其父接口都完成初始化，如果我们把 Child5.class 文件也删掉，也能打印出 55，原来接口中的修饰符默认为 public static final 说明接口中的值是一个常量，不需要加载到 JVM 中，也就没有初始化。 12345678910111213141516public class MyTest05 &#123; public static void main(String[] args) &#123; System.out.println(Child5.j); &#125;&#125;interface Parent5 &#123; public static Thread thread = new Thread() &#123; &#123; System.out.println("Parent5 static block"); &#125; &#125;;&#125;class Child5 implements Parent5 &#123; public static int j = 55;&#125; 此时也也是输出 55 ，也没有初始化 Child5 接口 Parent5 下一例子 12345678910111213141516171819202122232425public class MyTest06 &#123; public static void main(String[] args) &#123; Singleton singleton = Singleton.newSingleton(); System.out.println(Singleton.counter1); System.out.println(Singleton.counter2); &#125;&#125;class Singleton &#123; public static int counter1; private static Singleton singleton = new Singleton(); private Singleton() &#123; counter1++; // counter1 = 1 counter2++; // counter2 = 1 &#125; public static int counter2 = 0; // 此时又把值赋值为 0 public static Singleton newSingleton() &#123; return singleton; &#125;&#125; 此时输出 1210 为什么会这样呢，准备阶段 counter1 和 counter2 的初始值都是 0 ，初始化阶段从上往下赋值，后面 counter2 又赋值为 0 我们再来回顾一下 12345678910111213141516171819202122public class MyTest09 &#123; static &#123; System.out.println("MyTest09 static block"); &#125; public static void main(String[] args) &#123; System.out.println(Child9.j); &#125;&#125;class Parent9 &#123; public static int i = 9; static &#123; System.out.println("Parent9 static block"); &#125;&#125;class Child9 extends Parent9 &#123; public static int j = 99; static &#123; System.out.println("Child9 static block"); &#125;&#125; 输出 1234MyTest09 static blockParent9 static blockChild9 static block99 我们多输出点信息 1234567891011121314151617181920212223242526272829public class MyTest09 &#123; static &#123; System.out.println("MyTest09 static block"); &#125; public static void main(String[] args) &#123; Parent9 parent9; // 不会初始化 System.out.println("-------------"); parent9 = new Parent9(); System.out.println("-------------"); System.out.println(Parent9.i); System.out.println("-------------"); System.out.println(Child9.j); &#125;&#125;class Parent9 &#123; public static int i = 9; static &#123; System.out.println("Parent9 static block"); &#125;&#125;class Child9 extends Parent9 &#123; public static int j = 99; static &#123; System.out.println("Child9 static block"); &#125;&#125; 输出结果 12345678MyTest09 static block-------------Parent9 static block-------------9-------------Child9 static block99 在看一个例子 1234567891011121314public class MyTest12 &#123; public static void main(String[] args) throws Exception&#123; ClassLoader classLoader = ClassLoader.getSystemClassLoader(); Class&lt;?&gt; clazz = classLoader.loadClass("com.cuzz.jvm.classloader.CL"); System.out.println("--------------"); clazz = Class.forName("com.cuzz.jvm.classloader.CL"); &#125;&#125;class CL &#123; static &#123; System.out.println("CL static block"); &#125;&#125; 输出 12--------------CL static block 说明调用 ClassLoader 类的 loadClass 方法加载一个类，并不是对类的主动使用，不会导致类的初始化，而通过 Class.forName 方法是通过反射机制，会对类初始化 类的加载类的加载是指将类的 .class 文件中的二进制数据读入到内存中，将其运行时数据区的方法区内，然后在内存中创建一个 java.lang.Class 对象（规范中并未说明Class对象位于哪里，HotSpot 虚拟机将其放在了方法区中）用来封装类在方法区内的数据结构 加载 .class 文件的方式 从本地系统中直接加载 .class 文件 通过网络下载的 .class 文件 从 zip，jar 等归档文件中加载 .class 文件 从专有数据库中提取 .class 文件 将 Java 源文件动态编译为 .class 文件 类的加载器 类的加载器分类： Java 虚拟机自带的加载器 根加载器（Bootstrap） 拓展类加载器（Extension） 应用加载器（Application） 用户自定义的类加载器 java.lang.ClassLoader 的子类 用户定制类的加载方法 注意：类的加载并不需要等到某个类被首次主动使用时再加载它；JVM 规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载过程中遇到了 .class 文件缺失或存在错误，类加载器必须在程序首次主动使用该类才报告错误，如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误 看一个例子 12345678910111213public class MyTest07 &#123; public static void main(String[] args) throws Exception &#123; Class&lt;?&gt; clazz = Class.forName("java.lang.String"); System.out.println(clazz.getClassLoader()); Class&lt;?&gt; clazz1 = Class.forName("com.cuzz.jvm.classloader.C"); System.out.println(clazz1.getClassLoader()); &#125;&#125;class C &#123; &#125; 输出 12nullsun.misc.Launcher$AppClassLoader@dad5dc 看看 getClassLoader 的文档 Returns the class loader for the class. Some implementations may use null to represent the bootstrap class loader. This method will return null in such implementations if this class was loaded by the bootstrap class loader. 说明输出 null 说明 java.lang.String 是根加载器加载的 获取 ClassLoader 的途径 获得当前类 ClassLoader clazz.getClassLoader() 获得当前线程上下文的 ClassLoader Thread.currentThread().getContextClassLoader() 获取系统的 ClassLoader ClassLoader.getSystemClassLoader() 获取调用者的 ClassLoader DriverManger.getCallerClassLoader() 类的验证类的验证的内容： 类文件的结构检查 语义检查 字节码验证 二进制兼容性的验证 类的初始化时机当 Java 虚拟机在初始化一个类时，要求它的所有父类都已经被初始化，但是这条规则并不适用于接口 在初始化一个类时，并不会先初始化它所实现的接口 在初始化一个接口时，并不会先初始化它的父接口 因此，一个父接口并不会因为它的子接口或者实现类的初始化而初始化，只有当程序首次使用特定接口的静态变量时，才会导致该接口的初始化 JVM参数设置非稳态选项使用说明: -XX:+&lt;option&gt; 启用 option -XX:-&lt;option&gt; 不启用 option -XX:&lt;option&gt;=&lt;number&gt; 设定option的值为数字类型，可跟单位，例如 32k, 1024m, 2g -XX:&lt;option&gt;=&lt;string&gt; 设定option的值为字符串，例如-XX:HeapDumpPath=./dump.core]]></content>
      <categories>
        <category>深入理解Java虚拟机</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Brief History of HTTP]]></title>
    <url>%2F2019%2F01%2F26%2FBrief%20History%20of%20HTTP%2F</url>
    <content type="text"><![CDATA[原文：https://hpbn.co/brief-history-of-http/ The Hypertext Transfer Protocol (HTTP) is one of the most ubiquitous and widely adopted application protocols on the Internet: it is the common language between clients and servers, enabling the modern web. From its simple beginnings as a single keyword and document path, it has become the protocol of choice not just for browsers, but for virtually every Internet-connected software and hardware application. In this chapter, we will take a brief historical tour of the evolution of the HTTP protocol. A full discussion of the varying HTTP semantics is outside the scope of this book, but an understanding of the key design changes of HTTP, and the motivations behind each, will give us the necessary background for our discussions on HTTP performance, especially in the context of the many upcoming improvements in HTTP/2. §HTTP 0.9: The One-Line ProtocolThe original HTTP proposal by Tim Berners-Lee was designed with simplicity in mind as to help with the adoption of his other nascent idea: the World Wide Web. The strategy appears to have worked: aspiring protocol designers, take note. In 1991, Berners-Lee outlined the motivation for the new protocol and listed several high-level design goals: file transfer functionality, ability to request an index search of a hypertext archive, format negotiation, and an ability to refer the client to another server. To prove the theory in action, a simple prototype was built, which implemented a small subset of the proposed functionality: Client request is a single ASCII character string. Client request is terminated by a carriage return (CRLF). Server response is an ASCII character stream. Server response is a hypertext markup language (HTML). Connection is terminated after the document transfer is complete. However, even that sounds a lot more complicated than it really is. What these rules enable is an extremely simple, Telnet-friendly protocol, which some web servers support to this very day: 12345678$&gt; telnet google.com 80Connected to 74.125.xxx.xxxGET /about/(hypertext response)(connection closed) The request consists of a single line: GET method and the path of the requested document. The response is a single hypertext document—no headers or any other metadata, just the HTML. It really couldn’t get any simpler. Further, since the previous interaction is a subset of the intended protocol, it unofficially acquired the HTTP 0.9 label. The rest, as they say, is history. From these humble beginnings in 1991, HTTP took on a life of its own and evolved rapidly over the coming years. Let us quickly recap the features of HTTP 0.9: Client-server, request-response protocol. ASCII protocol, running over a TCP/IP link. Designed to transfer hypertext documents (HTML). The connection between server and client is closed after every request. Note : Popular web servers, such as Apache and Nginx, still support the HTTP 0.9 protocol—in part, because there is not much to it! If you are curious, open up a Telnet session and try accessing google.com, or your own favorite site, via HTTP 0.9 and inspect the behavior and the limitations of this early protocol. §HTTP/1.0: Rapid Growth and Informational RFCThe period from 1991 to 1995 is one of rapid coevolution of the HTML specification, a new breed of software known as a “web browser,” and the emergence and quick growth of the consumer-oriented public Internet infrastructure. §The Perfect Storm: Internet Boom of the Early 1990s Building on Tim Berner-Lee’s initial browser prototype, a team at the National Center of Supercomputing Applications (NCSA) decided to implement their own version. With that, the first popular browser was born: NCSA Mosaic. One of the programmers on the NCSA team, Marc Andreessen, partnered with Jim Clark to found Mosaic Communications in October 1994. The company was later renamed Netscape, and it shipped Netscape Navigator 1.0 in December 1994. By this point, it was already clear that the World Wide Web was bound to be much more than just an academic curiosity. In fact, that same year the first World Wide Web conference was organized in Geneva, Switzerland, which led to the creation of the World Wide Web Consortium (W3C) to help guide the evolution of HTML. Similarly, a parallel HTTP Working Group (HTTP-WG) was established within the IETF to focus on improving the HTTP protocol. Both of these groups continue to be instrumental to the evolution of the Web. Finally, to create the perfect storm, CompuServe, AOL, and Prodigy began providing dial-up Internet access to the public within the same 1994–1995 time frame. Riding on this wave of rapid adoption, Netscape made history with a wildly successful IPO on August 9, 1995—the Internet boom had arrived, and everyone wanted a piece of it! The growing list of desired capabilities of the nascent Web and their use cases on the public Web quickly exposed many of the fundamental limitations of HTTP 0.9: we needed a protocol that could serve more than just hypertext documents, provide richer metadata about the request and the response, enable content negotiation, and more. In turn, the nascent community of web developers responded by producing a large number of experimental HTTP server and client implementations through an ad hoc process: implement, deploy, and see if other people adopt it. From this period of rapid experimentation, a set of best practices and common patterns began to emerge, and in May 1996 the HTTP Working Group (HTTP-WG) published RFC 1945, which documented the “common usage” of the many HTTP/1.0 implementations found in the wild. Note that this was only an informational RFC: HTTP/1.0 as we know it is not a formal specification or an Internet standard! Having said that, an example HTTP/1.0 request should look very familiar: 1234567891011121314151617$&gt; telnet website.org 80Connected to xxx.xxx.xxx.xxxGET /rfc/rfc1945.txt HTTP/1.0 (1)User-Agent: CERN-LineMode/2.15 libwww/2.17b3Accept: */*HTTP/1.0 200 OK (2)Content-Type: text/plainContent-Length: 137582Expires: Thu, 01 Dec 1997 16:00:00 GMTLast-Modified: Wed, 1 May 1996 12:45:26 GMTServer: Apache 0.84(plain-text response)(connection closed) Request line with HTTP version number, followed by request headers Response status, followed by response headers The preceding exchange is not an exhaustive list of HTTP/1.0 capabilities, but it does illustrate some of the key protocol changes: Request may consist of multiple newline separated header fields. Response object is prefixed with a response status line. Response object has its own set of newline separated header fields. Response object is not limited to hypertext. The connection between server and client is closed after every request. Both the request and response headers were kept as ASCII encoded, but the response object itself could be of any type: an HTML file, a plain text file, an image, or any other content type. Hence, the “hypertext transfer” part of HTTP became a misnomer not long after its introduction. In reality, HTTP has quickly evolved to become a hypermedia transport, but the original name stuck. In addition to media type negotiation, the RFC also documented a number of other commonly implemented capabilities: content encoding, character set support, multi-part types, authorization, caching, proxy behaviors, date formats, and more. Note : Almost every server on the Web today can and will still speak HTTP/1.0. Except that, by now, you should know better! Requiring a new TCP connection per request imposes a significant performance penalty on HTTP/1.0; see Three-Way Handshake, followed by Slow-Start. §HTTP/1.1: Internet StandardThe work on turning HTTP into an official IETF Internet standard proceeded in parallel with the documentation effort around HTTP/1.0 and happened over a period of roughly four years: between 1995 and 1999. In fact, the first official HTTP/1.1 standard is defined in RFC 2068, which was officially released in January 1997, roughly six months after the publication of HTTP/1.0. Then, two and a half years later, in June of 1999, a number of improvements and updates were incorporated into the standard and were released as RFC 2616. The HTTP/1.1 standard resolved a lot of the protocol ambiguities found in earlier versions and introduced a number of critical performance optimizations: keepalive connections, chunked encoding transfers, byte-range requests, additional caching mechanisms, transfer encodings, and request pipelining. With these capabilities in place, we can now inspect a typical HTTP/1.1 session as performed by any modern HTTP browser and client: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657$&gt; telnet website.org 80Connected to xxx.xxx.xxx.xxxGET /index.html HTTP/1.1 (1)Host: website.orgUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_4)... (snip)Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Encoding: gzip,deflate,sdchAccept-Language: en-US,en;q=0.8Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.3Cookie: __qca=P0-800083390... (snip)HTTP/1.1 200 OK (2)Server: nginx/1.0.11Connection: keep-aliveContent-Type: text/html; charset=utf-8Via: HTTP/1.1 GWADate: Wed, 25 Jul 2012 20:23:35 GMTExpires: Wed, 25 Jul 2012 20:23:35 GMTCache-Control: max-age=0, no-cacheTransfer-Encoding: chunked100 (3)&lt;!doctype html&gt;(snip)100(snip)0 (4)GET /favicon.ico HTTP/1.1 (5)Host: www.website.orgUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_4)... (snip)Accept: */*Referer: http://website.org/Connection: close (6)Accept-Encoding: gzip,deflate,sdchAccept-Language: en-US,en;q=0.8Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.3Cookie: __qca=P0-800083390... (snip)HTTP/1.1 200 OK (7)Server: nginx/1.0.11Content-Type: image/x-iconContent-Length: 3638Connection: closeLast-Modified: Thu, 19 Jul 2012 17:51:44 GMTCache-Control: max-age=315360000Accept-Ranges: bytesVia: HTTP/1.1 GWADate: Sat, 21 Jul 2012 21:35:22 GMTExpires: Thu, 31 Dec 2037 23:55:55 GMTEtag: W/PSA-GAu26oXbDi(icon data)(connection closed) Request for HTML file, with encoding, charset, and cookie metadata Chunked response for original HTML request Number of octets in the chunk expressed as an ASCII hexadecimal number (256 bytes) End of chunked stream response Request for an icon file made on same TCP connection Inform server that the connection will not be reused Icon response, followed by connection close Phew, there is a lot going on in there! The first and most obvious difference is that we have two object requests, one for an HTML page and one for an image, both delivered over a single connection. This is connection keepalive in action, which allows us to reuse the existing TCP connection for multiple requests to the same host and deliver a much faster end-user experience; see Optimizing for TCP. To terminate the persistent connection, notice that the second client request sends an explicit close token to the server via the Connection header. Similarly, the server can notify the client of the intent to close the current TCP connection once the response is transferred. Technically, either side can terminate the TCP connection without such signal at any point, but clients and servers should provide it whenever possible to enable better connection reuse strategies on both sides. Note : HTTP/1.1 changed the semantics of the HTTP protocol to use connection keepalive by default. Meaning, unless told otherwise (via Connection: close header), the server should keep the connection open by default. However, this same functionality was also backported to HTTP/1.0 and enabled via the Connection: Keep-Alive header. Hence, if you are using HTTP/1.1, technically you don’t need the Connection: Keep-Alive header, but many clients choose to provide it nonetheless. Additionally, the HTTP/1.1 protocol added content, encoding, character set, and even language negotiation, transfer encoding, caching directives, client cookies, plus a dozen other capabilities that can be negotiated on each request. We are not going to dwell on the semantics of every HTTP/1.1 feature. This is a subject for a dedicated book, and many great ones have been written already. Instead, the previous example serves as a good illustration of both the quick progress and evolution of HTTP, as well as the intricate and complicated dance of every client-server exchange. There is a lot going on in there! Note : For a good reference on all the inner workings of the HTTP protocol, check out O’Reilly’s HTTP: The Definitive Guide by David Gourley and Brian Totty. §HTTP/2: Improving Transport PerformanceSince its publication, RFC 2616 has served as a foundation for the unprecedented growth of the Internet: billions of devices of all shapes and sizes, from desktop computers to the tiny web devices in our pockets, speak HTTP every day to deliver news, video, and millions of other web applications we have all come to depend on in our lives. What began as a simple, one-line protocol for retrieving hypertext quickly evolved into a generic hypermedia transport, and now a decade later can be used to power just about any use case you can imagine. Both the ubiquity of servers that can speak the protocol and the wide availability of clients to consume it means that many applications are now designed and deployed exclusively on top of HTTP. Need a protocol to control your coffee pot? RFC 2324 has you covered with the Hyper Text Coffee Pot Control Protocol (HTCPCP/1.0)—originally an April Fools’ Day joke by IETF, and increasingly anything but a joke in our new hyper-connected world. The Hypertext Transfer Protocol (HTTP) is an application-level protocol for distributed, collaborative, hypermedia information systems. It is a generic, stateless, protocol that can be used for many tasks beyond its use for hypertext, such as name servers and distributed object management systems, through extension of its request methods, error codes and headers. A feature of HTTP is the typing and negotiation of data representation, allowing systems to be built independently of the data being transferred. RFC 2616: HTTP/1.1, June 1999 The simplicity of the HTTP protocol is what enabled its original adoption and rapid growth. In fact, it is now not unusual to find embedded devices—sensors, actuators, and coffee pots alike—using HTTP as their primary control and data protocols. But under the weight of its own success and as we increasingly continue to migrate our everyday interactions to the Web—social, email, news, and video, and increasingly our entire personal and job workspaces—it has also begun to show signs of stress. Users and web developers alike are now demanding near real-time responsiveness and protocol performance from HTTP/1.1, which it simply cannot meet without some modifications. To meet these new challenges, HTTP must continue to evolve, and hence the HTTPbis working group announced a new initiative for HTTP/2 in early 2012: There is emerging implementation experience and interest in a protocol that retains the semantics of HTTP without the legacy of HTTP/1.x message framing and syntax, which have been identified as hampering performance and encouraging misuse of the underlying transport. The working group will produce a specification of a new expression of HTTP’s current semantics in ordered, bi-directional streams. As with HTTP/1.x, the primary target transport is TCP, but it should be possible to use other transports. HTTP/2 charter, January 2012 The primary focus of HTTP/2 is on improving transport performance and enabling both lower latency and higher throughput. The major version increment sounds like a big step, which it is and will be as far as performance is concerned, but it is important to note that none of the high-level protocol semantics are affected: all HTTP headers, values, and use cases are the same. Any existing website or application can and will be delivered over HTTP/2 without modification: you do not need to modify your application markup to take advantage of HTTP/2. The HTTP servers will have to speak HTTP/2, but that should be a transparent upgrade for the majority of users. The only difference if the working group meets its goal, should be that our applications are delivered with lower latency and better utilization of the network link! Having said that, let’s not get ahead of ourselves. Before we get to the new HTTP/2 protocol features, it is worth taking a step back and examining our existing deployment and performance best practices for HTTP/1.1. The HTTP/2 working group is making fast progress on the new specification, but even if the final standard was already done and ready, we would still have to support older HTTP/1.1 clients for the foreseeable future—realistically, a decade or more.]]></content>
      <categories>
        <category>HTTP</category>
      </categories>
      <tags>
        <tag>英文</tag>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty 源码分析（五）]]></title>
    <url>%2F2019%2F01%2F22%2FNetty%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%BA%94%EF%BC%89%2F</url>
    <content type="text"><![CDATA[版本 4.1.15 官网：https://netty.io/ Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. ReferenceCountedio.netty.util.ReferenceCounted 引用计数文档 public interface ReferenceCountedA reference-counted object that requires explicit deallocation.When a new ReferenceCounted is instantiated, it starts with the reference count of 1. retain() increases the reference count, and release() decreases the reference count. If the reference count is decreased to 0, the object will be deallocated explicitly, and accessing the deallocated object will usually result in an access violation.If an object that implements ReferenceCounted is a container of other objects that implement ReferenceCounted, the contained objects will also be released via release() when the container’s reference count becomes 0. 我们看看其中的方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public interface ReferenceCounted &#123; /** * Returns the reference count of this object. If &#123;@code 0&#125;, it means this object has been deallocated. */ int refCnt(); /** * Increases the reference count by &#123;@code 1&#125;. */ ReferenceCounted retain(); /** * Increases the reference count by the specified &#123;@code increment&#125;. */ ReferenceCounted retain(int increment); /** * Records the current access location of this object for debugging purposes. * If this object is determined to be leaked, the information recorded by this operation will be provided to you * via &#123;@link ResourceLeakDetector&#125;. This method is a shortcut to &#123;@link #touch(Object) touch(null)&#125;. */ ReferenceCounted touch(); /** * Records the current access location of this object with an additional arbitrary information for debugging * purposes. If this object is determined to be leaked, the information recorded by this operation will be * provided to you via &#123;@link ResourceLeakDetector&#125;. */ ReferenceCounted touch(Object hint); /** * Decreases the reference count by &#123;@code 1&#125; and deallocates this object if the reference count reaches at * &#123;@code 0&#125;. * * @return &#123;@code true&#125; if and only if the reference count became &#123;@code 0&#125; and this object has been deallocated */ boolean release(); /** * Decreases the reference count by the specified &#123;@code decrement&#125; and deallocates this object if the reference * count reaches at &#123;@code 0&#125;. * * @return &#123;@code true&#125; if and only if the reference count became &#123;@code 0&#125; and this object has been deallocated */ boolean release(int decrement);&#125; AbstractReferenceCountedByteBufio.netty.buffer.AbstractReferenceCountedByteBuf 我们先来看两个比较重要的方法，retain() 和 release() 方法 retain()io.netty.buffer.AbstractReferenceCountedByteBuf#retain() retain() 方法可以使引用计数加一 1234567891011121314151617181920212223242526@Overridepublic ByteBuf retain() &#123; return retain0(1);&#125;@Overridepublic ByteBuf retain(int increment) &#123; return retain0(checkPositive(increment, "increment"));&#125;private ByteBuf retain0(int increment) &#123; for (;;) &#123; int refCnt = this.refCnt; final int nextCnt = refCnt + increment; // 如果 refCnt = 0 的时候 nextCont = increment，就就应该被回收 // Ensure we not resurrect (which means the refCnt was 0) and also that we encountered an overflow. if (nextCnt &lt;= increment) &#123; throw new IllegalReferenceCountException(refCnt, increment); &#125; // 这里使用到了自旋锁 if (refCntUpdater.compareAndSet(this, refCnt, nextCnt)) &#123; break; &#125; &#125; return this;&#125; java.util.concurrent.atomic.AtomicIntegerFieldUpdater public abstract class AtomicIntegerFieldUpdaterextends ObjectA reflection-based utility that enables atomic updates to designated volatile int fields of designated classes. This class is designed for use in atomic data structures in which several fields of the same node are independently subject to atomic updates.Note that the guarantees of the compareAndSet method in this class are weaker than in other atomic classes. Because this class cannot ensure that all uses of the field are appropriate for purposes of atomic access, it can guarantee atomicity only with respect to other invocations of compareAndSet and set on the same updater. AtomicIntegerFieldUpdater要点的总结： 更新器必须是int类型的变量，不能是其他包装类型 更新器的更新必须是volatile类型的变量，确保线程之间的共享变量时的立即可见性 变量不能是static的，必须是实例变量，因为Unsafe.objectFieldOffset() 方法不支持静态变量（CAS操作本质是通过对象实例的偏移来直接进行赋值） 更新器只能修改它可见范围内的变量，因为更新器是通过反射来得到这个变量，如果变量不可见就会报错 如果更新的变量时包装类型，那么可以使用AtomicReferenceFieldUpdater来进行更新 java.util.concurrent.atomic.AtomicIntegerFieldUpdater#compareAndSet public abstract boolean compareAndSet(T obj, int expect, int update)Atomically sets the field of the given object managed by this updater to the given updated value if the current value == the expected value. This method is guaranteed to be atomic with respect to other calls to compareAndSet and set, but not necessarily with respect to other changes in the field.Parameters:obj - An object whose field to conditionally setexpect - the expected valueupdate - the new value 一个不安全的更新 123456789101112131415161718192021222324/** * @Author: cuzz * @Date: 2019/1/19 15:40 * @Description: */public class AtomicUpdateTest &#123; public static void main(String[] args) &#123; Person person = new Person(); for (int i = 0; i &lt; 10; i++) &#123; new Thread(() -&gt; &#123; try &#123; Thread.sleep(20); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.print(person.age++ + " "); // 1 6 7 5 4 2 3 1 8 9 &#125;).start(); &#125; &#125;&#125;class Person&#123; int age = 1;&#125; 使用AtomicIntegerFieldUpdater 123456789101112131415161718192021222324/** * @Author: cuzz * @Date: 2019/1/19 15:40 * @Description: */public class AtomicUpdateTest &#123; public static void main(String[] args) &#123; AtomicIntegerFieldUpdater&lt;Person&gt; fieldUpdater = AtomicIntegerFieldUpdater.newUpdater(Person.class, "age"); Person person = new Person(); for (int i = 0; i &lt; 10; i++) &#123; new Thread(() -&gt; &#123; try &#123; Thread.sleep(20); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.print(fieldUpdater.getAndIncrement(person) + " "); // 1 4 3 2 5 6 7 10 9 8 &#125;).start(); &#125; &#125;&#125;class Person&#123; volatile int age = 1;&#125; 大概有以下两种字段适合用Atomic*FieldUpdater: 大多数用到这个字段的代码是在读取字段的值, 但仍然有通过CAS更新字段值的需求. 这个时候用AtomicInteger的话每个直接读取这个字段的地方都要多一次.get()调用, 用volatile又满足不了需求, 所以就用到了AtomicIntegerFieldUpdater 这个字段所属的类会被创建大量的实例对象, 如果用AtomicInteger, 每个实例里面都要创建AtomicInteger对象, 从而多出内存消耗. 比如一个链表类的Node, 用AtomicReference保存next显然是不合适的. 原文：https://blog.csdn.net/u012415542/article/details/80646605 12private static final AtomicIntegerFieldUpdater&lt;AbstractReferenceCountedByteBuf&gt; refCntUpdater = AtomicIntegerFieldUpdater.newUpdater(AbstractReferenceCountedByteBuf.class, "refCnt"); Reference counted objects引用计数文档：Reference counted objects Netty 处理器重要概念 Netty 的处理器可以分为两类：入站处理器和出站处理器 入站处理器的顶层是 ChannelnboundHandler，出站处理器的顶层是 ChannelOutboundHandler 数据处理时常用的各种解码器本质上都是处理器 编解码器：无论我们向网络中写入的数据是什么类型，数据在网络中传递时，其都是以字节流的形式呈现，将数据有原本的字节流的操作成为编码（encode），将数据有字节转化为它原本的格式或是其它的操作成为解码（decode），编码统一称为（codec） 编码：本质上是一种出站处理器，因此，编码一定是一种 ChannelOutboundHandler 解码：本质上是一种入站处理器，因此，解码一定是一种 ChannelInboundHandler 在 Netty 中，编码器通常以 xxxEncoder命名；解码器通常以xxxDecoder命名 编写一个Long类型的解码器编写一个解码器在客服端与服务端传输一个 Long 型的数据，Netty 为我们提供了 ByteToMessageDecoder io.netty.handler.codec.ByteToMessageDecoder io.netty.handler.codecpublic abstract class ByteToMessageDecoderextends ChannelInboundHandlerAdapterChannelInboundHandlerAdapter which decodes bytes in a stream-like fashion from one ByteBuf to an other Message type. For example here is an implementation which reads all readable bytes from the input ByteBuf and create a new ByteBuf. public class SquareDecoder extends ByteToMessageDecoder { @Override public void decode(ChannelHandlerContext ctx, ByteBuf in, List out) throws Exception { out.add(in.readBytes(in.readableBytes())); } } Frame detectionGenerally frame detection should be handled earlier in the pipeline by adding a DelimiterBasedFrameDecoder, FixedLengthFrameDecoder, LengthFieldBasedFrameDecoder, or LineBasedFrameDecoder.If a custom frame decoder is required, then one needs to be careful when implementing one with ByteToMessageDecoder. Ensure there are enough bytes in the buffer for a complete frame by checking ByteBuf.readableBytes(). If there are not enough bytes for a complete frame, return without modifying the reader index to allow more bytes to arrive.To check for complete frames without modifying the reader index, use methods like ByteBuf.getInt(int). One MUST use the reader index when using methods like ByteBuf.getInt(int). For example calling in.getInt(0) is assuming the frame starts at the beginning of the buffer, which is not always the case. Use in.getInt(in.readerIndex()) instead.PitfallsBe aware that sub-classes of ByteToMessageDecoder MUST NOT annotated with @Sharable.Some methods such as ByteBuf.readBytes(int) will cause a memory leak if the returned buffer is not released or added to the out List. Use derived buffers like ByteBuf.readSlice(int) to avoid leaking memory. MyByteToLongDecoder 123456789101112131415/** * @Author: cuzz * @Date: 2019/1/22 12:16 * @Description: */public class MyByteToLongDecoder extends ByteToMessageDecoder&#123; @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; System.out.println("decode invoked!"); System.out.println(in.readableBytes()); if (in.readableBytes() &gt;= 8) &#123; out.add(in.readLong()); &#125; &#125;&#125; MyLongToByteEncoder 12345678910111213/** * @Author: cuzz * @Date: 2019/1/22 12:23 * @Description: */public class MyLongToByteEncoder extends MessageToByteEncoder&lt;Long&gt;&#123; @Override protected void encode(ChannelHandlerContext ctx, Long msg, ByteBuf out) throws Exception &#123; System.out.println("encoder invoked!"); System.out.println(msg); out.writeLong(msg); &#125;&#125; 重要结论： 无论是编码器还是解码器，其所接收的消息类型必须要与待处理的参数保持一致，否则该编码器或则解码器不会被执行 在解码器进行数据解码时，一定要记得判断缓冲（ByteBuf）中的数据是否足够，否则将会产生一些问题 ReplayingDecoder文档：https://netty.io/4.1/api/io/netty/handler/codec/ReplayingDecoder.html 如果我们使用这个继承这个编码器，他会自动帮我判断是否可读，代码也简单，简化了我们的判断 12345678public class MyByteToLongDecoder2 extends ReplayingDecoder&lt;Void&gt; &#123; @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; System.out.println("MyByteToLongDecoder2 decode invoked!"); out.add(in.readLong()); &#125;&#125; LengthFieldBasedFrameDecoderio.netty.handler.codec.LengthFieldBasedFrameDecoder 文档：https://netty.io/4.1/api/io/netty/handler/codec/LengthFieldBasedFrameDecoder.html 这是一个常用语自定义协议的解码器 TCP 粘包拆包如果我写的自定义协议没有对粘包和拆包做特殊处理的话就会产生粘包和拆包现象 粘包、拆包发生原因发生TCP粘包或拆包有很多原因，现列出常见的几点，可能不全面，欢迎补充，1、要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包。2、待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。3、要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包。4、接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。粘包、拆包解决办法通过以上分析，我们清楚了粘包或拆包发生的原因，那么如何解决这个问题呢？解决问题的关键在于如何给每个数据包添加边界信息，常用的方法有如下几个：1、发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。2、发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。3、可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。 作者：wxy941011来源：CSDN原文：https://blog.csdn.net/wxy941011/article/details/80428470版权声明：本文为博主原创文章，转载请附上博文链接！ 自定义协议解决粘包和拆包一个 Person 协议类 123456789101112131415161718192021222324252627/** * @Author: cuzz * @Date: 2019/1/22 16:00 * @Description: 这是一个关于 Person 的协议 */public class PersonProtocol &#123; private int length; private byte[] content; public int getLength() &#123; return length; &#125; public void setLength(int length) &#123; this.length = length; &#125; public byte[] getContent() &#123; return content; &#125; public void setContent(byte[] content) &#123; this.content = content; &#125;&#125; 解码处理器 1234567891011121314151617181920212223242526/** * @Author: cuzz * @Date: 2019/1/22 16:04 * @Description: */public class MyPersonDecoder extends ReplayingDecoder&lt;Void&gt;&#123; @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; System.out.println("MyPersonDecoder decode invoked!"); // Gets a 32-bit integer at the current &#123;@code readerIndex&#125; // and increases the &#123;@code readerIndex&#125; by &#123;@code 4&#125; in this buffer. int length = in.readInt(); byte[] content = new byte[length]; // Transfers this buffer's data to the specified destination starting at // the current &#123;@code readerIndex&#125; and increases the &#123;@code readerIndex&#125; // by the number of the transferred bytes (= &#123;@code dst.length&#125; in.readBytes(content); // 把内容添加到协议中 PersonProtocol personProtocol = new PersonProtocol(); personProtocol.setLength(length); personProtocol.setContent(content); out.add(personProtocol); &#125;&#125; 编码处理器 12345678910111213141516/** * @Author: cuzz * @Date: 2019/1/22 16:12 * @Description: */public class MyPersonEncoder extends MessageToByteEncoder&lt;PersonProtocol&gt;&#123; @Override protected void encode(ChannelHandlerContext ctx, PersonProtocol msg, ByteBuf out) throws Exception &#123; System.out.println("MyPersonEncoder encoder invoked!"); // 消息头 out.writeInt(msg.getLength()); // 消息体 out.writeBytes(msg.getContent()); &#125;&#125; 服务端 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * @Author: cuzz * @Date: 2019/1/22 16:39 * @Description: */public class MyServer &#123; public static void main(String[] args) throws Exception&#123; EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workGroup = new NioEventLoopGroup(); try &#123; ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new MyPersonDecoder()); pipeline.addLast(new MyPersonEncoder()); pipeline.addLast(new MyServerHandler()); &#125; &#125;); ChannelFuture channelFuture = serverBootstrap.bind(8899).sync(); channelFuture.channel().closeFuture().sync(); &#125; finally &#123; bossGroup.shutdownGracefully(); workGroup.shutdownGracefully(); &#125; &#125;&#125;/** * @Author: cuzz * @Date: 2019/1/22 16:16 * @Description: */public class MyServerHandler extends SimpleChannelInboundHandler&lt;PersonProtocol&gt;&#123; private int count; @Override protected void channelRead0(ChannelHandlerContext ctx, PersonProtocol msg) throws Exception &#123; int length = msg.getLength(); byte[] content = msg.getContent(); System.out.println("服务端接收到的数据："); System.out.println("长度：" + length); System.out.println("内容：" + new String(content, Charset.forName("utf-8"))); System.out.println("服务器接收到的消息数量：" + (++this.count)); PersonProtocol personProtocol = new PersonProtocol(); String resp = "hello, world"; personProtocol.setLength(resp.getBytes("utf-8").length); personProtocol.setContent(resp.getBytes("utf-8")); ctx.writeAndFlush(personProtocol); &#125;&#125; 客服端 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class MyClient &#123; public static void main(String[] args) throws Exception &#123; EventLoopGroup eventLoopGroup = new NioEventLoopGroup(); try &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.group(eventLoopGroup) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new MyPersonDecoder()); pipeline.addLast(new MyPersonEncoder()); pipeline.addLast(new MyClientHandler()); &#125; &#125;); ChannelFuture channelFuture = bootstrap.connect("localhost",8899).sync(); channelFuture.channel().closeFuture().sync(); &#125; finally &#123; eventLoopGroup.shutdownGracefully(); &#125; &#125;&#125;/** * @Author: cuzz * @Date: 2019/1/22 16:25 * @Description: */public class MyClientHandler extends SimpleChannelInboundHandler&lt;PersonProtocol&gt;&#123; private int count; @Override protected void channelRead0(ChannelHandlerContext ctx, PersonProtocol msg) throws Exception &#123; int length = msg.getLength(); byte[] content = msg.getContent(); System.out.println("客户端接收的消息："); System.out.println("消息的长度：" + length); System.out.println("消息的内容：" + new String(content, Charset.forName("utf-8"))); System.out.println("客户端接收到的消息数量：" + (++count)); &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; for (int i = 0; i &lt; 10; i++) &#123; String messageToBeSend = "send form client"; PersonProtocol personProtocol = new PersonProtocol(); personProtocol.setLength(messageToBeSend.getBytes("utf-8").length); personProtocol.setContent(messageToBeSend.getBytes("utf-8")); ctx.writeAndFlush(personProtocol); &#125; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 总结这里关于 Netty 的这五篇分析都是看的圣思园张龙老师的课程自己所写下的笔记，自己对 Netty 有了简单的认识，也对 NIO 有了更深的了解，最主要的学会看英文文档，看官方文档很重要，不要惧怕，慢慢的就感觉还是文档写的最清楚，最有价值。老师还提到需要多记录，因此我也把一些重要的知识点记录下来，方便以后查找。当然以后还要加强学习，多看看 Netty 官方文档和例子，加强练习。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty 源码分析（四）]]></title>
    <url>%2F2019%2F01%2F19%2FNetty%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[版本 4.1.15 官网：https://netty.io/ Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. ChannelPromiseio.netty.channel.ChannelPromise 前面我们分析了 ChannelFuture ，看看ChannelPromise 的作用 1234/** * Special &#123;@link ChannelFuture&#125; which is writable. */public interface ChannelPromise extends ChannelFuture, Promise&lt;Void&gt; &#123; ... &#125; 这是一个可以写入的 ChannelFuture ，我先看看 Promise 这个类 Promiseio.netty.util.concurrent.Promise 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public interface Promise&lt;V&gt; extends Future&lt;V&gt; &#123; /** * Marks this future as a success and notifies all * listeners. * * If it is success or failed already it will throw an &#123;@link IllegalStateException&#125;. */ Promise&lt;V&gt; setSuccess(V result); /** * Marks this future as a success and notifies all * listeners. * * @return &#123;@code true&#125; if and only if successfully marked this future as * a success. Otherwise &#123;@code false&#125; because this future is * already marked as either a success or a failure. */ boolean trySuccess(V result); /** * Marks this future as a failure and notifies all * listeners. * * If it is success or failed already it will throw an &#123;@link IllegalStateException&#125;. */ Promise&lt;V&gt; setFailure(Throwable cause); /** * Marks this future as a failure and notifies all * listeners. * * @return &#123;@code true&#125; if and only if successfully marked this future as * a failure. Otherwise &#123;@code false&#125; because this future is * already marked as either a success or a failure. */ boolean tryFailure(Throwable cause); /** * Make this future impossible to cancel. * * @return &#123;@code true&#125; if and only if successfully marked this future as uncancellable or it is already done * without being cancelled. &#123;@code false&#125; if this future has been cancelled already. */ boolean setUncancellable(); @Override Promise&lt;V&gt; addListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); @Override Promise&lt;V&gt; addListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); @Override Promise&lt;V&gt; removeListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); @Override Promise&lt;V&gt; removeListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); @Override Promise&lt;V&gt; await() throws InterruptedException; @Override Promise&lt;V&gt; awaitUninterruptibly(); @Override Promise&lt;V&gt; sync() throws InterruptedException; @Override Promise&lt;V&gt; syncUninterruptibly();&#125; JDK 所提供的的 Future 只能通过手工的方式检查执行结果，而这个操作是会阻塞的；Netty 则对 ChannelFutre 进行了增强，通过 ChannelFutureListener 以回调的方式来获取执行结果，去除了手工检查阻塞的操作，值得注意的是，ChannelFutrureListener 的 operationComplete 方法是由I/O线程执行的，因此要注意的是不要在这里执行耗时操作，否则需要通过另外的线程或线程池来执行 ChannelInboundHandlerAdapterio.netty.channel.ChannelInboundHandlerAdapter io.netty.channelpublic class ChannelInboundHandlerAdapterextends ChannelHandlerAdapter implements ChannelInboundHandlerAbstract base class for ChannelInboundHandler implementations which provide implementations of all of their methods. This implementation just forward the operation to the next ChannelHandler in the ChannelPipeline. Sub-classes may override a method implementation to change this. Be aware that messages are not released after the channelRead(ChannelHandlerContext, Object) method returns automatically. If you are looking for a ChannelInboundHandler implementation that releases the received messages automatically, please see SimpleChannelInboundHandler. 这里使用了适配器模式 ChannelInboundHandlerio.netty.channel.ChannelInboundHandler 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * &#123;@link ChannelHandler&#125; which adds callbacks for state changes. This allows the user * to hook in to state changes easily. */public interface ChannelInboundHandler extends ChannelHandler &#123; /** * The &#123;@link Channel&#125; of the &#123;@link ChannelHandlerContext&#125; was registered with its &#123;@link EventLoop&#125; */ void channelRegistered(ChannelHandlerContext ctx) throws Exception; /** * The &#123;@link Channel&#125; of the &#123;@link ChannelHandlerContext&#125; was unregistered from its &#123;@link EventLoop&#125; */ void channelUnregistered(ChannelHandlerContext ctx) throws Exception; /** * The &#123;@link Channel&#125; of the &#123;@link ChannelHandlerContext&#125; is now active */ void channelActive(ChannelHandlerContext ctx) throws Exception; /** * The &#123;@link Channel&#125; of the &#123;@link ChannelHandlerContext&#125; was registered is now inactive and reached its * end of lifetime. */ void channelInactive(ChannelHandlerContext ctx) throws Exception; /** * Invoked when the current &#123;@link Channel&#125; has read a message from the peer. */ void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception; /** * Invoked when the last message read by the current read operation has been consumed by * &#123;@link #channelRead(ChannelHandlerContext, Object)&#125;. If &#123;@link ChannelOption#AUTO_READ&#125; is off, no further * attempt to read an inbound data from the current &#123;@link Channel&#125; will be made until * &#123;@link ChannelHandlerContext#read()&#125; is called. */ void channelReadComplete(ChannelHandlerContext ctx) throws Exception; /** * Gets called if an user event was triggered. */ void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception; /** * Gets called once the writable state of a &#123;@link Channel&#125; changed. You can check the state with * &#123;@link Channel#isWritable()&#125;. */ void channelWritabilityChanged(ChannelHandlerContext ctx) throws Exception; /** * Gets called if a &#123;@link Throwable&#125; was thrown. */ @Override @SuppressWarnings("deprecation") void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception;&#125; SimpleChannelInboundHandlerio.netty.channel.SimpleChannelInboundHandler 我们在写自己的 Handler 的时候长会继承这个 SimpleChannelInboundHandler 12345678910111213141516171819public class MyServerHandler extends SimpleChannelInboundHandler&lt;String&gt;&#123; @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception &#123; System.out.println(ctx.channel().remoteAddress() + ": " + msg); ctx.channel().writeAndFlush("from server: " + UUID.randomUUID()); &#125; /** * 出现异常关闭连接 * @param ctx * @param cause * @throws Exception */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 我们看看这个文档 io.netty.channelpublic abstract class SimpleChannelInboundHandlerextends ChannelInboundHandlerAdapterChannelInboundHandlerAdapter which allows to explicit only handle a specific type of messages. For example here is an implementation which only handle String messages. 12345678910&gt; public class StringHandler extends&gt; SimpleChannelInboundHandler&lt;String&gt; &#123;&gt; &gt; @Override&gt; protected void channelRead0(ChannelHandlerContext ctx, String message)&gt; throws Exception &#123;&gt; System.out.println(message);&gt; &#125;&gt; &#125;&gt; &gt; Be aware that depending of the constructor parameters it will release all handled messages by passing them to ReferenceCountUtil.release(Object). In this case you may need to use ReferenceCountUtil.retain(Object) if you pass the object to the next handler in the ChannelPipeline.Forward compatibility notice 我们可以通过泛型指定消息类型 1234567891011121314151617181920212223242526272829303132@Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; boolean release = true; try &#123; if (acceptInboundMessage(msg)) &#123; @SuppressWarnings("unchecked") I imsg = (I) msg; channelRead0(ctx, imsg); &#125; else &#123; release = false; ctx.fireChannelRead(msg); &#125; &#125; finally &#123; if (autoRelease &amp;&amp; release) &#123; // 把这个消息计数减一，当减为0就丢弃 ReferenceCountUtil.release(msg); &#125; &#125;&#125;/** * &lt;strong&gt;Please keep in mind that this method will be renamed to * &#123;@code messageReceived(ChannelHandlerContext, I)&#125; in 5.0.&lt;/strong&gt; * * Is called for each message of type &#123;@link I&#125;. * * @param ctx the &#123;@link ChannelHandlerContext&#125; which this &#123;@link SimpleChannelInboundHandler&#125; * belongs to * @param msg the message to handle * @throws Exception is thrown if an error occurred */protected abstract void channelRead0(ChannelHandlerContext ctx, I msg) throws Exception; 给我们强制转换为特定的类型，再调用 channelRead0 方法，这是一个抽象方法，需要我们自己去实现 ReferenceCountedio.netty.util.ReferenceCounted io.netty.utilpublic interface ReferenceCountedA reference-counted object that requires explicit deallocation.When a new ReferenceCounted is instantiated, it starts with the reference count of 1. retain() increases the reference count, and release() decreases the reference count. If the reference count is decreased to 0, the object will be deallocated explicitly, and accessing the deallocated object will usually result in an access violation.If an object that implements ReferenceCounted is a container of other objects that implement ReferenceCounted, the contained objects will also be released via release() when the container’s reference count becomes 0. ctx.channel().write()和ctx.write()的区别在 Netty 中有两种发消息的方式，可以直接写到 Channel 中，也可以写到与 ChannelHandler 所关联的那个 ChannelHandlerContext 中，对于 ctx.channel().write() 方式来说，消息会从 ChannelPipeline 的末尾开始流动，对于 ctx.write() 来说，消息将从 ChannelPipeline 中的下一个 ChannelHandler 开始流动 这篇博客个解释了 https://blog.csdn.net/FishSeeker/article/details/78447684 结论： ChannelHandlerContext 与 ChannelHandler 之间的关联绑定关系是永远不会发生改变的，因此对其进行缓存时没有任何问题的 对于与 Channel 的同名方法来说， ChannelHandlerContext 的方法将会产生更短的事件流，所以我们因该在可能的情况下利用这个特性来提升性能 Java NIONIO 总结使用 NIO 进行文件读取所涉及的步骤： 从 FileInputStream 对象获取到 Channel 对象 创建 Buffer 将数据从 Channel 中读取到Buffer中 0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity flip() 方法： 将 limit 值设置为当前的 position 将 position 设置 0 clear() 方法： 将 limit 设置为capacity 将 position 设置为0 compact() 方法： 将所有未读的数据复制到 buffer 起始的位置处 将 position 设置为最后一个未读元素的后面 将 limit 设置为 capacity 现在buffer 就准备好了，但是不会覆盖未读的数据 Java NIO中，关于DirectBuffer，HeapBuffer的疑问？ DirectBuffer 属于堆外存，那应该还是属于用户内存，而不是内核内存？ FileChannel 的read(ByteBuffer dst)函数,write(ByteBuffer src)函数中，如果传入的参数是HeapBuffer类型,则会临时申请一块DirectBuffer,进行数据拷贝，而不是直接进行数据传输，这是出于什么原因？ 答案： https://www.zhihu.com/question/57374068/answer/152691891 Java NIO中的direct buffer（主要是DirectByteBuffer）其实是分两部分的： 12345 Java | native |DirectByteBuffer | malloc&apos;d[ address ] -+-&gt; [ data ] | 其中 DirectByteBuffer 自身是一个Java对象，在Java堆中；而这个对象中有个long类型字段address，记录着一块调用 malloc() 申请到的native memory。 所以回到题主的问题： \1. DirectBuffer 属于堆外存，那应该还是属于用户内存，而不是内核内存？ DirectByteBuffer 自身是（Java）堆内的，它背后真正承载数据的buffer是在（Java）堆外——native memory中的。这是 malloc() 分配出来的内存，是用户态的。 \2. FileChannel 的read(ByteBuffer dst)函数,write(ByteBuffer src)函数中，如果传入的参数是HeapBuffer类型,则会临时申请一块DirectBuffer,进行数据拷贝，而不是直接进行数据传输，这是出于什么原因？ 题主看的是OpenJDK的 sun.nio.ch.IOUtil.write(FileDescriptor fd, ByteBuffer src, long position, NativeDispatcher nd) 的实现对不对： 1234567891011121314151617181920212223242526272829static int write(FileDescriptor fd, ByteBuffer src, long position, NativeDispatcher nd) throws IOException&#123; if (src instanceof DirectBuffer) return writeFromNativeBuffer(fd, src, position, nd); // Substitute a native buffer int pos = src.position(); int lim = src.limit(); assert (pos &lt;= lim); int rem = (pos &lt;= lim ? lim - pos : 0); ByteBuffer bb = Util.getTemporaryDirectBuffer(rem); try &#123; bb.put(src); bb.flip(); // Do not update src until we see how many bytes were written src.position(pos); int n = writeFromNativeBuffer(fd, bb, position, nd); if (n &gt; 0) &#123; // now update src src.position(pos + n); &#125; return n; &#125; finally &#123; Util.offerFirstTemporaryDirectBuffer(bb); &#125;&#125; 这里其实是在迁就OpenJDK里的HotSpot VM的一点实现细节。 HotSpot VM里的GC除了CMS之外都是要移动对象的，是所谓“compacting GC”。 如果要把一个Java里的 byte[] 对象的引用传给native代码，让native代码直接访问数组的内容的话，就必须要保证native代码在访问的时候这个 byte[] 对象不能被移动，也就是要被“pin”（钉）住。 可惜HotSpot VM出于一些取舍而决定不实现单个对象层面的object pinning，要pin的话就得暂时禁用GC——也就等于把整个Java堆都给pin住。HotSpot VM对JNI的Critical系API就是这样实现的。这用起来就不那么顺手。 所以 Oracle/Sun JDK / OpenJDK 的这个地方就用了点绕弯的做法。它假设把 HeapByteBuffer 背后的 byte[] 里的内容拷贝一次是一个时间开销可以接受的操作，同时假设真正的I/O可能是一个很慢的操作。 于是它就先把 HeapByteBuffer 背后的 byte[] 的内容拷贝到一个 DirectByteBuffer 背后的native memory去，这个拷贝会涉及 sun.misc.Unsafe.copyMemory() 的调用，背后是类似 memcpy() 的实现。这个操作本质上是会在整个拷贝过程中暂时不允许发生GC的，虽然实现方式跟JNI的Critical系API不太一样。（具体来说是 Unsafe.copyMemory() 是HotSpot VM的一个intrinsic方法，中间没有safepoint所以GC无法发生）。 然后数据被拷贝到native memory之后就好办了，就去做真正的I/O，把 DirectByteBuffer 背后的native memory地址传给真正做I/O的函数。这边就不需要再去访问Java对象去读写要做I/O的数据了。 ByteBuf文档：https://netty.io/4.1/api/index.html 我们看第一个例子 1234567891011121314public class ByteBufTest01 &#123; public static void main(String[] args) &#123; final ByteBuf buffer = Unpooled.buffer(10); for (int i = 0, index = 120; i &lt; 10; i++) &#123; buffer.writeByte(index + i); &#125; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(buffer.getByte(i)); &#125; &#125;&#125; 输出： 12345678910120121122123124125126127-128-127 我们来看看这个方法的文档 123456789/** * Sets the specified byte at the current &#123;@code writerIndex&#125; * and increases the &#123;@code writerIndex&#125; by &#123;@code 1&#125; in this buffer. * The 24 high-order bits of the specified value are ignored. * * @throws IndexOutOfBoundsException * if &#123;@code this.writableBytes&#125; is less than &#123;@code 1&#125; */public abstract ByteBuf writeByte(int value); 虽然传入的一个 int 值，可是它会丢弃高位的 24 bit，我们知道 int 是 4 字节（32 bit），丢弃 3 字节 （24 bit），就保留到 1 字节（8 bit） 我们要看下一个例子 1234567891011121314151617public class ByteBufTest02 &#123; public static void main(String[] args) &#123; ByteBuf byteBuf = Unpooled.copiedBuffer("hello world", Charset.forName("utf-8")); // 判断是否为堆缓存，如果是堆缓存，返回true if (byteBuf.hasArray()) &#123; byte[] bytes = byteBuf.array(); System.out.println(new String(bytes, Charset.forName("utf-8"))); System.out.println(byteBuf); System.out.println(byteBuf.arrayOffset()); // 可读字节第一偏移量 System.out.println(byteBuf.readerIndex()); System.out.println(byteBuf.writerIndex()); System.out.println(byteBuf.capacity()); &#125; &#125;&#125; 输出： 123456hello world UnpooledByteBufAllocator$InstrumentedUnpooledUnsafeHeapByteBuf(ridx: 0, widx: 11, cap: 33)001133 ridx 表示读的 index，widx 表示写的 index 我们来看看复合 Buffer 1234567891011121314151617public class ByteBufTest03 &#123; public static void main(String[] args) &#123; // 新建一个复合 buffer CompositeByteBuf compositeByteBuf = Unpooled.compositeBuffer(); ByteBuf heapBuf = Unpooled.buffer(10); ByteBuf directBuf = Unpooled.directBuffer(8); compositeByteBuf.addComponent(heapBuf); compositeByteBuf.addComponent(directBuf); compositeByteBuf.forEach(System.out::println); // 输出 // UnpooledSlicedByteBuf(ridx: 0, widx: 0, cap: 0/0, unwrapped: UnpooledByteBufAllocator$InstrumentedUnpooledUnsafeHeapByteBuf(ridx: 0, widx: 0, cap: 10)) // UnpooledSlicedByteBuf(ridx: 0, widx: 0, cap: 0/0, unwrapped: UnpooledByteBufAllocator$InstrumentedUnpooledUnsafeNoCleanerDirectByteBuf(ridx: 0, widx: 0, cap: 8)) &#125;&#125; Netty 提供的 3 种缓冲区heap buffer（堆缓冲区）： 这是最常见的类型，ByteBuf 将数据存储到 JVM 的堆空间中，并且将实际的数据放到 byte 数组中来实现的 优点：由于数据是存储在 JVM 的堆中，因此可以快速的创建和快速的释放，并且它提供了 直接访问内部字节数组的方法 缺点：每次读写数据时，都需要先将数据复制到直接缓冲中再进行网络传输 direct buffer（直接缓冲区）： 在堆之外直接分配内存空间，直接缓冲区并不会占用堆的容量空间，因为他是有操作系统在本地内存进行的数据分配 优点：在使用 Socket 进行数据传输时，性能非常好，因为数据直接位于操作系统的本地内存中，所以不需要从 JVM 将数据复制到直接缓冲区 缺点：因为 Direct Buffer 是直接在操作系统内存中的，所以内存空间分配与释放要比堆空间更加复杂，而且速度要慢一些 Netty 通过提供内存池来解决这个问题，直接缓冲区并不支持通过字节数组的方式来访问数据 重点：对于后端的业务消息的编解码来说，推荐使用 HeapByteBuf；对于 I/O 通信的读写缓冲区，我们推荐使用 DirectBytebuf composite buffer（符合缓冲区）： 复合缓冲区实际上是将多个缓冲区实例组合起来，并向外提供一个统一视图。像是一个缓冲区的 List JDK 的 ByteBuffer 与 Netty 的 ByteBuf 之间的差异比对 Netty 的 ByteBuf 采用了读写分离的策略（readerIndex 和 writeerIndex），一个初始化（里面尚未有任何数据）的 ByteBuf 的 readerIndex 与 writerIndex 的值都为0 当数索引与写索引处于同一个位置时，如果我们继续读取，那么就会抛出 IndexOutOfBoundsException 对于ByteBuf 的任何读写操作都会分别单独维护读索引和写索引，MaxCapacity 最大的容量默认为Integer.MAX_VALUE JDK 的 ByteBuffer的缺点： final byte[] hb; 这是JDK的ByteBuffer对象中用于储存的对象声明，可以看到，其字节数组布尔声明为final的，也就是长度是固定不变的，一旦分配好后就不能动态扩容与收缩，而且当储存的数据字节很大时就很有可能出现IndexOutOfBoundsException，如果要预防着个异常，那就需要再储存之前完全确定好待储存的字节的大小，如果ByteBuffer的空间不足，我们只有一种解决方案，那就是创建新的ByteBuffer对象，然后再将之前的ByteBuffer中的数据复制过去，这一切操作都需要由开发者自己来手动完成的 ByteBuffer 只使用一个position 指针来标识位置信息，在进行读写切换时就需要调用flip方法或则是rewind 方法，使用很不方便 Netty 的 ByteBuf 的优点： 储存字节的数组是动态的，其最大值默认是Integer.MAX_VALUE，这里的动态性是体现在write方法中的，write方法执行会判断buffer容量，如果不足则会自动扩容 ByteBuf的读写索引是完成分开的，使用起来很方便 12345678910111213141516171819202122232425262728// io.netty.buffer.AbstractByteBuf#writeByte @Override public ByteBuf writeByte(int value) &#123; ensureWritable0(1); // 会先判断是否够写入一个字节 _setByte(writerIndex++, value); return this; &#125;// io.netty.buffer.AbstractByteBuf#ensureWritable0// 会自动扩容 final void ensureWritable0(int minWritableBytes) &#123; ensureAccessible(); if (minWritableBytes &lt;= writableBytes()) &#123; return; &#125; if (minWritableBytes &gt; maxCapacity - writerIndex) &#123; throw new IndexOutOfBoundsException(String.format( "writerIndex(%d) + minWritableBytes(%d) exceeds maxCapacity(%d): %s", writerIndex, minWritableBytes, maxCapacity, this)); &#125; // Normalize the current capacity to the power of 2. int newCapacity = alloc().calculateNewCapacity(writerIndex + minWritableBytes, maxCapacity); // Adjust to the new capacity. capacity(newCapacity); &#125;]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty 源码分析（三）]]></title>
    <url>%2F2019%2F01%2F16%2FNetty%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[版本 4.1.15 官网：https://netty.io/ Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. addLast 方法io.netty.channel.DefaultChannelPipeline#addLast 12345678910111213141516171819202122232425262728293031323334@Overridepublic final ChannelPipeline addLast(EventExecutorGroup group, String name, ChannelHandler handler) &#123; final AbstractChannelHandlerContext newCtx; synchronized (this) &#123; checkMultiplicity(handler); newCtx = newContext(group, filterName(name, handler), handler); addLast0(newCtx); // 是把 ChannelHandlerContext 添加进去 // If the registered is false it means that the channel was not registered on an eventloop yet. // In this case we add the context to the pipeline and add a task that will call // ChannelHandler.handlerAdded(...) once the channel is registered. if (!registered) &#123; newCtx.setAddPending(); callHandlerCallbackLater(newCtx, true); return this; &#125; EventExecutor executor = newCtx.executor(); if (!executor.inEventLoop()) &#123; newCtx.setAddPending(); executor.execute(new Runnable() &#123; @Override public void run() &#123; callHandlerAdded0(newCtx); &#125; &#125;); return this; &#125; &#125; callHandlerAdded0(newCtx); return this;&#125; AbstractChannelHandlerContext 定义了一个上下文，找到实现的一个接口 ChannelHandlerContext io.netty.channel.ChannelHandlerContext 文档：https://netty.io/5.0/api/io/netty/channel/ChannelHandlerContext.html 接下来我分析一下 ChannelHandlerContext ，PipeLine，Handler 这三者的关系 这篇文章写的很清楚 https://blog.csdn.net/u010853261/article/details/54574440 ChannelHandlerContext每个ChannelHandler被添加到ChannelPipeline后，都会创建一个ChannelHandlerContext并与之创建的ChannelHandler关联绑定。ChannelHandlerContext允许ChannelHandler与其他的ChannelHandler实现进行交互。ChannelHandlerContext不会改变添加到其中的ChannelHandler，因此它是安全的 下图显示了ChannelHandlerContext、ChannelHandler、ChannelPipeline的关系： 最后我们看到 1234567private void addLast0(AbstractChannelHandlerContext newCtx) &#123; AbstractChannelHandlerContext prev = tail.prev; newCtx.prev = prev; newCtx.next = tail; prev.next = newCtx; tail.prev = newCtx;&#125; 我们的双向链表链表维护的是 ChannelHandlerContext 对象，而ChannelHandlerContext 包装了 ChannelHandler 我们回到 addLast 方法上 123456789101112131415161718p.addLast(new ChannelInitializer&lt;Channel&gt;() &#123; @Override public void initChannel(final Channel ch) throws Exception &#123; final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) &#123; pipeline.addLast(handler); &#125; ch.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); &#125; &#125;); &#125;&#125;); 进入 ChannelInitializer 类中，我们看 #initChannel 方法，说这个方法当 Channel 注册时会被调用，一旦掉用完就会被移除 ChannelPipeline，这是因为只需要把里面封装的 Handler 添加到 ChannelPipeline，因为他本身就不一个 Handler io.netty.channel.ChannelInitializerprotected abstract void initChannel(C ch) This method will be called once the Channel was registered. After the method returns this instance will be removed from the ChannelPipeline of the Channel. 下面是移除代码 1234567891011121314151617181920212223242526private boolean initChannel(ChannelHandlerContext ctx) throws Exception &#123; if (initMap.putIfAbsent(ctx, Boolean.TRUE) == null) &#123; // Guard against re-entrance. try &#123; initChannel((C) ctx.channel()); &#125; catch (Throwable cause) &#123; // Explicitly call exceptionCaught(...) as we removed the handler before calling initChannel(...). // We do so to prevent multiple calls to initChannel(...). exceptionCaught(ctx, cause); &#125; finally &#123; remove(ctx); &#125; return true; &#125; return false;&#125;private void remove(ChannelHandlerContext ctx) &#123; try &#123; ChannelPipeline pipeline = ctx.pipeline(); if (pipeline.context(this) != null) &#123; pipeline.remove(this); &#125; &#125; finally &#123; initMap.remove(ctx); &#125;&#125; ChannelHandlerContext.attr(..) == Channel.attr(..)https://netty.io/wiki/new-and-noteworthy-in-4.1.html Both Channel and ChannelHandlerContext implement the interface AttributeMap to enable a user to attach one or more user-defined attributes to them. What sometimes made a user confused was that a Channel and a ChannelHandlerContext had its own storage for the user-defined attributes. For example, even if you put an attribute ‘KEY_X’ via Channel.attr(KEY_X).set(valueX), you will never find it via ChannelHandlerContext.attr(KEY_X).get() and vice versa. This behavior is not only confusing but also is waste of memory. To address this issue, we decided to keep only one map per Channel internally. AttributeMap always uses AttributeKey as its key. AttributeKey ensures uniqueness between each key, and thus there’s no point of having more than one attribute map per Channel. As long as a user defines its own AttributeKey as a private static final field of his or her ChannelHandler, there will be no risk of duplicate keys. 注意：现在这两个关联的是一个Map callHandlerCallbackLater 我们回到 #addLast 方法上，这个时候是还没有注册的，进入这个 #callHandlerCallbackLater 方法，把稍后调用 Handler 回调，封装成一个 task 123456789101112131415private void callHandlerCallbackLater(AbstractChannelHandlerContext ctx, boolean added) &#123; assert !registered; PendingHandlerCallback task = added ? new PendingHandlerAddedTask(ctx) : new PendingHandlerRemovedTask(ctx); PendingHandlerCallback pending = pendingHandlerCallbackHead; if (pending == null) &#123; pendingHandlerCallbackHead = task; &#125; else &#123; // Find the tail of the linked-list. while (pending.next != null) &#123; pending = pending.next; &#125; pending.next = task; &#125;&#125; 注册我们回到io.netty.bootstrap.AbstractBootstrap#initAndRegister 12345678910111213141516171819202122final ChannelFuture initAndRegister() &#123; Channel channel = null; try &#123; channel = channelFactory.newChannel(); init(channel); &#125; catch (Throwable t) &#123; if (channel != null) &#123; // channel can be null if newChannel crashed (eg SocketException("too many open files")) channel.unsafe().closeForcibly(); &#125; // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor return new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE).setFailure(t); &#125; ChannelFuture regFuture = config().group().register(channel); if (regFuture.cause() != null) &#123; if (channel.isRegistered()) &#123; channel.close(); &#125; else &#123; channel.unsafe().closeForcibly(); &#125; &#125; 前面的初始化初始化已经有一点的了解，现在我来看注册，这里有#config，#group 和 #register 这三个方法，我们一个一个分析 1ChannelFuture regFuture = config().group().register(channel); config 方法12345/** * Returns the &#123;@link AbstractBootstrapConfig&#125; object that can be used to obtain the current config * of the bootstrap. */public abstract AbstractBootstrapConfig&lt;B, C&gt; config(); 返回了一个 ServerbootstrapConfig 对象 group 方法1234567/** * Returns the configured &#123;@link EventLoopGroup&#125; or &#123;@code null&#125; if non is configured yet. */@SuppressWarnings("deprecation")public final EventLoopGroup group() &#123; return bootstrap.group();&#125; 返回一个 NioEventLoopGroup 对象，这个时候返回的是一个调用的是他的父类MultithreadEventLoopGroup的 register 方法io.netty.channel.MultithreadEventLoopGroup#register(io.netty.channel.Channel) 最终会调用 io.netty.channel.SingleThreadEventLoop#register(io.netty.channel.Channel) 的注册方法 我们来看看这个类 io.netty.channel.SingleThreadEventLoop io.netty.channelpublic abstract class SingleThreadEventLoopextends SingleThreadEventExecutorimplements EventLoopAbstract base class for EventLoops that execute all its submitted tasks in a single thread. io.netty.channel.AbstractChannel.AbstractUnsafe#register 1234567891011121314151617181920212223242526272829303132333435363738@Overridepublic final void register(EventLoop eventLoop, final ChannelPromise promise) &#123; if (eventLoop == null) &#123; throw new NullPointerException("eventLoop"); &#125; if (isRegistered()) &#123; promise.setFailure(new IllegalStateException("registered to an event loop already")); return; &#125; if (!isCompatible(eventLoop)) &#123; promise.setFailure( new IllegalStateException("incompatible event loop type: " + eventLoop.getClass().getName())); return; &#125; AbstractChannel.this.eventLoop = eventLoop; // 如果是当前线程就让它执行 if (eventLoop.inEventLoop()) &#123; register0(promise); // 如果不是的话就放到线程池中注册 &#125; else &#123; try &#123; eventLoop.execute(new Runnable() &#123; @Override public void run() &#123; register0(promise); &#125; &#125;); &#125; catch (Throwable t) &#123; logger.warn( "Force-closing a channel whose registration task was not accepted by an event loop: &#123;&#125;", AbstractChannel.this, t); closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); &#125; &#125;&#125; 先理解一下线程 Netty 中的线程模型 一个 EventLoopGroup 当中会包含多个 EventLoop 一个 EventLoop 在它的整个生命周期当中都只会与唯一一个 Thread 进行绑定 所有 EventLoop 所处理的各种 I/O 事件都是将在他所关联的那个 Thread 上进行处理 一个 Channel 在它的整个生命周期中只会注册在一个 EventLoop 上 一个 EventLoop 在运行过程中，会被分配给一或者多个 Channel 重要结论： 在Netty 中 Channel 的实现是线程安全的，基于此，我们可以存储一个 Channel 的引用，并且在需要向远程端点发送数据时，通过这个引用来调用 Channel 相应的方法，即便是当时有很多线程都在使用它也不会出现多线程的问题，而且消息一点会按照这个顺序发送出去 我们在业务开发中，不要将执行耗时的任务放入到 EventLoop 的执行队列中，因为它会堵塞该线程的所有Channel 上的其它执行任务，如果我们需要进行阻塞调用或则是耗时操作，那么我们需要使用一个专门的EventExectutor(业务线程池) 通常会有两种实现方式： 在 ChannelHandler 的回调方法中，使用自己定义的业务线程池，这样就可以实现异步调用 借助于 Netty 提供的向 ChannelPipeline 添加ChannelHandler是调用的addLast方法来传递 EventExecutorGroup 说明：如果addLast(handler)的方法是由I/O线程所执行的，如果addLast(eventExectutorGroup, handler)的方法，那么就是由参数中的group的线程组来执行 io.netty.channel.AbstractChannel.AbstractUnsafe#register0 1234567891011121314151617181920212223242526272829303132333435363738private void register0(ChannelPromise promise) &#123; try &#123; // check if the channel is still open as it could be closed in the mean time when the register // call was outside of the eventLoop if (!promise.setUncancellable() || !ensureOpen(promise)) &#123; return; &#125; boolean firstRegistration = neverRegistered; doRegister(); // 这个方法 neverRegistered = false; registered = true; // Ensure we call handlerAdded(...) before we actually notify the promise. This is needed as the // user may already fire events through the pipeline in the ChannelFutureListener. pipeline.invokeHandlerAddedIfNeeded(); safeSetSuccess(promise); pipeline.fireChannelRegistered(); // Only fire a channelActive if the channel has never been registered. This prevents firing // multiple channel actives if the channel is deregistered and re-registered. if (isActive()) &#123; if (firstRegistration) &#123; pipeline.fireChannelActive(); &#125; else if (config().isAutoRead()) &#123; // This channel was registered before and autoRead() is set. This means we need to begin read // again so that we process inbound data. // // See https://github.com/netty/netty/issues/4805 beginRead(); &#125; &#125; &#125; catch (Throwable t) &#123; // Close the channel directly to avoid FD leak. closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); &#125;&#125; io.netty.channel.nio.AbstractNioChannel#doRegister 看到 doXxx 开头的方法就知道是认真工作的 123456789101112131415161718192021@Overrideprotected void doRegister() throws Exception &#123; boolean selected = false; for (;;) &#123; try &#123; selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this); return; &#125; catch (CancelledKeyException e) &#123; if (!selected) &#123; // Force the Selector to select now as the "canceled" SelectionKey may still be // cached and not removed because no Select.select(..) operation was called yet. eventLoop().selectNow(); selected = true; &#125; else &#123; // We forced a select operation on the selector before but the SelectionKey is still cached // for whatever reason. JDK bug ? throw e; &#125; &#125; &#125;&#125; 与我们前面写的 NIO 逻辑是一样的 1serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); sync1234567891011121314151617181920public class MyServer &#123; public static void main(String[] args) throws InterruptedException &#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workGroup = new NioEventLoopGroup(); try &#123; ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_KEEPALIVE, false) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new MyServerinitializer()); ChannelFuture channelFuture = bootstrap.bind(8899).sync(); channelFuture.channel().closeFuture().sync(); &#125; finally &#123; bossGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); &#125; &#125;&#125; 我们回到我们编写的 Server 中，需要绑定，之后需要调用 #sync 表示这个方法需要同步，要不然还没绑定完成就返回了 ChannelFuture ，里面的结果或者状态是还没有完成的，加了 #sync 就能保证完成 1ChannelFuture channelFuture = bootstrap.bind(8899).sync(); 在我们正常开发是流程就会停在下面，就卡住了 1channelFuture.channel().closeFuture().sync(); 当我们调用关闭就会到 finally 中，会执行优雅关闭 到此我们启动过程基本分析完了]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty 源码分析（二）]]></title>
    <url>%2F2019%2F01%2F15%2FNetty%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[版本 4.1.15 官网：https://netty.io/ Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. 先来看一个NIO网络编程服务端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879/** * @Author: cuzz * @Date: 2019/1/7 15:39 * @Description: */public class NioServer &#123; // 储存客户端连接 private static Map&lt;String, SocketChannel&gt; clientMap = new HashMap&lt;&gt;(); public static void main(String[] args) throws IOException &#123; ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.configureBlocking(false); ServerSocket serverSocket = serverSocketChannel.socket(); serverSocket.bind(new InetSocketAddress(8899)); Selector selector = Selector.open(); serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); while (true) &#123; try &#123; selector.select(); Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); selectionKeys.forEach(selectionKey -&gt; &#123; try &#123; if (selectionKey.isAcceptable()) &#123; // 可以读 read(selector, selectionKey); &#125; else if (selectionKey.isReadable()) &#123; // 可以写 write(selector, selectionKey); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;); selectionKeys.clear(); // 别忘了清空 &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; private static void write(Selector selector, SelectionKey selectionKey) throws IOException&#123; SocketChannel client = (SocketChannel) selectionKey.channel(); ByteBuffer byteBuffer = ByteBuffer.allocate(512); int read = client.read(byteBuffer); if (read &gt; 0) &#123; byteBuffer.flip(); Charset charset = Charset.forName("utf-8"); String receiveMessage = String.valueOf(charset.decode(byteBuffer).array()); System.out.println(client + ": " + receiveMessage); String key = null; for (Map.Entry&lt;String, SocketChannel&gt; entry : clientMap.entrySet()) &#123; if (entry.getValue() == client) &#123; key = entry.getKey(); break; &#125; &#125; for (Map.Entry&lt;String, SocketChannel&gt; entry : clientMap.entrySet()) &#123; SocketChannel value = entry.getValue(); ByteBuffer writeBuffer = ByteBuffer.allocate(1024); writeBuffer.put((key + " :" + receiveMessage).getBytes()); writeBuffer.flip(); value.write(writeBuffer); &#125; &#125; &#125; private static void read(Selector selector, SelectionKey selectionKey) throws IOException&#123; ServerSocketChannel server = (ServerSocketChannel) selectionKey.channel(); System.out.println(server); SocketChannel client = server.accept(); client.configureBlocking(false); client.register(selector, SelectionKey.OP_READ); String key = UUID.randomUUID().toString(); // 保存客户端 clientMap.put(key, client); &#125;&#125; 客服端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * @Author: cuzz * @Date: 2019/1/8 17:10 * @Description: */public class NioClient &#123; public static void main(String[] args)&#123; try &#123; SocketChannel socketChannel = SocketChannel.open(); socketChannel.configureBlocking(false); Selector selector = Selector.open(); socketChannel.register(selector, SelectionKey.OP_CONNECT); socketChannel.connect(new InetSocketAddress("127.0.0.1",8899)); while (true) &#123; selector.select(); Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); for (SelectionKey selectionKey : selectionKeys ) &#123; if (selectionKey.isConnectable()) &#123; SocketChannel client = (SocketChannel) selectionKey.channel(); if (client.isConnectionPending()) &#123; client.finishConnect(); System.out.println(client); ByteBuffer writeBuffer = ByteBuffer.allocate(512); writeBuffer.put((LocalDateTime.now() + " 连接成功").getBytes()); writeBuffer.flip(); client.write(writeBuffer); ExecutorService executorService = Executors.newSingleThreadExecutor(); executorService.submit(() -&gt; &#123; while (true) &#123; InputStreamReader inputStreamReader = new InputStreamReader(System.in); BufferedReader bf = new BufferedReader(inputStreamReader); String message = bf.readLine(); ByteBuffer buffer = ByteBuffer.allocate(512); buffer.put(message.getBytes()); buffer.flip(); client.write(buffer); &#125; &#125;); &#125; client.register(selector, SelectionKey.OP_READ); &#125; else if (selectionKey.isReadable()) &#123; SocketChannel client = (SocketChannel) selectionKey.channel(); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); int read = client.read(byteBuffer); if (read &gt; 0) &#123; String message = new String(byteBuffer.array()); System.out.println(message); &#125; &#125; &#125; selectionKeys.clear(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 代码还是比较复杂的，Netty 内部就是把这些细节给封装起来了 Reactor模式翻译过来为反应器模式，可以先看看由 Doug Lea 写的 Scalable IO in Java ，更好的理解 Netty 的设计模式 还有一篇博客也写得很好，介绍相关理论模型，使用场景，基本组件、整体架构， 这可能是目前最透彻的Netty原理架构解析 Netty 那些事儿 ——— Reactor模式详解 Netty Reactor 工作架构图 bind() 方法前面通过 .channel(NioServerSocketChannel.class) 是为了通过反射创建一个 NioServerSocketChannel 对象 NioServerSocketChannel使用反射创建 NioServerSocketChannel 肯定是通过无参数构造器，在调用 newSocket(DEFAULT_SELECTOR_PROVIDER) 所以这是一个静态方法，返回一个 ServerSocketChannel 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * A &#123;@link io.netty.channel.socket.ServerSocketChannel&#125; implementation which uses * NIO selector based implementation to accept new connections. */public class NioServerSocketChannel extends AbstractNioMessageChannel implements io.netty.channel.socket.ServerSocketChannel &#123; private static final ChannelMetadata METADATA = new ChannelMetadata(false, 16); private static final SelectorProvider DEFAULT_SELECTOR_PROVIDER = SelectorProvider.provider(); private static ServerSocketChannel newSocket(SelectorProvider provider) &#123; try &#123; /** * Use the &#123;@link SelectorProvider&#125; to open &#123;@link SocketChannel&#125; and so remove condition in * &#123;@link SelectorProvider#provider()&#125; which is called by each ServerSocketChannel.open() otherwise. * * See &lt;a href="https://github.com/netty/netty/issues/2308"&gt;#2308&lt;/a&gt;. */ return provider.openServerSocketChannel(); &#125; catch (IOException e) &#123; throw new ChannelException( "Failed to open a server socket.", e); &#125; &#125; private final ServerSocketChannelConfig config; /** * Create a new instance */ public NioServerSocketChannel() &#123; this(newSocket(DEFAULT_SELECTOR_PROVIDER)); &#125; /** * Create a new instance using the given &#123;@link SelectorProvider&#125;. */ public NioServerSocketChannel(SelectorProvider provider) &#123; this(newSocket(provider)); &#125; /** * Create a new instance using the given &#123;@link ServerSocketChannel&#125;. */ public NioServerSocketChannel(ServerSocketChannel channel) &#123; super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket()); &#125; ...&#125; AbstractNioChannel我们回到调用的这个构造方法上 1234public NioServerSocketChannel(ServerSocketChannel channel) &#123; super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket());&#125; 一直调用父类，把 SelectionKey.OP_ACCEPT 设置上，还有设置非堵塞，是不出是很熟悉，这都是对 NIO 进行封装 io.netty.channel.nio.AbstractNioChannel#AbstractNioChannel 12345678910protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) &#123; super(parent); this.ch = ch; this.readInterestOp = readInterestOp; try &#123; ch.configureBlocking(false); &#125; catch (IOException e) &#123; ... &#125;&#125; 再调用父类，就是设置 Id 和创建管道 io.netty.channel.AbstractChannel 123456protected AbstractChannel(Channel parent) &#123; this.parent = parent; id = newId(); unsafe = newUnsafe(); pipeline = newChannelPipeline();&#125; NioServerSocketChannelConfig我们在回到这个构造方法上，我们重点来看看这个， NioServerSocketChannelConfig 这是一个配置类，Netty 的各种各样的信息都是体现在这个里面 1234public NioServerSocketChannel(ServerSocketChannel channel) &#123; super(null, channel, SelectionKey.OP_ACCEPT); config = new NioServerSocketChannelConfig(this, javaChannel().socket());&#125; 把自己和刚开始创建的 NIOSocketChannel 的 ServerSocket 对象传入进去 io.netty.channel.DefaultChannelConfig 123public DefaultChannelConfig(Channel channel) &#123; this(channel, new AdaptiveRecvByteBufAllocator());&#125; 传了一个 AdaptiveRecvByteBufAllocator 翻译过来可以叫可适配的接受字节缓冲适配器 AdaptiveRecvByteBufAllocatorio.netty.channel.AdaptiveRecvByteBufAllocator 文档： The RecvByteBufAllocator that automatically increases and decreases the predicted buffer size on feed back.It gradually increases the expected number of readable bytes if the previous read fully filled the allocated buffer. It gradually decreases the expected number of readable bytes if the read operation was not able to fill a certain amount of the allocated buffer two times consecutively. Otherwise, it keeps returning the same prediction. 构造方法，默认是1024，最小是63，最大是65536 12345678/** * Creates a new predictor with the default parameters. With the default * parameters, the expected buffer size starts from &#123;@code 1024&#125;, does not * go down below &#123;@code 64&#125;, and does not go up above &#123;@code 65536&#125;. */public AdaptiveRecvByteBufAllocator() &#123; this(DEFAULT_MINIMUM, DEFAULT_INITIAL, DEFAULT_MAXIMUM);&#125; 我们在看看里面的内部类 1234567891011121314151617181920212223242526272829303132333435363738394041private final class HandleImpl extends MaxMessageHandle &#123; private final int minIndex; private final int maxIndex; private int index; private int nextReceiveBufferSize; private boolean decreaseNow; public HandleImpl(int minIndex, int maxIndex, int initial) &#123; this.minIndex = minIndex; this.maxIndex = maxIndex; index = getSizeTableIndex(initial); nextReceiveBufferSize = SIZE_TABLE[index]; &#125; @Override public int guess() &#123; return nextReceiveBufferSize; &#125; private void record(int actualReadBytes) &#123; if (actualReadBytes &lt;= SIZE_TABLE[Math.max(0, index - INDEX_DECREMENT - 1)]) &#123; if (decreaseNow) &#123; index = Math.max(index - INDEX_DECREMENT, minIndex); nextReceiveBufferSize = SIZE_TABLE[index]; decreaseNow = false; &#125; else &#123; decreaseNow = true; &#125; &#125; else if (actualReadBytes &gt;= nextReceiveBufferSize) &#123; index = Math.min(index + INDEX_INCREMENT, maxIndex); nextReceiveBufferSize = SIZE_TABLE[index]; decreaseNow = false; &#125; &#125; @Override public void readComplete() &#123; record(totalBytesRead()); &#125;&#125; 其父亲 MaxMessageHandle 中，根据记录中的分配，计算出下一次分配的内存 1234@Overridepublic ByteBuf allocate(ByteBufAllocator alloc) &#123; return alloc.ioBuffer(guess());&#125; 根据系统的支持返回是堆内内存还是堆外内存 1234567@Overridepublic ByteBuf ioBuffer(int initialCapacity) &#123; if (PlatformDependent.hasUnsafe()) &#123; return directBuffer(initialCapacity); &#125; return heapBuffer(initialCapacity);&#125; Pipeline我们回到前面管道的创建 io.netty.channel.AbstractChannel 123456protected AbstractChannel(Channel parent) &#123; this.parent = parent; id = newId(); unsafe = newUnsafe(); pipeline = newChannelPipeline();&#125; io.netty.channel.DefaultChannelPipeline#DefaultChannelPipeline 1234567891011protected DefaultChannelPipeline(Channel channel) &#123; this.channel = ObjectUtil.checkNotNull(channel, "channel"); succeededFuture = new SucceededChannelFuture(channel, null); voidPromise = new VoidChannelPromise(channel, true); tail = new TailContext(this); head = new HeadContext(this); head.next = tail; tail.prev = head;&#125; 这里维护了一个上下文，并且把 Channel 对象赋值给自己，所以 Channel 和 Pipeline 是相互引用的 ChannelPipelineio.netty.channel.ChannelPipeline 文档： A list of ChannelHandlers which handles or intercepts inbound events and outbound operations of a Channel. ChannelPipeline implements an advanced form of the Intercepting Filter pattern to give a user full control over how an event is handled and how the ChannelHandlers in a pipeline interact with each other. Creation of a pipeline Each channel has its own pipeline and it is created automatically when a new channel is created. How an event flows in a pipeline The following diagram describes how I/O events are processed by ChannelHandlers in a ChannelPipeline typically. An I/O event is handled by either a ChannelInboundHandler or a ChannelOutboundHandler and be forwarded to its closest handler by calling the event propagation methods defined in ChannelHandlerContext, such as ChannelHandlerContext.fireChannelRead(Object) and ChannelHandlerContext.write(Object). 123456789101112131415161718192021222324252627282930313233343536373839&gt; I/O Request&gt; via Channel or&gt; ChannelHandlerContext&gt; |&gt; +---------------------------------------------------+---------------+&gt; | ChannelPipeline | |&gt; | \|/ |&gt; | +---------------------+ +-----------+----------+ |&gt; | | Inbound Handler N | | Outbound Handler 1 | |&gt; | +----------+----------+ +-----------+----------+ |&gt; | /|\ | |&gt; | | \|/ |&gt; | +----------+----------+ +-----------+----------+ |&gt; | | Inbound Handler N-1 | | Outbound Handler 2 | |&gt; | +----------+----------+ +-----------+----------+ |&gt; | /|\ . |&gt; | . . |&gt; | ChannelHandlerContext.fireIN_EVT() ChannelHandlerContext.OUT_EVT()|&gt; | [ method call] [method call] |&gt; | . . |&gt; | . \|/ |&gt; | +----------+----------+ +-----------+----------+ |&gt; | | Inbound Handler 2 | | Outbound Handler M-1 | |&gt; | +----------+----------+ +-----------+----------+ |&gt; | /|\ | |&gt; | | \|/ |&gt; | +----------+----------+ +-----------+----------+ |&gt; | | Inbound Handler 1 | | Outbound Handler M | |&gt; | +----------+----------+ +-----------+----------+ |&gt; | /|\ | |&gt; +---------------+-----------------------------------+---------------+&gt; | \|/&gt; +---------------+-----------------------------------+---------------+&gt; | | | |&gt; | [ Socket.read() ] [ Socket.write() ] |&gt; | |&gt; | Netty Internal I/O Threads (Transport Implementation) |&gt; +-------------------------------------------------------------------+&gt; &gt; An inbound event is handled by the inbound handlers in the bottom-up direction as shown on the left side of the diagram. An inbound handler usually handles the inbound data generated by the I/O thread on the bottom of the diagram. The inbound data is often read from a remote peer via the actual input operation such as SocketChannel.read(ByteBuffer). If an inbound event goes beyond the top inbound handler, it is discarded silently, or logged if it needs your attention. An outbound event is handled by the outbound handler in the top-down direction as shown on the right side of the diagram. An outbound handler usually generates or transforms the outbound traffic such as write requests. If an outbound event goes beyond the bottom outbound handler, it is handled by an I/O thread associated with the Channel. The I/O thread often performs the actual output operation such as SocketChannel.write(ByteBuffer) For example, let us assume that we created the following pipeline: 1234567&gt; ChannelPipeline p = ...;&gt; p.addLast("1", new InboundHandlerA());&gt; p.addLast("2", new InboundHandlerB());&gt; p.addLast("3", new OutboundHandlerA());&gt; p.addLast("4", new OutboundHandlerB());&gt; p.addLast("5", new InboundOutboundHandlerX());&gt; &gt; In the example above, the class whose name starts with Inbound means it is an inbound handler. The class whose name starts with Outbound means it is a outbound handler. In the given example configuration, the handler evaluation order is 1, 2, 3, 4, 5 when an event goes inbound. When an event goes outbound, the order is 5, 4, 3, 2, 1. On top of this principle, ChannelPipeline skips the evaluation of certain handlers to shorten the stack depth: 3 and 4 don’t implement ChannelInboundHandler, and therefore the actual evaluation order of an inbound event will be: 1, 2, and 5. 1 and 2 don’t implement ChannelOutboundHandler, and therefore the actual evaluation order of a outbound event will be: 5, 4, and 3. If 5 implements both ChannelInboundHandler and ChannelOutboundHandler, the evaluation order of an inbound and a outbound event could be 125 and 543 respectively. Forwarding an event to the next handler As you might noticed in the diagram shows, a handler has to invoke the event propagation methods in ChannelHandlerContext to forward an event to its next handler. Those methods include: Inbound event propagation methods ChannelHandlerContext.fireChannelRegistered() hannelHandlerContext.fireChannelActive() ChannelHandlerContext.fireChannelRead(Object) ChannelHandlerContext.fireChannelReadComplete() ChannelHandlerContext.fireExceptionCaught(Throwable) ChannelHandlerContext.fireUserEventTriggered(Object) ChannelHandlerContext.fireChannelWritabilityChanged() ChannelHandlerContext.fireChannelInactive() ChannelHandlerContext.fireChannelUnregistered() Outbound event propagation methods: ChannelHandlerContext.bind(SocketAddress, ChannelPromise) ChannelHandlerContext.connect(SocketAddress, SocketAddress, ChannelPromise) ChannelHandlerContext.write(Object, ChannelPromise) ChannelHandlerContext.flush() ChannelHandlerContext.read() ChannelHandlerContext.disconnect(ChannelPromise) ChannelHandlerContext.close(ChannelPromise) ChannelHandlerContext.deregister(ChannelPromise) and the following example shows how the event propagation is usually done: 12345678910111213141516&gt; public class MyInboundHandler extends ChannelInboundHandlerAdapter &#123;&gt; @Override&gt; public void channelActive(ChannelHandlerContext ctx) &#123;&gt; System.out.println("Connected!");&gt; ctx.fireChannelActive();&gt; &#125;&gt; &#125;&gt; &gt; public class MyOutboundHandler extends ChannelOutboundHandlerAdapter &#123;&gt; @Override&gt; public void close(ChannelHandlerContext ctx, ChannelPromise promise) &#123;&gt; System.out.println("Closing ..");&gt; ctx.close(promise);&gt; &#125;&gt; &#125;&gt; &gt; Building a pipeline (重点) A user is supposed to have one or more ChannelHandlers in a pipeline to receive I/O events (e.g. read) and to request I/O operations (e.g. write and close). For example, a typical server will have the following handlers in each channel’s pipeline, but your mileage may vary depending on the complexity and characteristics of the protocol and business logic: Protocol Decoder - translates binary data (e.g. ByteBuf) into a Java object. Protocol Encoder - translates a Java object into binary data. Business Logic Handler - performs the actual business logic (e.g. database access). and it could be represented as shown in the following example: 123456789101112131415&gt; static final EventExecutorGroup group = new DefaultEventExecutorGroup(16);&gt; ...&gt; &gt; ChannelPipeline pipeline = ch.pipeline();&gt; &gt; pipeline.addLast("decoder", new MyProtocolDecoder());&gt; pipeline.addLast("encoder", new MyProtocolEncoder());&gt; &gt; // Tell the pipeline to run MyBusinessLogicHandler's event handler methods&gt; // in a different thread than an I/O thread so that the I/O thread is not blocked by&gt; // a time-consuming task.&gt; // If your business logic is fully asynchronous or finished very quickly, you don't&gt; // need to specify a group.&gt; pipeline.addLast(group, "handler", new MyBusinessLogicHandler());&gt; &gt; 注：可以使用重载这个方法添加一个事件循环组 group 去执行耗时的任务，获取在 MyBusinessLogicHandler 中把耗时部分异步处理，这样就不会堵塞 IO 线程 Thread safety A ChannelHandler can be added or removed at any time because a ChannelPipeline is thread safe. For example, you can insert an encryption handler when sensitive information is about to be exchanged, and remove it after the exchange. 对于传统的过滤器如 SpringMVC 比如我们配置了 Filter1 Filter2 Filter3 过滤器，请求和返回都要经过滤器这3个过滤器，而管道可以选择的其中某些作为请求的过滤器，一些作为返回的过滤器，不一定要一样，入站的处理器专门处理入站的，出站的处理器专门处理出站的 init() 方法io.netty.bootstrap.ServerBootstrap#init 1234567891011121314151617@Overridevoid init(Channel channel) throws Exception &#123; final Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = options0(); synchronized (options) &#123; setChannelOptions(channel, options, logger); &#125; final Map&lt;AttributeKey&lt;?&gt;, Object&gt; attrs = attrs0(); synchronized (attrs) &#123; for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: attrs.entrySet()) &#123; @SuppressWarnings("unchecked") AttributeKey&lt;Object&gt; key = (AttributeKey&lt;Object&gt;) e.getKey(); channel.attr(key).set(e.getValue()); &#125; &#125; ...&#125; ChannelOption类图 io.netty.channelpublic class ChannelOptionextends AbstractConstant]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty 源码分析（一）]]></title>
    <url>%2F2019%2F01%2F03%2FNetty%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[版本 4.1.15 官网：https://netty.io/ Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. 先看一个例子服务端MyServer 类 123456789101112131415161718192021222324/** * @Author: cuzz * @Date: 2019/1/1 19:44 * @Description: */public class MyServer &#123; public static void main(String[] args) throws InterruptedException &#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workGroup = new NioEventLoopGroup(); try &#123; ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new MyServerinitializer()); ChannelFuture channelFuture = bootstrap.bind(8899).sync(); channelFuture.channel().closeFuture().sync(); &#125; finally &#123; bossGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); &#125; &#125;&#125; MyServerinitializer 类 123456789101112131415161718/** * @Author: cuzz * @Date: 2019/1/1 20:06 * @Description: */public class MyServerinitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new LengthFieldBasedFrameDecoder(Integer.MAX_VALUE, 0, 4, 0, 4)); pipeline.addLast(new LengthFieldPrepender(4)); pipeline.addLast(new StringDecoder(CharsetUtil.UTF_8)); pipeline.addLast(new StringEncoder(CharsetUtil.UTF_8)); pipeline.addLast(new MyServerHandler()); &#125;&#125; MyServerHandler 类 123456789101112131415161718192021222324/** * @Author: cuzz * @Date: 2019/1/1 20:23 * @Description: */public class MyServerHandler extends SimpleChannelInboundHandler&lt;String&gt;&#123; @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception &#123; System.out.println(ctx.channel().remoteAddress() + ": " + msg); ctx.channel().writeAndFlush("from server: " + UUID.randomUUID()); &#125; /** * 出现异常关闭连接 * @param ctx * @param cause * @throws Exception */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 客服端MyClient 类 12345678910111213141516171819202122/** * @Author: cuzz * @Date: 2019/1/1 20:31 * @Description: */public class MyClient &#123; public static void main(String[] args) throws Exception &#123; EventLoopGroup eventLoopGroup = new NioEventLoopGroup(); try &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.group(eventLoopGroup) .channel(NioSocketChannel.class) .handler(new MyClientInitializer()); ChannelFuture channelFuture = bootstrap.connect("localhost",8899).sync(); channelFuture.channel().closeFuture().sync(); &#125; finally &#123; eventLoopGroup.shutdownGracefully(); &#125; &#125;&#125; MyClientInitializer 类 12345678910111213141516/** * @Author: cuzz * @Date: 2019/1/1 20:40 * @Description: */public class MyClientInitializer extends ChannelInitializer&lt;SocketChannel&gt;&#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new LengthFieldBasedFrameDecoder(Integer.MAX_VALUE, 0, 4, 0, 4)); pipeline.addLast(new LengthFieldPrepender(4)); pipeline.addLast(new StringDecoder(CharsetUtil.UTF_8)); pipeline.addLast(new StringEncoder(CharsetUtil.UTF_8)); pipeline.addLast(new MyClientHandler()); &#125;&#125; MyClientHandler 类 1234567891011121314151617181920212223/** * @Author: cuzz * @Date: 2019/1/1 20:42 * @Description: */public class MyClientHandler extends SimpleChannelInboundHandler&lt;String&gt;&#123; @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception &#123; System.out.println(ctx.channel().remoteAddress() + ": " + msg); ctx.writeAndFlush("from clinet: " + UUID.randomUUID()); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; ctx.writeAndFlush("来自客户端的连接！！！"); &#125;&#125; 初始化EventLoopGroup创建一个 bossGroup 和 workGroup 12EventLoopGroup bossGroup = new NioEventLoopGroup();EventLoopGroup workGroup = new NioEventLoopGroup(); EventLoopGroup 翻译过来叫事件循环组，其本身就是一个死循环 bossGroup 是把接受连接，把连接转发给 workGroup ，workGroup 是真正完成用户请求处理的类 EventLoopGroup 是一个接口，在后面循环的过程中可以选择把 Channel 注册上 1234567891011121314/** * Special &#123;@link EventExecutorGroup&#125; which allows registering &#123;@link Channel&#125;s that get * processed for later selection during the event loop. * */public interface EventLoopGroup extends EventExecutorGroup &#123; @Override EventLoop next(); ChannelFuture register(Channel channel); ChannelFuture register(ChannelPromise promise);&#125; NioEventLoopGroup123456789101112131415// 他是一个基于NIO的选择器的对象 public class NioEventLoopGroup extends MultithreadEventLoopGroup &#123; // 0 public NioEventLoopGroup() &#123; this(0); &#125; // 1 public NioEventLoopGroup(int nThreads) &#123; this(nThreads, (Executor) null); &#125; // 2 public NioEventLoopGroup(int nThreads, Executor executor) &#123; this(nThreads, executor, SelectorProvider.provider()); &#125;&#125; MultithreadEventExecutorGroup最终会跳到MultithreadEventExecutorGroup 中的一个构造器中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960protected MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args) &#123; &#125; // 1 if (executor == null) &#123; executor = new ThreadPerTaskExecutor(newDefaultThreadFactory()); &#125; children = new EventExecutor[nThreads]; for (int i = 0; i &lt; nThreads; i ++) &#123; boolean success = false; try &#123; children[i] = newChild(executor, args); success = true; &#125; catch (Exception e) &#123; // TODO: Think about if this is a good exception type throw new IllegalStateException("failed to create a child event loop", e); &#125; finally &#123; if (!success) &#123; for (int j = 0; j &lt; i; j ++) &#123; children[j].shutdownGracefully(); &#125; for (int j = 0; j &lt; i; j ++) &#123; EventExecutor e = children[j]; try &#123; while (!e.isTerminated()) &#123; e.awaitTermination(Integer.MAX_VALUE, TimeUnit.SECONDS); &#125; &#125; catch (InterruptedException interrupted) &#123; // Let the caller handle the interruption. Thread.currentThread().interrupt(); break; &#125; &#125; &#125; &#125; &#125; chooser = chooserFactory.newChooser(children); final FutureListener&lt;Object&gt; terminationListener = new FutureListener&lt;Object&gt;() &#123; @Override public void operationComplete(Future&lt;Object&gt; future) throws Exception &#123; if (terminatedChildren.incrementAndGet() == children.length) &#123; terminationFuture.setSuccess(null); &#125; &#125; &#125;; for (EventExecutor e: children) &#123; e.terminationFuture().addListener(terminationListener); &#125; Set&lt;EventExecutor&gt; childrenSet = new LinkedHashSet&lt;EventExecutor&gt;(children.length); Collections.addAll(childrenSet, children); readonlyChildren = Collections.unmodifiableSet(childrenSet); &#125; ThreadPerTaskExecutor代码1中，executor = new ThreadPerTaskExecutor(newDefaultThreadFactory());，跟进去 123456789101112131415public final class ThreadPerTaskExecutor implements Executor &#123; private final ThreadFactory threadFactory; public ThreadPerTaskExecutor(ThreadFactory threadFactory) &#123; if (threadFactory == null) &#123; throw new NullPointerException("threadFactory"); &#125; this.threadFactory = threadFactory; &#125; @Override public void execute(Runnable command) &#123; threadFactory.newThread(command).start(); &#125;&#125; 这里用到了工厂方法和命令模式，通过传入一个command调用工厂方法 Executor1234567891011121314public interface Executor &#123; /** * Executes the given command at some time in the future. The command * may execute in a new thread, in a pooled thread, or in the calling * thread, at the discretion of the &#123;@code Executor&#125; implementation. * * @param command the runnable task * @throws RejectedExecutionException if this task cannot be * accepted for execution * @throws NullPointerException if command is null */ void execute(Runnable command);&#125; 这是在java.util.concurrent 下的一个接口，最主要的实现方式把一个task传入，新建一个线程运行 12345class ThreadPerTaskExecutor implements Executor &#123; public void execute(Runnable r) &#123; new Thread(r).start(); &#125;&#125; 也可以通过一系列的限制，比如序列化等一下操作 123456789101112131415161718192021222324252627282930class SerialExecutor implements Executor &#123; final Queue&lt;Runnable&gt; tasks = new ArrayDeque&lt;Runnable&gt;(); final Executor executor; Runnable active; SerialExecutor(Executor executor) &#123; this.executor = executor; &#125; public synchronized void execute(final Runnable r) &#123; tasks.offer(new Runnable() &#123; public void run() &#123; try &#123; r.run(); &#125; finally &#123; scheduleNext(); &#125; &#125; &#125;); if (active == null) &#123; scheduleNext(); &#125; &#125; protected synchronized void scheduleNext() &#123; if ((active = tasks.poll()) != null) &#123; executor.execute(active); &#125; &#125;&#125; 其中非常常用用的几个实现如：ExecutorService，ThreadPoolExecutor 下面是官方文档 The Executor implementations provided in this package implement ExecutorService, which is a more extensive interface. The ThreadPoolExecutor class provides an extensible thread pool implementation. The Executors class provides convenient factory methods for these Executors.The Executor implementations provided in this package implement ExecutorService, which is a more extensive interface. The ThreadPoolExecutor class provides an extensible thread pool implementation. The Executors class provides convenient factory methods for these Executors. 回顾一下 MyServer 中启动的代码 123456789101112try &#123; ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new MyServerinitializer()); ChannelFuture channelFuture = bootstrap.bind(8899).sync(); channelFuture.channel().closeFuture().sync();&#125; finally &#123; bossGroup.shutdownGracefully(); bossGroup.shutdownGracefully();&#125; ServerBootstrap1public class ServerBootstrap extends AbstractBootstrap&lt;ServerBootstrap, ServerChannel&gt; &#123; ... &#125; ServerBootstrap 是 Bootstrap子类，容易的地启动一个 ServerChannel ServerChannel接受一个即将到来的连接，创建子 Channel 12345678/** * A &#123;@link Channel&#125; that accepts an incoming connection attempt and creates * its child &#123;@link Channel&#125;s by accepting them. &#123;@link ServerSocketChannel&#125; is * a good example. */public interface ServerChannel extends Channel &#123; // This is a tag interface.&#125; 其有很多实现的子类，其中 NioServerSocketChannel 是我们比较关注的 方法链1234bootstrap.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new MyServerinitializer()); .group(bossGroup, workGroup) 我们把 bossGroup 和 workGroup 传入进去，由于是方法链，肯定返回本身，跟踪下去 12345678910111213141516/** * Set the &#123;@link EventLoopGroup&#125; for the parent (acceptor) and the child (client). These * &#123;@link EventLoopGroup&#125;'s are used to handle all the events and IO for &#123;@link ServerChannel&#125; and * &#123;@link Channel&#125;'s. */public ServerBootstrap group(EventLoopGroup parentGroup, EventLoopGroup childGroup) &#123; super.group(parentGroup); if (childGroup == null) &#123; throw new NullPointerException("childGroup"); &#125; if (this.childGroup != null) &#123; throw new IllegalStateException("childGroup set already"); &#125; this.childGroup = childGroup; return this;&#125; 这个步，就是给 bossGroup 和 workGroup 赋值给 ServerBootstrap 的实例 .channel(NioServerSocketChannel.class) 方法，接受的是一个 class 对象，一般接受 class 对象大多数与反射有关系 1234567891011/** * The &#123;@link Class&#125; which is used to create &#123;@link Channel&#125; instances from. * You either use this or &#123;@link #channelFactory(io.netty.channel.ChannelFactory)&#125; if your * &#123;@link Channel&#125; implementation has no no-args constructor. */public B channel(Class&lt;? extends C&gt; channelClass) &#123; if (channelClass == null) &#123; throw new NullPointerException("channelClass"); &#125; return channelFactory(new ReflectiveChannelFactory&lt;C&gt;(channelClass));&#125; 进入 channelFactory 方法 1234567891011/** * &#123;@link io.netty.channel.ChannelFactory&#125; which is used to create &#123;@link Channel&#125; instances from * when calling &#123;@link #bind()&#125;. This method is usually only used if &#123;@link #channel(Class)&#125; * is not working for you because of some more complex needs. If your &#123;@link Channel&#125; implementation * has a no-args constructor, its highly recommend to just use &#123;@link #channel(Class)&#125; for * simplify your code. */@SuppressWarnings(&#123; "unchecked", "deprecation" &#125;)public B channelFactory(io.netty.channel.ChannelFactory&lt;? extends C&gt; channelFactory) &#123; return channelFactory((ChannelFactory&lt;C&gt;) channelFactory);&#125; 如果有无参数的构造方法推荐使用，这样可以简化代码 Q：为什么必须要有无参数构造方法呢？ A : 一般来说，获取一个实例如下生成，所以必须有无参数构造方法 12Class class = Class.forName(className);Object object = class.newInstance(); // 只能调用无参构造函数 我们在来看看 NioServerSocketChannel A {@link io.netty.channel.socket.ServerSocketChannel} implementation which uses NIO selector based implementation to accept new connections. .childHandler(new MyServerinitializer()); 设置用于请求的 Handler 12345678910/** * Set the &#123;@link ChannelHandler&#125; which is used to serve the request for the &#123;@link Channel&#125;'s. */public ServerBootstrap childHandler(ChannelHandler childHandler) &#123; if (childHandler == null) &#123; throw new NullPointerException("childHandler"); &#125; this.childHandler = childHandler; return this;&#125; 这里其实有 handler 和 childHandler 一个是给 bossGroup 使用的，一个是给 workGroup 使用的 启动1ChannelFuture channelFuture = bootstrap.bind(8899).sync(); ChannelFutureChannelFuture 先是继承了自己提供的 Future ，自身的 Future 又继承 java.util.concurrent.Future&lt;V&gt; ，我们先看看 JUC 中 Future 和 FutureTask JUC.Future看看其中几个主要的方法，从方法名也知道是做什么的 123456789101112public interface Future&lt;V&gt; &#123; boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; 文档： A Future represents the result of an asynchronous computation. Methods are provided to check if the computation is complete, to wait for its completion, and to retrieve the result of the computation. The result can only be retrieved using method get when the computation has completed, blocking if necessary until it is ready. Cancellation is performed by the cancel method. Additional methods are provided to determine if the task completed normally or was cancelled. Once a computation has completed, the computation cannot be cancelled. If you would like to use a Future for the sake of cancellability but not provide a usable result, you can declare types of the form Future&lt;?&gt; and return null as a result of the underlying task. 使用： 1234567891011121314151617181920interface ArchiveSearcher &#123; String search(String target); &#125;class App &#123; ExecutorService executor = ... ArchiveSearcher searcher = ... void showSearch(final String target) throws InterruptedException &#123; Future&lt;String&gt; future = executor.submit(new Callable&lt;String&gt;() &#123; public String call() &#123; return searcher.search(target); &#125; &#125;); displayOtherThings(); // do other things while searching try &#123; displayText(future.get()); // use future &#125; catch (ExecutionException ex) &#123; cleanup(); return; &#125; &#125;&#125; JUC.FutureTask The FutureTask class is an implementation of Future that implements Runnable, and so may be executed by an Executor. For example, the above construction with submit could be replaced by: 12345FutureTask&lt;String&gt; future = new FutureTask&lt;String&gt;(new Callable&lt;String&gt;() &#123; public String call() &#123; return searcher.search(target); &#125;&#125;);executor.execute(future); 可以通过 Executor 的实例去执行，最后再从 future 中获取 Netty.Future123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public interface Future&lt;V&gt; extends java.util.concurrent.Future&lt;V&gt; &#123; boolean isSuccess(); boolean isCancellable(); Throwable cause(); /** * Adds the specified listener to this future. The * specified listener is notified when this future is * &#123;@linkplain #isDone() done&#125;. If this future is already * completed, the specified listener is notified immediately. */ Future&lt;V&gt; addListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); /** * Adds the specified listeners to this future. The * specified listeners are notified when this future is * &#123;@linkplain #isDone() done&#125;. If this future is already * completed, the specified listeners are notified immediately. */ Future&lt;V&gt; addListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); /** * Removes the first occurrence of the specified listener from this future. * The specified listener is no longer notified when this * future is &#123;@linkplain #isDone() done&#125;. If the specified * listener is not associated with this future, this method * does nothing and returns silently. */ Future&lt;V&gt; removeListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener); /** * Removes the first occurrence for each of the listeners from this future. * The specified listeners are no longer notified when this * future is &#123;@linkplain #isDone() done&#125;. If the specified * listeners are not associated with this future, this method * does nothing and returns silently. */ Future&lt;V&gt; removeListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners); // 等待Future完成 Future&lt;V&gt; sync() throws InterruptedException; Future&lt;V&gt; syncUninterruptibly(); Future&lt;V&gt; await() throws InterruptedException; Future&lt;V&gt; awaitUninterruptibly(); boolean await(long timeout, TimeUnit unit) throws InterruptedException; boolean await(long timeoutMillis) throws InterruptedException; boolean awaitUninterruptibly(long timeout, TimeUnit unit); boolean awaitUninterruptibly(long timeoutMillis); V getNow(); @Override boolean cancel(boolean mayInterruptIfRunning);&#125; 我们主要看看 xxListener 方法，一后缀为 Listener 使用了观察者模式 它比 JUC.Future 更厉害的是就因为这个 Listener ，虽然 JUC.Future 可以调用 get() 方法，获取异步结果，但是我们不知道什么时候去调用，调用早了就堵塞在那里；而 Netty.Future 使用了观察者模式，当完成时会自动触发 ChannelFuture我们回到 ChannelFuture ，都重写了 Netty.Future 中的方法，返回值是 Future 的子类，java5或者以前，必须一样，java7以后可以不同，但是必须是父类返回值的派生类 12345678910111213141516171819202122232425262728293031public interface ChannelFuture extends Future&lt;Void&gt; &#123; /** * Returns a channel where the I/O operation associated with this * future takes place. */ Channel channel(); @Override ChannelFuture addListener(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt; listener); @Override ChannelFuture addListeners(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt;... listeners); @Override ChannelFuture removeListener(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt; listener); @Override ChannelFuture removeListeners(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt;... listeners); @Override ChannelFuture sync() throws InterruptedException; @Override ChannelFuture syncUninterruptibly(); @Override ChannelFuture await() throws InterruptedException; @Override ChannelFuture awaitUninterruptibly(); 文档： io.netty.channelpublic interface ChannelFutureextends Future The result of an asynchronous Channel I/O operation. All I/O operations in Netty are asynchronous. It means any I/O calls will return immediately with no guarantee that the requested I/O operation has been completed at the end of the call. Instead, you will be returned with a ChannelFuture instance which gives you the information about the result or status of the I/O operation. A ChannelFuture is either uncompleted or completed. When an I/O operation begins, a new future object is created. The new future is uncompleted initially - it is neither succeeded, failed, nor cancelled because the I/O operation is not finished yet. If the I/O operation is finished either successfully, with failure, or by cancellation, the future is marked as completed with more specific information, such as the cause of the failure. Please note that even failure and cancellation belong to the completed state.1234567891011121314151617&gt; +---------------------------+&gt; | Completed successfully |&gt; +---------------------------+&gt; +----&gt; isDone() = true |&gt; +--------------------------+ | | isSuccess() = true |&gt; | Uncompleted | | +===========================+&gt; +--------------------------+ | | Completed with failure |&gt; | isDone() = false | | +---------------------------+&gt; | isSuccess() = false |----+----&gt; isDone() = true |&gt; | isCancelled() = false | | | cause() = non-null |&gt; | cause() = null | | +===========================+&gt; +--------------------------+ | | Completed by cancellation |&gt; | +---------------------------+&gt; +----&gt; isDone() = true |&gt; | isCancelled() = true |&gt; +---------------------------+&gt; Various methods are provided to let you check if the I/O operation has been completed, wait for the completion, and retrieve the result of the I/O operation. It also allows you to add ChannelFutureListeners so you can get notified when the I/O operation is completed. 推荐使用监听器而不是等待的方法1234567891011121314151617181920// BAD - NEVER DO THIS@Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) &#123; ChannelFuture future = ctx.channel().close(); future.awaitUninterruptibly(); // Perform post-closure operation // ...&#125;// GOOD@Overridepublic void channelRead(ChannelHandlerContext ctx, Object msg) &#123; ChannelFuture future = ctx.channel().close(); future.addListener(new ChannelFutureListener() &#123; public void operationComplete(ChannelFuture future) &#123; // Perform post-closure operation // ... &#125; &#125;);&#125; 不要混淆连接超时和等待超时​12345678910111213141516171819202122232425262728293031// BAD - NEVER DO THISBootstrap b = ...;ChannelFuture f = b.connect(...);f.awaitUninterruptibly(10, TimeUnit.SECONDS);if (f.isCancelled()) &#123; // Connection attempt cancelled by user&#125; else if (!f.isSuccess()) &#123; // You might get a NullPointerException here because the future // might not be completed yet. f.cause().printStackTrace();&#125; else &#123; // Connection established successfully&#125;// GOODBootstrap b = ...;// Configure the connect timeout option.b.option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 10000);ChannelFuture f = b.connect(...);f.awaitUninterruptibly();// Now we are sure the future is completed.assert f.isDone();if (f.isCancelled()) &#123; // Connection attempt cancelled by user&#125; else if (!f.isSuccess()) &#123; f.cause().printStackTrace();&#125; else &#123; // Connection established successfully&#125; bind()方法当我们调用 bind 方法时，才真正的启动服务器​1ChannelFuture channelFuture = bootstrap.bind(8899).sync(); 通过一些判断最终到 doBind 方法上 1234567891011121314151617181920212223242526272829303132333435private ChannelFuture doBind(final SocketAddress localAddress) &#123; final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); if (regFuture.cause() != null) &#123; return regFuture; &#125; if (regFuture.isDone()) &#123; // At this point we know that the registration was complete and successful. ChannelPromise promise = channel.newPromise(); doBind0(regFuture, channel, localAddress, promise); return promise; &#125; else &#123; // Registration future is almost always fulfilled already, but just in case it's not. final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; Throwable cause = future.cause(); if (cause != null) &#123; // Registration on the EventLoop failed so fail the ChannelPromise directly to not cause an // IllegalStateException once we try to access the EventLoop of the Channel. promise.setFailure(cause); &#125; else &#123; // Registration was successful, so set the correct executor to use. // See https://github.com/netty/netty/issues/2586 promise.registered(); doBind0(regFuture, channel, localAddress, promise); &#125; &#125; &#125;); return promise; &#125;&#125; initAndRegister()方法这个主要是初始化和注册，比较复杂，后续在分析 加油！！！]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[201812]]></title>
    <url>%2F2018%2F12%2F30%2F201812%2F</url>
    <content type="text"><![CDATA[总结这个月一边忙着实验，一边写代码，做计算的好处就是时间比较充裕，早上来到实验室用脚本把任务一提交就可以安心的写代码了 面试上个月到小米面试了，很遗憾没有面上，不过还是有点收获的，自己学着迷茫了，就去面试一下，看看有什么自己没有掌握好，更好的考验自己。 这次面试我的面试官主要问的很多基础的问题 自我介绍 对操作系统了不了解，说下队列 说下 Dubbo 算法 树的按层打印 把数值转化为中文大写金额 没有问 Java 的相关内容，自己答的不是很好，又有学习的动力了，回来就马上补这些知识 剑指Offer这个月把里面的题又刷了一遍，比起第一次刷代码更简洁了，时间复杂度也能优化更好，刷题还是很有意义的 视频汇编语言程序设计这是清华大学公开课，讲得挺简单易懂，自己对汇编程序过了一遍，对汇编有了一个简单的认识，汇编是对指令的一种抽象，更贴近机器，对代码有了一个新的认识 操作系统这也是清华大学公开课，由于自己对这些基础知识比较缺乏，现在在学校，还是要踏踏实实把这些基础知识学好，才能走得更远 看点CSAPP最近也在看 CSAPP 这本书，这个是对这本一个简单的提炼，先掌握主干再慢慢消化书上的内容，总结的很好 下月计划 看完《编码》 Leetcode 50 道 熟悉一下 Netty]]></content>
      <categories>
        <category>monthly</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[201811]]></title>
    <url>%2F2018%2F11%2F30%2F201811%2F</url>
    <content type="text"><![CDATA[看到阮一峰老师写的每周技术分享，自己想写一个类似来记录一下自己，方便以后自己查找，我就每月总结一次。科研上我需要每个月要发一份总结导师，而这个总结主要是技术上的，也包括自己平时的所见所闻，希望自己能坚持写下去 总结springcloud-vue-project上一个月主要写了一个 Vue + SpringCloud 的项目，项目大部分写完了，对微服务的知识我那么一点点入门，主要架构图如下 面试想出去实习，投了两个面试，一个做 OMS 系统的物流公司 先是做了一套卷子，两道算法题比较简单，数据库感觉没答好，很久没有写 SQL 基础知识问得比较少，就问了一个AtomicInteger怎么保证线程安全，有道题目中我写了这个类 因为我有实习经历，就问了一些项目相关的，怎么解决项目中遇到的困难，一些常用的中间件熟不熟，能不能自己部署，Docker会不会用之类的，后面就和产品经历聊了聊，就快速的结束了 还有一个就是小米了，下周面试，希望能成功 Leetcode最近每天都会刷刷 leetcode，刚开始的时候痛不欲生，慢慢的越来越顺了，当然有一部分原因是为了面试，不过我觉得刷题有助于自己的代码能量，挺有意思的 工具SurfingkeysSurfingkeys 和现有的一些插件一样，让你尽可能的通过键盘来使用 Chrome/Firefox 浏览器，比如跳转网页，上下左右滚屏。但不只是给vim用户使用，Surfingkeys的基本特性是让你自己写一段 Javascript 脚本，然后通过 mapkey 映射到某些按键。之后当你按了那几个键以后，对应的Javascript 脚本就会被执行。 玩了一下，特别棒，解放鼠标 视频计算机科学速成课这是 Youtube 上很火的速成课，其中这门讲的是计算机相关的知识，一共40集，每集很短只有10分钟，但是知识量巨多，包含计算科学的各个方面 gitbub 地址 第 1 集：计算机早期历史 第 2 集：电子计算机 第 3 集：布尔逻辑和逻辑门 第 4 集：二进制 第 5 集：算数逻辑单元 - ALU 第 6 集：寄存器和内存 第 7 集：中央处理器（CPU) 第 8 集：指令和程序 第 9 集：高级 CPU 设计 第 10 集：早期的编程方式 第 11 集：编程语言发展史 第 12 集：编程基础 - 语句和函数 第 13 集：算法入门 第 14 集：数据结构 第 15 集：阿兰·图灵 第 16 集：软件工程 第 17 集：集成电路与摩尔定律 第 18 集：操作系统 第 19 集：内存&amp;储存介质 第 20 集：文件系统 第 21 集：压缩 第 22 集：命令行界面 第 23 集：屏幕与 2D 图形显示 第 24 集：冷战和消费主义 第 25 集：个人计算机革命 第 26 集：图形用户界面 (GUI) 第 27 集：3D 图形 第 28 集：计算机网络 第 29 集：互联网 第 30 集：万维网 第 31 集：计算机安全 第 32 集：黑客与攻击 第 33 集：加密 第 34 集：机器学习与人工智能 第 35 集：计算机视觉 第 37 集：机器人 第 38 集：计算机心理学 第 39 集：教育科技 第 40 集：奇点，天网，计算机的未来 中国通史-古代史《中国通史》以史诗般的宏大叙事手法，生动再现了中华文明从原始社会到二十一世纪初的完整发展历程。内容涉及历史、政治、经济、军事、哲学、宗教、文学、 艺术、语言、考古、天文、地理、科技、人物、民俗以及中外交流等各个方面，直观地再现了中华民族五千年文明历史全景，全面展示了华夏文明的古今传承。 写代码写累了看看，作为一个工科生，对历史知识了解的不多，这部记录篇值得看看，看看古代中国人民的聪明才智，看看一个朝代的兴盛衰败。 看点技术分享周刊这是阮老师技术分享周刊，每周五更新，里面分享了很多有用的工具和教程，非常值得关注。我每周都会第一时间查看，现在已经更新到33期了，如果有好的链接可以 issue Computer Science Learning Notes这是一个 Java 相关的知识库，总结的很好，排版也非常漂亮，不管是应付面试还是提升自己都很有帮助，一共包括十个版块]]></content>
      <categories>
        <category>monthly</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[堆排序]]></title>
    <url>%2F2018%2F11%2F23%2F%E5%A0%86%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[今天看到一篇面经，算法题是手写堆排序，《算法》放在书架已经有一段时间了，想试试能不能写出来，然而并没有，所以记录一下 自顶到底构造堆这是一道 lintcode上面的题目堆化 构造一个堆只需要从左到右遍历数组，每次只要保证所遍历到的位子能满足堆的条件 12345678910111213141516171819202122232425public class Solution &#123; /* * @param A: Given an integer array * @return: nothing */ public void heapify(int[] A) &#123; for (int i = 0; i &lt; A.length; i++) &#123; swim(A, i); &#125; &#125; // 上浮 private void swim(int[] A, int i) &#123; while(i &gt; 0 &amp;&amp; A[i] &lt; A[(i-1) / 2]) &#123; swap(A, i, (i-1) / 2); i = (i-1) / 2; &#125; &#125; private void swap(int[] A, int i, int j) &#123; int temp = A[i]; A[i] = A[j]; A[j] = temp; &#125;&#125; 自底到顶构造堆而堆排序采用的是自底到顶构造堆，每次把第一个元素和最后一个元素交换，交换之后把第一个元素下沉，同时堆数组减一，下面是代码 1234567891011121314151617181920212223242526272829303132333435363738394041public class Heap &#123; private static void heapSort(int[] array) &#123; int len = array.length - 1; for (int i = (len - 1) / 2; i &gt;= 0; i--) &#123; sink(array, i, len); &#125; printArr(array); while (len &gt;= 0) &#123; swap(array, 0, len); sink(array, 0, --len); &#125; &#125; private static void sink(int[] array, int i, int len) &#123; while (i * 2 + 1 &lt;= len) &#123; int j = i * 2 + 1; if (j + 1 &lt;= len &amp;&amp; array[j+1] &gt; array[j]) j++; if (array[i] &gt; array[j]) break; swap(array, i, j); i = j; &#125; &#125; private static void swap(int[] array, int i, int j) &#123; int temp = array[i]; array[i] = array[j]; array[j] = temp; &#125; public static void main(String[] args) &#123; int[] array = &#123;2, 3, 1, 6, 4, 5, 2, 1&#125;; heapSort(array); printArr(array); &#125; private static void printArr(int[] array) &#123; Arrays.stream(array).forEach(a -&gt; System.out.print(a + " ")); System.out.println(); &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>堆排序</tag>
        <tag>lintcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell入门]]></title>
    <url>%2F2018%2F10%2F04%2FShell%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Shell是操作系统（内核）与用户之间的桥梁 Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。Shell 既是一种命令语言，又是一种程序设计语言。 Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务。 Ken Thompson 的 sh 是第一种 Unix Shell，Windows Explorer 是一个典型的图形界面 Shell Shell编程之Hello World编写一个hello world shell一般使用.sh作为后缀 123456#!/bin/bash # 使用/bin/sh来解释执行 # auto echo hello world! # 解释这个脚本是干什么的# by authors cuzz # 作者和时间一些信息echo "hello world!" 给脚本添加执行权限 1&gt; chmod +x hello.sh Shell编程之变量Shell变量可以分为两类：局部变量和环境变量 12345678#!/bin/bash# define path variables# by authors cuzzname=cuzz # 等号两边不能有空格echo "my name is $name" # 使用$引用 基本变量 1234567echo $PWD # 当前路径echo $0 # 脚本名echo $1 # 第一个参数echo $2 # 第二个参数echo $? # 判断上一个命令是否正确echo $* # 所有参数echo $# # 参数的个数 Shell编程之if条件语句比较大小 12345678910111213#!/bin/bash# if test# by authors cuzznum=100# 计算使用两个小括号if (($num &gt; 10)); then echo "this num greater than 10."else echo "this num littler than 10."fi 逻辑运算符 运算符 说明 举例 -eq 检测两个数是否相等，相等返回 true。 [ \$a -eq $b ] 返回 false。 -ne 检测两个数是否不相等，不相等返回 true。 [ \$a -ne $b ] 返回 true。 -gt 检测左边的数是否大于右边的，如果是，则返回 true。 [ \$a -gt $b ] 返回 false。 -lt 检测左边的数是否小于右边的，如果是，则返回 true。 [ \$a -lt $b ] 返回 true。 -ge 检测左边的数是否大于等于右边的，如果是，则返回 true。 [ \$a -ge $b ] 返回 false。 -le 检测左边的数是否小于等于右边的，如果是，则返回 true。 [ \$a -le $b ] 返回 true。 目录 操作符 说明 举例 -d file 检测文件是否是目录，如果是，则返回 true。 [ -d $file ] 返回 false。 -f file 检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。 [ -f $file ] 返回 true。 -p file 检测文件是否是有名管道，如果是，则返回 true。 [ -p $file ] 返回 false。 -e file 检测文件（包括目录）是否存在，如果是，则返回 true。 [ -e $file ] 返回 true。 创建文件 12345678910111213#!/bin/bash# if test# by authors cuzzDIR=cuzzif [ ! -d $DIR ]; then # 都有空格 mkdir $DIR echo "this $DIR create success."else echo "this dir is exit."fi 测试文件是否存在 123456789101112#!/bin/bash# if test# by authors cuzzfile=test.txtif [ ! -e $file ]; then echo "OK" &gt;&gt; $file # &gt;&gt;是追加内容 &gt;是覆盖内容else cat $filefi mysql备份 12345678910111213141516171819202122232425262728293031323334353637#!/bin/bash# auto backup mysql db# by authors cuzz# define backup pathBAK_DIR=/data/backup/`date +%Y%m%d` # 反引号可以把里面当作命令来解析 # mysqlMYSQLDB=testMYSQLUSER=rootMYSQLPW=123456MYSQLCMD=/usr/bin/mysqldump # 备份命令# 判断是否是rootif [ $UID -ne 0 ]; then echo "Only root can execute Shell." exitfiif [ ! -d $BAK_DIR ]; then mkdir -p $BAK_DIR # -p 父目录不存在就创建 echo "The $BAK_DIR create success."else echo "This $BAK_DIR is exist."fi# mysql backup command$MYSQLCMD -u$MYSQLUSER -p$MYSQLPW -d $MYSQLDB &gt;$BAK_DIR/$MYSQLDB.sqlif [ $? -eq 0 ]; then echo "backup success."else echo "backup fail."fi Shell编程之for循环基本语句 123456#!/bin/bashfor i in `seq 1 15`do echo "the number is $i."done 求和 12345678910#!/bin/bashsum=0for ((i=1; i&lt;=100; i++)) # 双括号用于运算相当与其他语言的单括号do sum=`expr $sum + $i` # expr用于计算doneecho "$sum" 打包，只能打包到最后一个，后面的会把前面的覆盖了 1234567#!/bin/bashfor file in `find ./ -name "*.sh"`do tar -czf all.tgz $filedone Shell编程之while循环使用 12345678#!/bin/bashi=0while [[ $i -lt 10 ]] # (( $i &lt; 10))是一样的do echo "$i" ((i++))done 结合read使用 123456#!/bin/bashwhile read line # 把读取的东西赋值给linedo echo $linedone &lt;/etc/hosts # 从哪里读取 Shell编程之数组Shell 数组用括号来表示，元素用”空格”符号分割开，语法格式如下： 12345678910111213my_array=(A B "C" D) # 定义数组array_name[0]=value0 # 使用下标来定义array_name[1]=value1array_name[2]=value2$&#123;array_name[0]&#125; # 读取第一个元素$&#123;my_array[*]&#125; # 读取所有元素 $&#123;my_array[@]&#125; # 读取所有元素$&#123;#my_array[*]&#125; # 读取数组长度$&#123;#my_array[@]&#125; # 读取数组长度 Shell编程之函数无返回值得函数 12345678sayHello()&#123; # 定义函数一 echo "hello"&#125;function sayHelloWorld()&#123; # 定义函数二 echo "hello world"&#125;sayhell # 使用函数 有返回值得，使用return只能返回0-255 123456789function sum()&#123; returnValue=$(( $1 + $2 )) return $returnValue&#125;sum 22 4echo $? 可以使用echo来传递参数 12345678910111213function length()&#123; str=$1 result=0 if [ "$str" != "" ] ; then result=$&#123;#str&#125; fi echo "$result"&#125;len=$(length "abc123") # 调用echo "The string's length is $len " Shell编程之sed命令把test.txt中的old修改为new，要使用-i才能插入 1&gt; sed -i &apos;s/old/new/s&apos; test.txt 在每行行前面添加一个cuzz 1&gt; sed -i sed &apos;s/^/&amp;cuzz/g&apos; test.txt 在每行的末尾添加一个cuzz 1&gt; sed -i &apos;s/$/&amp; cuzz/g&apos; test.txt 匹配某一行，在下方插入一行，找到cuzz这行在下方插入#### 1&gt; sed &apos;/cuzz/a #######&apos; test.txt 在之前添加一行，只要把a改成i 1&gt; sed &apos;/cuzz/i #######&apos; test.txt 打印 123&gt; sed -n &apos;/cuzz/p&apos; test.txt # 打印含有cuzz这一行&gt; sed -n &apos;1p&apos; test.txt # 打印第一行&gt; sed -n &apos;1,5p&apos; text.txt # 打印1到5行 查找最大和最小值 number.txt 123412 324 56 0034 -23 345345 349- 245 345 345 0989 0459 -25 命令 123456cat number.txt | sed 's/ /\n/g' | grep -v "^$" | sort -nr | sed -n '1p;$p'sed 's/ /\n/g' # 把所有空格换成换行grep -v "^$" # 去掉所有空格sort -nr # 降序排列sed -n '1p;$p # 找出第1行和最后一行 Shell编程之grep命令 -a ：将 binary 文件以 text 文件的方式搜寻数据 -c ：计算找到 ‘搜寻字符串’ 的次数 -i ：忽略大小写的不同，所以大小写视为相同 -n ：顺便输出行号 -v ：反向选择，亦即显示出没有 ‘搜寻字符串’ 内容的那一行 –color=auto ：可以将找到的关键词部分加上颜色的显示 egrep 和grep -E 相同，可以使用正则表达式 Shell编程之awk命令123456789# 每行按空格或TAB分割cat test.txt | awk '&#123;print $1&#125;' # 行匹配语句 awk '' 只能用单引号# 指定分割awk -F #-F相当于内置变量FS, 指定分割字符cat test.txt | awk -F: '&#123;print $1&#125;' # 以分号分割# 指定添加某些内容cat test.txt | awk -F: '&#123;print "haha" $1&#125;' # 提前出来再添加haha Shell编程之find命令基本命令 123456find /dir -name "test.txt" # 在/dir目录下查找find . -name "test.txt" # 在当前目录下找 find . -maxdepth 1 -name "text.txt" # 只遍历一层find . -type f -name "text" # 指定类型find . -name "text" -mtime -1 # 指定时间find . -size +20M # 指定大小 查找并执行其他命令 1find . -name "text.txt" -exec rm -rf &#123;&#125; \; # 后面&#123;&#125; \是固定格式]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring注解驱动开发（三）]]></title>
    <url>%2F2018%2F09%2F25%2FSpring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[注解可以简化配置，提高效率 The Spring Framework provides a comprehensive programming and configuration model for modern Java-based enterprise applications - on any kind of deployment platform. 属性赋值@value赋值使用@Value赋值 基本数值 可以写SPEL表达式 #{} 可以${}获取配置文件信息（在运行的环境变量中的值） 使用xml时候导入配置文件是 1&lt;context:property-placeholder location="classpath:person.properties"/&gt; 使用注解可以在配置类添加一个@PropertySource注解把配置文件中k/v保存到运行的环境中 使用${key}来获取 1234567891011121314/** * @Author: cuzz * @Date: 2018/9/24 18:43 * @Description: */@PropertySource(value = &#123;"classpath:/person.properties"&#125;)@Configurationpublic class MainConfigOfPropertyValue &#123; @Bean public Person person() &#123; return new Person(); &#125;&#125; Person 类 123456789101112@Datapublic class Person &#123; @Value("vhuj") private String name; @Value("#&#123;20-2&#125;") private Integer age; @Value("$&#123;person.nickName&#125;") private String nickName;&#125; 测试 1234567891011@Testpublic void test01() &#123; printBean(applicationContext); System.out.println("---------------------------"); Person person = (Person) applicationContext.getBean("person"); System.out.println(person); System.out.println("---------------------------");&#125; 输出 123---------------------------Person(name=vhuj, age=18, nickName=三三)--------------------------- 自动装配@Autowired@Qualifier@Primary自动转配： Spring利用依赖注入（DI），完成对IOC容器中各个组件的依赖关系赋值 @Autowired自动注入: a. 默认优先按照类型去容器中寻找对应的组件，如果找到去赋值 b. 如果找到到相同类型的组件，再将属性名（BookDao bookdao）作为组件的id去容器中查找 c. 接下来还可以使用@Qualifier(&quot;bookdao&quot;)明确指定需要装配的id d. 默认是必须的，我们可以指定 @Autowired(required=false)，指定非必须 @Primary让Spring自动装配时首先装配 自动装配@Resource和@InjectSpring还支持使用@Resource (JSR250) 和@Inject (JSR330) 注解，这两个是java规范 @Resource和@Autowired一样实现自动装配功能，默认是按组件名称进行装配的 没有支持@Primary和@Autowird(required=false)的功能 自动装配其他地方的自动装配@Autowired：构造器、参数、方法属性等 标注到方法位子上@Bean+方法参数，参数从容器中获取 12345678910111213141516171819202122232425/** * @Author: cuzz * @Date: 2018/9/24 20:57 * @Description: */public class Boss &#123; // 属性 @Autowired private Car car; // 构造器 如果构造器只有一个有参构造器可以省略 @Autowired public Boss(@Autowired Car car) &#123; &#125; public Car getCar() &#123; return car; &#125; // set方法 @Autowired // 参数 public void setCar(@Autowired Car car) &#123; this.car = car; &#125;&#125; 自动装配Aware注入Spring底层注解自定义组件想要使用Spring容器底层的一些组件（ApplicationContext，BeanFactory 等等），自定义组件实现xxxAware，在创建对象的时候会调用接口规定的方法注入相关的组件 1234567891011/** * Marker superinterface indicating that a bean is eligible to be * notified by the Spring container of a particular framework object * through a callback-style method. Actual method signature is * determined by individual subinterfaces, but should typically * consist of just one void-returning method that accepts a single * argument. */public interface Aware &#123;&#125; 我们实现几个常见的Aware接口 12345678910111213141516171819202122232425/** * @Author: cuzz * @Date: 2018/9/25 10:18 * @Description: */@Componentpublic class Red implements BeanNameAware ,BeanFactoryAware, ApplicationContextAware &#123; private ApplicationContext applicationContext; @Override public void setBeanName(String name) &#123; System.out.println("当前Bean的名字: " + name); &#125; @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; System.out.println("当前的BeanFactory: " + beanFactory); &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; System.out.println("传入的ioc: " + applicationContext); &#125;&#125; 注入到配置中测试 12345678910111213/** * @Author: cuzz * @Date: 2018/9/25 10:28 * @Description: */public class IOCTestAware &#123; @Test public void test01() &#123; AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfAware.class); &#125;&#125; 测试结果 123当前Bean的名字: red当前的BeanFactory: org.springframework.beans.factory.support.DefaultListableBeanFactory@159c4b8: defining beans [org.springframework.context.annotation.internalConfigurationAnnotationProcessor,org.springframework.context.annotation.internalAutowiredAnnotationProcessor,org.springframework.context.annotation.internalRequiredAnnotationProcessor,org.springframework.context.annotation.internalCommonAnnotationProcessor,org.springframework.context.event.internalEventListenerProcessor,org.springframework.context.event.internalEventListenerFactory,mainConfigOfAware,red]; root of factory hierarchy传入的ioc: org.springframework.context.annotation.AnnotationConfigApplicationContext@1e89d68: startup date [Tue Sep 25 10:29:17 CST 2018]; root of context hierarchy 把Spring自定义组件注入到容器中 原理： 1public interface ApplicationContextAware extends Aware &#123;&#125; 通过 Debug 方式，定位到 org.springframework.context.support.ApplicationContextAwareProcessor#postProcessBeforeInitialization 1234567891011121314151617181920212223@Overridepublic Object postProcessBeforeInitialization(final Object bean, String beanName) throws BeansException &#123; AccessControlContext acc = null; if (System.getSecurityManager() != null &amp;&amp; (bean instanceof EnvironmentAware || bean instanceof EmbeddedValueResolverAware || bean instanceof ResourceLoaderAware || bean instanceof ApplicationEventPublisherAware || bean instanceof MessageSourceAware || bean instanceof ApplicationContextAware)) &#123; acc = this.applicationContext.getBeanFactory().getAccessControlContext(); &#125; if (acc != null) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; invokeAwareInterfaces(bean); return null; &#125; &#125;, acc); &#125; else &#123; invokeAwareInterfaces(bean); // 调用 &#125; 调用下面方法进行判断，每种 xxxAware 接口中只有一种方法，并调用相应的方法 12345678910111213141516171819202122private void invokeAwareInterfaces(Object bean) &#123; if (bean instanceof Aware) &#123; if (bean instanceof EnvironmentAware) &#123; ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment()); &#125; if (bean instanceof EmbeddedValueResolverAware) &#123; ((EmbeddedValueResolverAware) bean).setEmbeddedValueResolver(this.embeddedValueResolver); &#125; if (bean instanceof ResourceLoaderAware) &#123; ((ResourceLoaderAware) bean).setResourceLoader(this.applicationContext); &#125; if (bean instanceof ApplicationEventPublisherAware) &#123; ((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext); &#125; if (bean instanceof MessageSourceAware) &#123; ((MessageSourceAware) bean).setMessageSource(this.applicationContext); &#125; if (bean instanceof ApplicationContextAware) &#123; ((ApplicationContextAware) bean).setApplicationContext(this.applicationContext); &#125; &#125;&#125; xxxAware都是通过xxxProcessor来处理的 比如：ApplicationContextAware 对应 ApplicationContextAwareProcessor 自动装配@Profile环境搭建Profile是Spring为我们提供可以根据当前环境，动态的激活和切换一系组件的功能 a. 使用命令动态参数激活：虚拟机参数位子加载 -Dspring.profiles.active=test b. 使用代码激活环境 我们想配置类 1234567891011121314151617181920212223/** * @Author: cuzz * @Date: 2018/9/25 10:47 * @Description: */@Configurationpublic class MainConfigOfProfile &#123; @Profile(value = "test") @Bean(value = "testDataSource") public DataSource testDataSource() &#123; System.out.println("testDataSource"); return null; &#125; @Profile(value = "dev") @Bean(value = "devDataSource") public DataSource devDataSource() &#123; System.out.println("devDataSource"); return null; &#125;&#125; 测试 12345678910111213141516171819/** * @Author: cuzz * @Date: 2018/9/25 10:59 * @Description: */public class IOCTestProfile &#123; @Test public void test01() &#123; // 1. 使用无参构造器创建一个applicationContext AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(); // 2. 设置要激活的环境 applicationContext.getEnvironment().setActiveProfiles("test"); // 3. 注册主配置类 applicationContext.register(MainConfigOfProfile.class); // 4. 启动刷新容器 applicationContext.refresh(); &#125;&#125; 输出 1testDataSource]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>注解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring注解驱动开发（二）]]></title>
    <url>%2F2018%2F09%2F24%2FSpring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[注解可以简化配置，提高效率 The Spring Framework provides a comprehensive programming and configuration model for modern Java-based enterprise applications - on any kind of deployment platform. 声明周期@Bean指定初始化和销毁方法Bean的生命周期Bean的创建、初始化和销毁是由容器帮我们管理的 我们可以自定义初始化和销毁方法，容器在进行到当前生命周期的时候来调用我买自定义的初始化和销毁方法 构造（对象创建） ​ 单实例： 在容器启动的时候创建 ​ 多实例： 在每次获取的时候创建对象 指定初始化方法初始化：对象创建完成后，并赋值化，调用初始化方法 销毁：单实例是在容器关闭的时候销毁，多实例容器不会管理这个Bean，容器不会调用销毁方法 编写一个Car类 12345678910111213141516171819/** * @Author: cuzz * @Date: 2018/9/23 21:20 * @Description: */public class Car &#123; public Car () &#123; System.out.println("car constructor..."); &#125; public void init() &#123; System.out.println("car...init..."); &#125; public void destroy() &#123; System.out.println("car...destroy..."); &#125;&#125; 在xml中我们可以指定init-method和destroy-method方法，如 1&lt;bean id="car" class="com.cuzz.bean.Car" init-method="init" destroy-method="destroy"&gt;&lt;/bean&gt; 使用注解我们可以 12345678910111213/** * @Author: cuzz * @Date: 2018/9/24 12:49 * @Description: 配置类 */@Configurationpublic class MainConfigOfLifecycle &#123; @Bean(initMethod = "init", destroyMethod = "destroy") public Car car() &#123; return new Car(); &#125;&#125; 测试 12345678910111213141516171819/** * @Author: cuzz * @Date: 2018/9/24 13:00 * @Description: */public class IOCTestLifeCycle &#123; @Test public void test01() &#123; // 创建ioc容器 AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfLifecycle.class); System.out.println("容器创建完成..."); // 关闭容器 System.out.println("---&gt;开始关闭容器"); applicationContext.close(); System.out.println("---&gt;已经关闭容器"); &#125;&#125; 可以看出先创建car，再调用init方法，在容器关闭时销毁实例 123456car constructor...car...init...容器创建完成...---&gt;开始关闭容器car...destroy...---&gt;已经关闭容器 在配置数据源的时候，有很多属性赋值，销毁的时候要把连接给断开 生命周期InitializingBean和DisposableBeanInitializingBean可以通过Bean实现InitializingBean来定义初始化逻辑，是设置好所有属性会调用afterPropertiesSet()方法 1234567891011121314public interface InitializingBean &#123; /** * Invoked by a BeanFactory after it has set all bean properties supplied * (and satisfied BeanFactoryAware and ApplicationContextAware). * &lt;p&gt;This method allows the bean instance to perform initialization only * possible when all bean properties have been set and to throw an * exception in the event of misconfiguration. * @throws Exception in the event of misconfiguration (such * as failure to set an essential property) or if initialization fails. */ void afterPropertiesSet() throws Exception;&#125; DisposableBean可以通过Bean实现DisposableBean来定义销毁逻辑，会调用destroy()方法 1234567891011public interface DisposableBean &#123; /** * Invoked by a BeanFactory on destruction of a singleton. * @throws Exception in case of shutdown errors. * Exceptions will get logged but not rethrown to allow * other beans to release their resources too. */ void destroy() throws Exception;&#125; 例子编写一个Cat类 1234567891011121314151617181920212223/** * @Author: cuzz * @Date: 2018/9/24 13:36 * @Description: */public class Cat implements InitializingBean, DisposableBean&#123; public Cat() &#123; System.out.println("cat constructor..."); &#125; @Override public void afterPropertiesSet() throws Exception &#123; System.out.println("cat...init..."); &#125; @Override public void destroy() throws Exception &#123; System.out.println("cat...destroy..."); &#125;&#125; 测试 123456cat constructor...cat...init...容器创建完成...---&gt;开始关闭容器cat...destroy...---&gt;已经关闭容器 生命周期@PostContruct和@PreDestroy注解@PostContruct在Bean创建完成并且属性赋值完成，来执行初始化 @PreDestroy在容器销毁Bean之前通知我们进行清理工作 编写一个Dog类，并把他注入到配置类中 123456789101112131415161718192021/** * @Author: cuzz * @Date: 2018/9/24 14:03 * @Description: */public class Dog &#123; public Dog() &#123; System.out.println("dog constructor..."); &#125; @PostConstruct public void postConstruct() &#123; System.out.println("post construct..."); &#125; @PreDestroy public void preDestroy() &#123; System.out.println("pre destroy..."); &#125;&#125; 测试结果 123456dog constructor...post construct...容器创建完成...---&gt;开始关闭容器pre destroy...---&gt;已经关闭容器 生命周期BeanPostProscessor后置处理器我们先看看源码，解释的很清楚，BeanPostProscessor 中postProcessBeforeInitialization方法会在每一个bean对象的初始化方法调用之前回调；postProcessAfterInitialization方法会在每个bean对象的初始化方法调用之后被回调 。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * Factory hook that allows for custom modification of new bean instances, * e.g. checking for marker interfaces or wrapping them with proxies. * * &lt;p&gt;ApplicationContexts can autodetect BeanPostProcessor beans in their * bean definitions and apply them to any beans subsequently created. * Plain bean factories allow for programmatic registration of post-processors, * applying to all beans created through this factory. * * &lt;p&gt;Typically, post-processors that populate beans via marker interfaces * or the like will implement &#123;@link #postProcessBeforeInitialization&#125;, * while post-processors that wrap beans with proxies will normally * implement &#123;@link #postProcessAfterInitialization&#125;. */public interface BeanPostProcessor &#123; /** * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;before&lt;/i&gt; any bean * initialization callbacks (like InitializingBean's &#123;@code afterPropertiesSet&#125; * or a custom init-method). The bean will already be populated with property values. * The returned bean instance may be a wrapper around the original. * @param bean the new bean instance * @param beanName the name of the bean * @return the bean instance to use, either the original or a wrapped one; * if &#123;@code null&#125;, no subsequent BeanPostProcessors will be invoked * @throws org.springframework.beans.BeansException in case of errors * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet */ Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException; /** * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;after&lt;/i&gt; any bean * initialization callbacks (like InitializingBean's &#123;@code afterPropertiesSet&#125; * or a custom init-method). The bean will already be populated with property values. * The returned bean instance may be a wrapper around the original. * &lt;p&gt;In case of a FactoryBean, this callback will be invoked for both the FactoryBean * instance and the objects created by the FactoryBean (as of Spring 2.0). The * post-processor can decide whether to apply to either the FactoryBean or created * objects or both through corresponding &#123;@code bean instanceof FactoryBean&#125; checks. * &lt;p&gt;This callback will also be invoked after a short-circuiting triggered by a * &#123;@link InstantiationAwareBeanPostProcessor#postProcessBeforeInstantiation&#125; method, * in contrast to all other BeanPostProcessor callbacks. * @param bean the new bean instance * @param beanName the name of the bean * @return the bean instance to use, either the original or a wrapped one; * if &#123;@code null&#125;, no subsequent BeanPostProcessors will be invoked * @throws org.springframework.beans.BeansException in case of errors * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet * @see org.springframework.beans.factory.FactoryBean */ Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException;&#125; 编写一个MyBeanPostProcessor实现BeanPostProcessor接口 123456789101112131415161718/** * @Author: cuzz * @Date: 2018/9/24 14:21 * @Description: 后置处理器，初始化前后进行处理工作 */public class MyBeanPostProcessor implements BeanPostProcessor&#123; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println("---&gt;postProcessBeforeInitialization..." + beanName +"==&gt;" + bean); return bean; &#125; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println("---&gt;postProcessAfterInitialization..." + beanName +"==&gt;" + bean); return bean; &#125;&#125; 添加到配置中 12345678910111213@Configurationpublic class MainConfigOfLifecycle &#123; @Bean public Cat cat() &#123; return new Cat(); &#125; @Bean public MyBeanPostProcessor myBeanPostProcessor() &#123; return new MyBeanPostProcessor(); &#125;&#125; 测试 123456789101112---&gt;postProcessBeforeInitialization...org.springframework.context.event.internalEventListenerProcessor==&gt;org.springframework.context.event.EventListenerMethodProcessor@1dc67c2---&gt;postProcessAfterInitialization...org.springframework.context.event.internalEventListenerProcessor==&gt;org.springframework.context.event.EventListenerMethodProcessor@1dc67c2---&gt;postProcessBeforeInitialization...org.springframework.context.event.internalEventListenerFactory==&gt;org.springframework.context.event.DefaultEventListenerFactory@2bd765---&gt;postProcessAfterInitialization...org.springframework.context.event.internalEventListenerFactory==&gt;org.springframework.context.event.DefaultEventListenerFactory@2bd765cat constructor...---&gt;postProcessBeforeInitialization...cat==&gt;com.cuzz.bean.Cat@1d3b207cat...init...---&gt;postProcessAfterInitialization...cat==&gt;com.cuzz.bean.Cat@1d3b207容器创建完成...---&gt;开始关闭容器cat...destroy...---&gt;已经关闭容器 在实例创建之前后创建之后会被执行 生命周期BeanPostProcessor原理通过debug到populateBean，先给属性赋值在执行initializeBean方法 123456try &#123; populateBean(beanName, mbd, instanceWrapper); if (exposedObject != null) &#123; exposedObject = initializeBean(beanName, exposedObject, mbd); &#125;&#125; initializeBean方法时， 1234567891011121314151617181920protected Object initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) &#123; Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) &#123; // 执行before方法 wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &#125; ... try &#123; // 执行初始化 invokeInitMethods(beanName, wrappedBean, mbd); &#125; if (mbd == null || !mbd.isSynthetic()) &#123; // 执行after方法 wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean;&#125; Spring底层对BeanPostProcessor的使用： Bean赋值、注入其他组件、@Autowired、生命周期注解功能、@Async等等都使用到了BeanPostProcessor这个接口的实现类，很重要 总结Bean 的初始化顺序 首先执行 bean 的构造方法 BeanPostProcessor 的 postProcessBeforeInitialization 方法 InitializingBean 的 afterPropertiesSet 方法 @Bean 注解的 initMethod方法 BeanPostProcesso r的 postProcessAfterInitialization 方法 DisposableBean 的 destroy 方法 @Bean注解的 destroyMethod 方法]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>注解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring注解驱动开发（一）]]></title>
    <url>%2F2018%2F09%2F23%2FSpring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[注解可以简化配置，提高效率 The Spring Framework provides a comprehensive programming and configuration model for modern Java-based enterprise applications - on any kind of deployment platform. 组件注册@Configuration和@Bean的注入使用xml方式我们一起注入一个bean使用xml来配置 123456789101112&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;bean id="person" class="com.cuzz.bean.Person"&gt; &lt;property name="name" value="cuzz"&gt;&lt;/property&gt; &lt;property name="age" value="18"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/beans&gt; 我可以使用ClassPathXmlApplicationContext来获取 12345678910111213/** * @Author: cuzz * @Date: 2018/9/23 10:48 * @Description: */public class MainTest &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext = new ClassPathXmlApplicationContext("bean.xml"); // 用id获取 Person bean = (Person) applicationContext.getBean("person"); System.out.println(bean); &#125;&#125; 输出Person(name=cuzz, age=18) 注解编写一个配置类 1234567891011121314/** * @Author: cuzz * @Date: 2018/9/23 10:55 * @Description: 配置类 */@Configuration // 告诉Spring这是一个配置类public class MainConfig &#123; // 给容器中注册一个Bean,类型为返回值类型,id默认用方法名 // 也可以指定id @Bean(value = "person01") public Person person() &#123; return new Person("vhsj", 16); &#125;&#125; 可以通过AnnotationConfigApplicationContext来获取，并且获取id 1234567891011121314151617/** * @Author: cuzz * @Date: 2018/9/23 10:59 * @Description: */public class MainTest &#123; public static void main(String[] args) &#123; AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MainConfig.class); Person person = (Person) context.getBean(Person.class); System.out.println(person); String[] names = context.getBeanNamesForType(Person.class); for (String name: names) &#123; System.out.println(name); &#125; &#125;&#125; 输出 12Person(name=vhsj, age=16)person01 由于给bean添加一个一个value，可以改变默认id 组件注册@ComponentScan使用xml只要标注了注解就能扫描到如： @Controller @Service @Repository @Component 1&lt;context:component-scan base-package="com.cuzz"&gt;&lt;/context:component-scan&gt; 注解在配置类中添加 12345678910/** * @Author: cuzz * @Date: 2018/9/23 10:55 * @Description: 配置类 */@Configuration // 告诉Spring这是一个配置类@ComponentScan(value = "com.cuzz") // 指定包public class MainConfig &#123; &#125; 添加controller、service等 测试 1234567891011121314151617/** * @Author: cuzz * @Date: 2018/9/23 13:03 * @Description: */public class IOCTest &#123; @Test public void test01() &#123; AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); // 获取所有bean定义的名字 String[] beanNames = applicationContext.getBeanDefinitionNames(); for (String name : beanNames) &#123; System.out.println(name); &#125; &#125;&#125; 输出结果 1234567891011org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfigbookControllerbookDaobookServiceperson01 可以看出添加@Controller @Service @Repository @C omponent注解的都可以扫描到 还可以指定添加某些类，和排除某些类，进入ComponentScan注解中有下面两个方法 12345ComponentScan.Filter[] includeFilters() default &#123;&#125;;ComponentScan.Filter[] excludeFilters() default &#123;&#125;;includeFilters = Filter[] ：指定扫描的时候只需要包含哪些组件excludeFilters = Filter[] ：指定扫描的时候按照什么规则排除那些组件 配置类，排除Controller 1234567@Configuration // 告诉Spring这是一个配置类@ComponentScan(value = "com.cuzz", excludeFilters = &#123; @ComponentScan.Filter(type = FilterType.ANNOTATION, classes = &#123;Controller.class&#125;)&#125;)public class MainConfig &#123;&#125; 运行测试方法，可以得出没有Controller类的 123456789org.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfigbookDaobookServiceperson01 自定义TypeFilter指定过滤规则第一和第二比较常用 12345FilterType.ANNOTATION：按照注解FilterType.ASSIGNABLE_TYPE：按照给定的类型；FilterType.ASPECTJ：使用ASPECTJ表达式FilterType.REGEX：使用正则指定FilterType.CUSTOM：使用自定义规则 新建一个MyTypeFilte类实现TypeFilter接口 1234567891011121314151617181920212223242526272829/** * @Author: cuzz * @Date: 2018/9/23 15:03 * @Description: */public class MyTypeFilter implements TypeFilter&#123; /** * metadataReader：读取到的当前正在扫描的类的信息 * metadataReaderFactory:可以获取到其他任何类信息的 */ @Override public boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) throws IOException &#123; // 获取当前类注解的信息 AnnotationMetadata annotationMetadata = metadataReader.getAnnotationMetadata(); // 获取当前正在扫描的类的类信息 ClassMetadata classMetadata = metadataReader.getClassMetadata(); // 获取当前类资源（类的路径） Resource resource = metadataReader.getResource(); String className = classMetadata.getClassName(); System.out.println("---&gt;"+className); // 这些类名中包含er就返回true if(className.contains("er"))&#123; return true; &#125; return false; &#125;&#125; 使用自定义注解记得需要关闭默认过滤器useDefaultFilters = false 123456789101112131415161718/** * @Author: cuzz * @Date: 2018/9/23 10:55 * @Description: 配置类 */@Configuration @ComponentScan(value = "com.cuzz", includeFilters = @ComponentScan.Filter(type = FilterType.CUSTOM, classes = MyTypeFilter.class), useDefaultFilters = false)public class MainConfig &#123; // 给容器中注册一个Bean,类型为返回值类型,id默认用方法名 // 也可以指定id @Bean(value = "person01") public Person person() &#123; return new Person("vhsj", 16); &#125;&#125; 测试12345678910111213141516171819202122---&gt;com.cuzz.AppTest---&gt;com.cuzz.bean.MainTest---&gt;com.cuzz.config.IOCTest---&gt;com.cuzz.config.MainTest---&gt;com.cuzz.App---&gt;com.cuzz.bean.Person---&gt;com.cuzz.config.MyTypeFilter---&gt;com.cuzz.controller.BookController---&gt;com.cuzz.dao.BookDao---&gt;com.cuzz.sevice.BookServiceorg.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfig // 不是扫描的 person // 这个是在bean中myTypeFilter // 有erbookController // 有erbookService // 有erperson01 // 这个是在bean中 组件注册@Scope设置作用域Spring的bean默认是单例的123456789101112@Testpublic void test02() &#123; AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); // 获取所有bean定义的名字 String[] beanNames = applicationContext.getBeanDefinitionNames(); for (String name : beanNames) &#123; System.out.println(name); &#125; Object bean = applicationContext.getBean("person"); Object bean2 = applicationContext.getBean("person"); System.out.println(bean == bean2); // 输出true&#125; Scope的四个范围1234ConfigurableBeanFactory#SCOPE_PROTOTYPE // 多实例 每次获取时创建对象，不会放在ioc容器中ConfigurableBeanFactory#SCOPE_SINGLETON // 单实例 ioc容器启动是创建对象，以后从容器中获取WebApplicationContext#SCOPE_REQUEST // web同一次请求创建一个实例WebApplicationContext#SCOPE_SESSION // web同一个session创建一个实例 如果我们把Scope修改 1234567891011121314/** * @Author: cuzz * @Date: 2018/9/23 15:40 * @Description: */@Configurationpublic class MainConfig2 &#123; @Scope(value = "prototype") @Bean public Person person() &#123; return new Person("vhuj", 25); &#125;&#125; 则测试输出false 组件注册@Lazy-bean懒加载懒加载懒加载的是针对单实例Bean，默认是在容器启动的时创建的，我们可以设置懒加载容器启动是不创建对象，在第一次使用（获取）Bean创建对象，并初始化 测试先给添加一个@Lazy注解 12345678910@Configurationpublic class MainConfig2 &#123; @Lazy @Bean public Person person() &#123; System.out.println("给容器中添加Person..."); return new Person("vhuj", 25); &#125;&#125; 编写一个测试方法 1234567@Testpublic void test03() &#123; AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); System.out.println("ioc容器创建完成..."); Object bean = applicationContext.getBean("person");&#125; 输出 12ioc容器创建完成...给容器中添加Person... 添加一个@Lazy是在第一次获取时，创建对象，以后获取就不需要创建了，直接从容器中获取，因为它是单实例 组件注册@Conditional按条件注册按照一定条件进行判断，满足条件给容器中注册Bean 编写自己的Condition类如果系统是windows，给容器中注入”bill” 如果系统是linux，给容器中注入”linus” 编写WindowCondition类并重写matches方法 12345678910111213141516171819202122/** * @Author: cuzz * @Date: 2018/9/23 20:30 * @Description: 判断是否是windows */ public class WindowCondition implements Condition&#123; /** * @param context 判断条件 * @param metadata 注释信息 * @return boolean */ @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123; Environment environment = context.getEnvironment(); String property = environment.getProperty("os.name"); if (property.contains("Windows")) &#123; return true; &#125; return false; &#125; &#125; context有以下方法 12345678// 能获取ioc使用的beanfactoryConfigurableListableBeanFactory beanFactory = context.getBeanFactory();// 能获取到类加载器ClassLoader classLoader = context.getClassLoader();// 获取到环境变量Environment environment = context.getEnvironment();// 获取到Bean定义的注册类BeanDefinitionRegistry registry = context.getRegistry(); 配置类添加Bean添加Condition条件 123456789101112131415@Configurationpublic class MainConfig2 &#123; @Conditional(&#123;WindowCondition.class&#125;) @Bean("bill") public Person person01() &#123; return new Person("Bill Gates", 60); &#125; @Conditional(&#123;LinuxCondition.class&#125;) @Bean("linux") public Person person02() &#123; return new Person("linus", 45); &#125;&#125; 测试12345678910111213141516171819@Testpublic void test04() &#123; AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); // 获取环境变量 ConfigurableEnvironment environment = applicationContext.getEnvironment(); String property = environment.getProperty("os.name"); System.out.println(property); // 获取所有bean定义的名字 String[] beanNames = applicationContext.getBeanDefinitionNames(); for (String name : beanNames) &#123; System.out.println(name); &#125; // key 是id Map&lt;String, Person&gt; map = applicationContext.getBeansOfType(Person.class); System.out.println(map);&#125; 发现只有“bill”这个Bean被注入 12345678910Windows 7org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfig2bill&#123;bill=Person(name=Bill Gates, age=60)&#125; 组件注册@Improt给容器中快速导入一个组件@Import导入@Import可以导入第三方包，或则自己写的类，比较方便，Id默认为全类名 比如我们新建一个类 1234567/** * @Author: cuzz * @Date: 2018/9/23 21:08 * @Description: */public class Color &#123;&#125; 我们只需要在配置类添加一个@Import把这个类导入 123@Import(&#123;Color.class&#125;)@Configurationpublic class MainConfig2 &#123;&#125; ImportSelector接口导入的选择器返回导入组件需要的全类名的数组 123456789public interface ImportSelector &#123; /** * Select and return the names of which class(es) should be imported based on * the &#123;@link AnnotationMetadata&#125; of the importing @&#123;@link Configuration&#125; class. */ String[] selectImports(AnnotationMetadata importingClassMetadata);&#125; 编写一个MyImportSelector类实现ImportSelector接口 1234567891011121314/** * @Author: cuzz * @Date: 2018/9/23 21:15 * @Description: */public class MyImportSelector implements ImportSelector&#123; // 返回值就导入容器组件的全类名 // AnnotationMetadata:当前类标注的@Import注解类的所有注解信息 @Override public String[] selectImports(AnnotationMetadata importingClassMetadata) &#123; return new String[] &#123;"com.cuzz.bean.Car"&#125;; &#125;&#125; 在配置类中，通过@Import导入 12345678/** * @Author: cuzz * @Date: 2018/9/23 15:40 * @Description: 配置类 */@Import(&#123;Color.class, MyImportSelector.class&#125;)@Configurationpublic class MainConfig2 &#123;&#125; 测试结果，com.cuzz.bean.Car注入了 123456789org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfig2com.cuzz.bean.Colorcom.cuzz.bean.Car ImportBeanDefinitionRegistrar接口选择器123456789101112131415public interface ImportBeanDefinitionRegistrar &#123; /** * Register bean definitions as necessary based on the given annotation metadata of * the importing &#123;@code @Configuration&#125; class. * &lt;p&gt;Note that &#123;@link BeanDefinitionRegistryPostProcessor&#125; types may &lt;em&gt;not&lt;/em&gt; be * registered here, due to lifecycle constraints related to &#123;@code @Configuration&#125; * class processing. * @param importingClassMetadata annotation metadata of the importing class * @param registry current bean definition registry */ public void registerBeanDefinitions( AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry);&#125; 编写一个ImportBeanDefinitionRegistrar实现类 123456789101112131415161718192021222324/** * @Author: cuzz * @Date: 2018/9/23 21:29 * @Description: */public class MyImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar &#123; /** * @param importingClassMetadata 当前类的注解信息 * @param registry 注册类 */ @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; // 查询容器 boolean b = registry.containsBeanDefinition("com.cuzz.bean.Car"); // 如果有car, 注册一个汽油类 if (b == true) &#123; // 需要添加一个bean的定义信息 RootBeanDefinition rootBeanDefinition = new RootBeanDefinition(Petrol.class); // 注册一个bean, 指定bean名 registry.registerBeanDefinition("petrol", rootBeanDefinition); &#125; &#125;&#125; 配置类 12345678/** * @Author: cuzz * @Date: 2018/9/23 15:40 * @Description: 配置类 */@Import(&#123;Color.class, MyImportSelector.class, MyImportBeanDefinitionRegistrar.class&#125;)@Configurationpublic class MainConfig2 &#123;&#125; 测试结果，出现了petrol 12345678910org.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfig2com.cuzz.bean.Colorcom.cuzz.bean.Car petrol 组件注册使用FactoryBean注册组件编写一个ColorFactoryBean类 12345678910111213141516171819202122/** * @Author: cuzz * @Date: 2018/9/23 21:55 * @Description: Spring定义的工厂Bean */public class ColorFactoryBean implements FactoryBean&lt;Color&gt; &#123; // 返回一个Color对象 @Override public Color getObject() throws Exception &#123; return new Color(); &#125; @Override public Class&lt;?&gt; getObjectType() &#123; return Color.class; &#125; // 是否为单例 @Override public boolean isSingleton() &#123; return true; &#125;&#125; 注入到容器中 1234@Beanpublic ColorFactoryBean colorFactoryBean() &#123; return new ColorFactoryBean();&#125; 测试 12345678@Testpublic void test05() &#123; AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); Object bean = applicationContext.getBean("colorFactoryBean"); // 工厂bean调用的是getClass()方法 System.out.println("colorFactoryBean的类型是: " + bean.getClass());&#125; 输出，发现此时的bean调用的方法是getObjectType方法 1colorFactoryBean的类型是: class com.cuzz.bean.Color 如果需要获取BeanFactory本身，可以在id前面加一个“&amp;”标识 1234567891011@Testpublic void test05() &#123; AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig2.class); Object bean = applicationContext.getBean("colorFactoryBean"); // 工厂bean调用的是getClass()方法 System.out.println("colorFactoryBean的类型是: " + bean.getClass()); Object bean2 = applicationContext.getBean("&amp;colorFactoryBean"); // 工厂bean调用的是getClass()方法 System.out.println("colorFactoryBean的类型是: " + bean2.getClass());&#125; 此时输出 12colorFactoryBean的类型是: class com.cuzz.bean.ColorcolorFactoryBean的类型是: class com.cuzz.bean.ColorFactoryBean 总结给容器中注册组件： 包扫描 + 组件组件（@Controller / @Service / @Repository / @Component） @Bean[导入第三方包组件] @Import[快速给容器中导入一个组件] @Import（要导入到容器中的组件），容器中就会自动注册这个组件，id 默认是全类名 ImportSelector，返回需要导入的组件的全类名数组 ImportBeanDefinitionRegistrar，手动注册bean到容器中 使用 Spring 提供的 FactoryBean （工厂Bean） 默认获取到的是工厂 bean 调用的 getObject 创建的对象 要获取工厂 Bean 本身，我们需要个 id 前面加一个 &amp; 符号，如 &amp;colorFactoryBean]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>注解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实习结束篇]]></title>
    <url>%2F2018%2F09%2F10%2F%E5%AE%9E%E4%B9%A0%E7%BB%93%E6%9D%9F%E7%AF%87%2F</url>
    <content type="text"><![CDATA[常怀感恩的心 昨天提交了离职信，完了成了一系列辞职手续 总经理找我聊了一会，谈了谈人生规划，很感谢他能给予我建议，也希望我毕业后能再回公司 先是和我师父告别，师父先是询问了我的情况，后来把我带到公司楼下聊了一会，询问了我一下规划，总结一下他给我提的意见 毕业刚出去，先去一线互联网城市，首先选择大厂，前三年不要太在意工资，主要是眼界 不要本末倒置，现在不要天天去背那些面试题和刷题，当前重要的是知识的沉淀，把公司用到的中间件，好好研究一下，不要只是看看，而要动手去搭建 不是科班出身的，身边缺少这种技术的氛围，平时多努力努力，多认识认识朋友 学校有项目，即使没报酬，也要去参与，多积累经验 然后是跟外卖组的人告别，感谢组长CJG，小师兄HL，以及CWZ，BW，NZ这些人对我的帮助，这一段时间在这里学习到了许多，感谢这些人 HL小师兄，也单独和我聊了聊，询问了我的情况，也给我一些工作经验，不能被人影响到自己，平时做事认真一点，不要担心犯错等 小师兄还送我下楼，最后小师兄拥抱一个就告别了 走到地铁站发现身上还有一张48的的士票还没报，又回公司了 然后又跟同事告别了一波]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>实习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实习记录]]></title>
    <url>%2F2018%2F07%2F23%2F%E5%AE%9E%E4%B9%A0%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[实习给了我很大信心 实习一段时间了，说说最近的感受吧 我是转行的，现在是一名材料计算的研究生，为什么要说材料计算呢，我是希望去面试的时候至少有计算这两个字，HR至少会觉得我跟计算机有点靠边，减少被HR给过滤掉 学java大概半年了，把java基础学完，在慕课网上找了一个实战课程，这是我部署上线的网站（还没写完），就去找实习了 由于是暑假，老师管的也没那么严，不用去实验室 刚开始的时候，不是很自信，在拉钩、Boss直聘和智联投简历，大概投了100来份，收到5-6个面试，武汉的夏天真的热，最气愤的是，遇到一两个培训机构，浪费时间，后来去面试都会在网上先查查，刚开始面试的都是一些小公司，小公司基本都是问你项目，然而我项目经验又不多，基本上都是回去等消息 接着面试了另一家小公司，公司的老板和我是一个学校的，跟我聊的也很不错，本来打算在这里实习的，后来收到良品的实习offer，就没去了，也跟这位学长沟通了，他也支持我 后来良品铺子打电话给我，让我去面试，良品铺子在武汉来说算比较大的企业，面试我的是一名架构师，大公司比较喜欢问基础，我对java基础掌握的还不错，答的也还可以，得到了他的认可，后面的面试就很轻松，他还主动要帮我加工资，后来我就认他当我师傅，真的很好，很感谢他 他还夸我基础挺好的，后来被我分配到外卖组，也是比较好的组，属于电商，所用的技术也是比较新 来组里又碰到了同一个学校的小师兄还是老乡，真是太幸运了，还有我组长，人都超级nice，也从他们那里学到很多 平时把需求做完，自己看看博客，看看书，学学公司所有的框架，发现公司用的框架很多都是阿里的，比起以前在工厂实习简直太爽了 实习这一段时间自己的提升真的很多，所以有机会一定要出去实习，平时我们部门还会组织技术分享，也可以增加自己的眼界，平时遇到问题，也可以快速寻求帮助，快速解决问题，知道一个公司是怎么开发产品的 最后收获最多的还是自信，刚开始觉得自己不是科班的有点不太自信，实习汇报完后小师兄说我学习能力比较强，上手快，不用让他操心，我的组长对我的评价说我达到2年的水平，哈哈，真的把我高兴坏了，我们的组长的boss也给我的评价也不错，我不是来炫耀这些，只是这些肯定给我很大的信心，让我在转行的道路上越走越有勇气，最后还是要靠自己努力，平时多写写代码，多看看书 最后感谢在我转行时所遇见的这些人。]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>实习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jQuery学习]]></title>
    <url>%2F2018%2F06%2F24%2FjQuery%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[jQuery是一个快速、简洁的JavaScript框架 jQuery设计的宗旨是“write Less，Do More” 初识jQueryjQuery是一个快速、简洁的JavaScript框架，是继Prototype之后又一个优秀的JavaScript代码库（或JavaScript框架）。jQuery设计的宗旨是“write Less，Do More”，即倡导写更少的代码，做更多的事情。它封装JavaScript常用的功能代码，提供一种简便的JavaScript设计模式，优化HTML文档操作、事件处理、动画设计和Ajax交互 总结来说为下面三点： jQuery 是一个 JavaScript jQuery 极大地简化了 JavaScript 编程 jQuery 很容易学习 使用jQuery编写HelloWorld 下载jQuery库 引入jQuery 12345&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;01-初识jQuery&lt;/title&gt; &lt;script src=&quot;js/jquery-1.11.3/jquery.js&quot;&gt;&lt;/script&gt;&lt;/head&gt; 编写helloWorld 1234567891011121314151617181920&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;02-jQuery-HelloWorld&lt;/title&gt; &lt;script src=&quot;js/jquery-1.11.3/jquery.js&quot;&gt;&lt;/script&gt; &lt;script&gt; // 原生js的固定写法 window.onload = function(ev) &#123; &#125;; // jQuery的固定写法 $(document).ready(function () &#123; alert(&quot;Hello World&quot;); &#125;); &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; jQuery和js入口函数的区别12345678910111213141516171819&lt;script&gt; window.onload = function (ev) &#123; // 通过原生的js入口函数可以拿到Dom元素 var img = document.getElementsByTagName(&quot;img&quot;)[0]; console.log(img); // 通过原生的js入口函数可以拿到dom元素的宽高 var width = window.getComputedStyle(img).width; console.log(width); &#125;; $(document).ready(function () &#123; // 通过jQuery入口函数可以拿到Dom元素 var $img = $(&quot;img&quot;)[0]; console.log($img); // 通过jQuery入口函数不能拿到dom元素的宽高 var $width = $img.width(); console.log($width); &#125;);&lt;/script&gt; 区别: 原生jQuery入口函数的加载模式不同 原生js会等到dom加载完毕，并且图片也加载完毕才会执行 jQuery会等到dom加载完毕，但不会等到图片也加载完毕就会执行 12345678910111213141516&lt;script&gt; window.onload = function (ev) &#123; alert(&quot;hello cuzz&quot;); // 不会显示 &#125;; window.onload = function (ev) &#123; alert(&quot;hello cuxx&quot;); // 会显示 &#125;;&lt;/script&gt;&lt;script&gt; $(document).ready(function () &#123; alert(&quot;hello cuzz&quot;); // 会显示 &#125;); $(document).ready(function () &#123; alert(&quot;hello cuxx&quot;); // 会显示 &#125;);&lt;/script&gt; 区别： 多个window.onload只会执行一次, 后面的会覆盖前面的 多个$(document).ready()会执行多次,后面的不会覆盖前面的 原因：jQuery框架本质是一个闭包，每次执行我们都会给ready函数传递一个新的函数，不同函数内部的数据不会相互干扰 1234567891011&lt;script&gt; // 相当于这样写 var test1 = function () &#123; alert(&quot;hello cuzz&quot;); &#125; var test2 = function () &#123; alert(&quot;hello cuxx&quot;); &#125; $(document).ready(test1); $(document).ready(test2);&lt;/script&gt; 对比： window.onload $(document).ready() 执行时机 必须等待网页全部加载完毕(包括 图片等),然后再执行包裹代码 只需要等待网页中的DOM结构 加载完毕,就能执行包裹的代码 执行次数 只能执行一次,如果第二次,那么 第一次的执行会被覆盖 可以执行多次,第N次都不会被上 一次覆盖 简写方案 无 $(function () { }); jQuery的四种写法123456789101112131415161718&lt;script&gt; // 第一种写法 $(document).ready(function () &#123; alert(&quot;hello cuzz&quot;); &#125;); // 第二种写法 jQuery(document).ready(function () &#123; alert(&quot;hello cuzz&quot;); &#125;); // 第三种写法 $(function () &#123; alert(&quot;hello cuzz&quot;); &#125;); // 第四种写法 jQuery(function () &#123; alert(&quot;hello cuzz&quot;); &#125;);&lt;/script&gt; 推荐使用第三种写法 jQuery的核心函数 jQuery(callback)，当dom加载完成之后执行传入的回调函数 12345&lt;script&gt; $(function () &#123; alert(&quot;123&quot;); &#125;);&lt;/script&gt; jQuery([sel,[context]])，接收一个包含 CSS 选择器的字符串，然后用这个字符串去匹配一组元素,并包装成jQuery对象 1234567891011&lt;script&gt; $(function () &#123; // 利用jQuery获取的div,得到的是一个jQuery对象 var $box = $(&quot;div&quot;); console.log($box); // 利用原生js语法获取的div,得到的是一个js对象 var box = document.getElementsByTagName(&quot;div&quot;); console.log(box); &#125;);&lt;/script&gt; 原生JS对象和jQuery对象相互转换 jQuery(html, [ownerDoc]) 根据 HTML 标记字符串，动态创建DOM 元素123456789&lt;script&gt; $(function () &#123; var $eles = $(&quot;&lt;p&gt;我是span&lt;/p&gt;&lt;u&gt;我是u&lt;/u&gt;&quot;); // 无论是jQuery找到的还是创建的,我们最终拿到的永远都是jQuery对象 console.log($eles); // 将创建好的DOM元素添加到body中 $(&quot;body&quot;).append($eles); &#125;);&lt;/script&gt; jQuery的本质是一个伪数组，有0到length-1的属性 jQuery静态方法 静态方法 12345678910111213&lt;script&gt; // 定义一个类 function AClass() &#123; &#125;; // 给这个类添加一个静态方法 AClass.staticMethod = function () &#123; alert(&quot;staticMethod&quot;) &#125;; // 静态方法的调用 AClass.staticMethod();&lt;/script&gt; 实例方法 123456789101112131415&lt;script&gt; // 定义一个类 function AClass() &#123; &#125; // 给这个类添加一个实例方法 AClass.prototype.instanceMethod = function () &#123; alert(&quot;instanceMethod&quot;); &#125; // 实例方法的调用 var a = new AClass(); a.instanceMethod();&lt;/script&gt; 常用静态方法 $.each(object, [callback]) 1234567891011121314151617181920212223242526272829303132$(function () &#123; // 遍历数组 var arr = [1, 3, 5, 7, 9]; // 通过原生方法遍历数组 // 第一个回调函数参数是遍历到的元素 // 第二个回调函数参数是当前遍历的索引 // 返回值: 没有返回值 var res = arr.forEach(function (ele, idx) &#123; console.log(idx, ele); &#125;); console.log(res); // 通过jQuery静态方法遍历数组 // 第一个回调函数参数是当前遍历的索引 // 第二个回调函数参数是遍历到的元素 // 返回值: 被遍历的数组 var $res2 = $.each(arr, function (idx, ele) &#123; console.log(idx, ele); &#125;); console.log($res2); // 遍历对象 var obj = &#123;name: &quot;&quot;, age:&quot;33&quot;, gender:&quot;male&quot;&#125;; // js对象没有forEach方法,所以通过forin方法遍历对象 for(var key in obj)&#123; console.log(key, obj[key]); &#125; // 通过jQuery静态方法遍历对象 $.each(obj,function (key, value) &#123; console.log(key, value); &#125;);&#125;); $.holdReady(hold)，传入true或false来暂停或则恢复ready()事件 $.trim(str) 去掉字符串起始和结尾的空格 $.isArray(obj) 判断是否是数组 $.isFunction(obj)判断是否是函数 $.isWindow(obj)判断是否是window对象学习网站在网上，发现菜鸟教程比较详细，排版也比较好，不再更新jQuery]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>jQuery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python零基础入门笔记]]></title>
    <url>%2F2018%2F01%2F02%2FPython%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[复习是为了更好的学习更新的知识。 学习python有一年多了，希望通过学习笔记来复习了，也能让后来者少走一点弯路。在课程笔记的同时加入了一部分自己的经验补充。 [√] 廖雪峰老师在慕课网的课程: Python入门 Python的初次体验python语言介绍全世界有几百种编程语言，但是流行的只有十几种，python就是其中一种。荷兰人龟叔于1989年圣诞节创立。 特点：优雅，明确，简单。 适合的领域： web网站和各种网络服务； 系统工具和脚本； 作为胶水语言把其他语言开发的模块包装起来方便使用。 Python是一门高级语言，所以不适合贴近硬件的代码: 比如驱动程序（首选C） 移动开发，有各自的语言，（objectC，swift/java） 游戏开发（首选C/C++）。 Python实际应用： YouTube，豆瓣，搜狐邮箱；Openstack开源云计算平台。Google，Yahoo，NASA。 语言之间的对比： C编译为机器码；JAVA编译为字节码；python为解释执行。 缺点： 运行慢，Python源码不能加密。 Python版本的选择博主建议选择安装环境篇的进阶版：2.7版本与3.x版本共存。 3.x版本建议选择Python 3.5.1 |Anaconda 4.1.0 (64-bit)以后如果要使用python进行TensorFlow windows版的配置可以省下时间。 windows下安装python参考：搭建Python开发环境 第一个python程序cmd下输入python。进入交互式环境。 命令行模式启动python:python 命令行模式执行python文件python 目录/xxx.py 命令行模式关闭python：exit() 注意：不要使用word，或者windows下自带的记事本来进行代码编写。 推荐使用： 轻量级：sublime Text 或 editplus 重量级(较大工程) : pycharm Professional 2.7版本专属： print &#39;hello,world!&#39; 3.x版本(2.7版本也可以正常运行)： print (&quot;hello,world!&quot;) Python变量和数据类型 讲解Python基本的数据类型.包括整数、浮点数、字符串和布尔类型，以及变量的概念和基本的数据运算。 数据类型整数在Python程序中，整数的表示方法和数学上的写法一模一样. 例如：1，100，-8080，0，等等。十六进制用0x前缀和0-9，a-f表示. 例如：0xff00，0xa5b4c3d2，等等。 浮点数浮点数也就是小数，之所以称为浮点数: 因为按照科学记数法表示时，一个浮点数的小数点位置是可变的 比如，1.23x10^9和12.3x10^8是相等的。 浮点数可以用数学写法: 如1.23，3.14，-9.01，等等。但是对于很大或很小的浮点数，就必须用科学计数法表示，把10用e替代，1.23x10^9就是1.23e9，或者12.3e8，0.000012可以写成1.2e-5，等等。 整数和浮点数在计算机内部存储的方式是不同的，整数运算永远是精确的（除法难道也是精确的？是的！），而浮点数运算则可能会有四舍五入的误差。 知识点：python2与3不同整除 python2.7下：/ 和 // 都是整数除法。 例: 1/2结果为0.后面小数部分会直接去除掉。 python3.x下： / 为浮点数除法(如：1/2=0.5) //为整数除法(如: 1//2 = 0） 12345a = 1 b = 2print a+b#python2.7下想要浮点数除法就得使用类型转换。print float(a)/b 字符串字符串是以’’或””括起来的任意文本，比如’abc’，”xyz”等等。请注意，’’或””本身只是一种表示方式，不是字符串的一部分. 因此，字符串’abc’只有a，b，c这3个字符。 布尔值布尔值和布尔代数的表示完全一致，一个布尔值只有True、False两种值，要么是True，要么是False，在Python中，可以直接用True、False表示布尔值（请注意大小写），也可以通过布尔运算计算出来。 布尔值可以用and、or和not运算。 and运算是与运算，只有所有都为 True，and运算结果才是 True。 or运算是或运算，只要其中有一个为 True，or 运算结果就是 True。 not运算是非运算，它是一个单目运算符，把 True 变成 False，False 变成 True。 空值空值是Python里一个特殊的值，用None表示。 None不能理解为0，因为0是有意义的，而None是一个特殊的空值。 编程小任务： 计算十进制整数 45678 和十六进制整数 0x12fd2 之和。 请用字符串表示出Learn Python in imooc。 请计算以下表达式的布尔值（注意==表示判断是否相等）：12100 &lt; 990xff == 255 题目答案： 1234print 45678+0x12fd2print "Learn Python in imooc" print 100&lt;99 print 0xff == 255 运行结果： 1234123456Learn Python in imoocFalseTrue print语句print语句可以向屏幕上输出指定的文字。比如输出’hello, world’，用代码实现如下： 1print 'hello, world' 注意： 当我们在Python交互式环境下编写代码时，&gt;&gt;&gt;是Python解释器的提示符，不是代码的一部分。 当我们在文本编辑器中编写代码时，千万不要自己添加 &gt;&gt;&gt;。 print语句也可以跟上多个字符串，用逗号,隔开，就可以连成一串输出： 1print 'The quick brown fox', 'jumps over', 'the lazy dog' 运行结果： 1The quick brown fox jumps over the lazy dog print会依次打印每个字符串，知识点：遇到逗号,会输出一个空格. print也可以打印整数，或者计算结果： 1234&gt;&gt;&gt; print 300300 #运行结果&gt;&gt;&gt; print 100 + 200300 #运行结果 漂亮做法： 12&gt;&gt;&gt; print '100 + 200 =', 100 + 200100 + 200 = 300 #运行结果 注意: 对于100 + 200，Python解释器自动计算出结果300.但是，’100 + 200 =’是字符串而非数学公式，Python把它视为字符串. 编程任务：请用两种方式打印出 hello, python.实现代码： 123#input codeprint 'hello, python.'print 'hello,','python.' 运行结果： 12hello, python.hello, python. 注释Python的注释以#开头，后面的文字直到行尾都算注释 12345# 这一行全部都是注释...print 'hello' # 这也是注释# 暂时不想运行下面一行代码:# print 'hello, python.' 注释还有一个巧妙的用途，就是一些代码我们不想运行，但又不想删除，就可以用注释暂时屏蔽掉： 编程任务:将代码编辑器中的 “print ‘hello’” 语句修改成注释语句 实现代码： 1# print 'hello' 注释：多行注释1234'''下面是一行被注释代码下面是两行被注释代码''' 什么是变量在Python中，变量的概念基本上和初中代数的方程变量是一致的。 例如，对于方程式y=x*x ，x就是变量。 当x=2时，计算结果是4。当x=5时，计算结果是25。 只是在计算机程序中，变量不仅可以是数字，还可以是任意数据类型。 在Python程序中，变量是用一个变量名表示。 知识点：变量名必须是大小写英文、数字和下划线 _ 的组合，且不能用数字开头。比如： 12a = 1t_007 = 'T007' 变量a是一个整数。变量t_007是一个字符串。 在Python中，等号=是赋值语句，可以把任意数据类型赋值给变量，同一个变量可以反复赋值，而且可以是不同类型的变量，例如： 1234a = 123 # a是整数print aa = 'imooc' # a变为字符串print a 知识点: 这种变量本身类型不固定的语言称之为动态语言，与之对应的是静态语言。 静态语言在定义变量时必须指定变量类型，如果赋值的时候类型不匹配，就会报错。例如Java是静态语言，赋值语句如下（// 表示注释）： 123//这些是java代码int a = 123; // a是整数类型变量a = "mooc"; // 错误：不能把字符串赋给整型变量 和静态语言相比，动态语言更灵活，就是这个原因。请不要把赋值语句的等号等同于数学的等号。比如下面的代码： 12x = 10x = x + 2 如果从数学上理解x = x + 2那无论如何是不成立的. 在程序中，赋值语句先计算右侧的表达式x + 2，得到结果12，再赋给变量x。由于x之前的值是10，重新赋值后，x的值变成12。 最后，知识点: 理解变量在计算机内存中的表示也非常重要。当我们写：a = ‘ABC’时，Python解释器干了两件事情： 在内存中创建了一个’ABC’的字符串； 在内存中创建了一个名为a的变量，并把它指向’ABC’。 也可以把一个变量a赋值给另一个变量b，这个操作实际上是把变量b指向变量a所指向的数据，例如下面的代码： 1234a = 'ABC'b = aa = 'XYZ'print b 最后一行打印出变量b的内容到底是’ABC’呢还是’XYZ’？如果从数学意义上理解，就会错误地得出b和a相同，也应该是’XYZ’，但实际上b的值是’ABC’，让我们一行一行地执行代码，就可以看到到底发生了什么事： 执行a = &#39;ABC&#39;，解释器创建了字符串 &#39;ABC&#39;和变量 a，并把a指向 &#39;ABC&#39;： 执行b = a，解释器创建了变量 b，并把b指向 a 指向的字符串&#39;ABC&#39;： 执行a = &#39;XYZ&#39;，解释器创建了字符串&#39;XYZ&#39;，并把a的指向改为’XYZ’，但b并没有更改： 所以，最后打印变量b的结果自然是’ABC’了。 编程任务： 等差数列可以定义为每一项与它的前一项的差等于一个常数，可以用变量 x1 表示等差数列的第一项，用 d 表示公差，请计算数列 1 4 7 10 13 16 19 … 前 100 项的和。 实现代码: 1234567x1 = 1d = 3n = 100x100 = x1+(100-1)*ds2 = (x1+x100)*100/2s = n*x1+n*(n-1)*d/2print s,s2 等差数列公式： （首项+尾项）*项数/2 项数*首项+项数*(项数-1)*公差/2 运行结果： 114950 14950 定义字符串字符串可以用&#39;&#39;或者&quot;&quot;括起来表示。 如果字符串本身包含&#39;怎么办？比如我们要表示字符串 I&#39;m OK，这时，可以用&quot; &quot;括起来表示： 12"I'm OK"'Learn "Python" in imooc' 类似的，知识点: 如果字符串包含&quot;，我们就可以用&#39; &#39;括起来表示： 如果字符串既包含&#39;又包含&quot;怎么办？ 知识点：转义 这个时候，就需要对字符串的某些特殊字符进行转义，Python字符串用\进行转义。 要表示字符串 Bob said &quot;I&#39;m OK&quot;.由于 &#39; 和&quot;会引起歧义，因此，我们在它前面插入一个\表示这是一个普通字符，不代表字符串的起始，因此，这个字符串又可以表示为 12'Bob said \"I\'m OK\".'# 在要保留原状的字符串前面加上右斜杠 注意：转义字符 \不计入字符串的内容中。 常用的转义字符还有： \n表示换行 \t 表示一个制表符 \\ 表示 \ 字符本身 编程任务： 请将下面两行内容用Python的字符串表示并打印出来： 12 Python was started in 1989 by &quot;Guido&quot;. Python is free and easy to learn. 12s = 'Python was started in 1989 by"Guido".\nPython is free and easy to learn.'print s raw字符串与多行字符串如果一个字符串包含很多需要转义的字符，对每一个字符都进行转义会很麻烦。为了避免这种情况，我们可以在字符串前面加个前缀 r ，表示这是一个 raw 字符串，里面的字符就不需要转义了。例如： 1r'\(~_~)/ \(~_~)/' 解释： 这个例子举得不是很好。可以看出raw加上之后。可能产生误会的\被修改为\\(\\ 表示 \ 字符本身) 不加上r 只有\和(并没有合成转义字符。 加上r。\需要被转义，经过转义后显示出来还是自己。 知识点: 个人小题(r的强大作用) 上图效果可以看出r的强大作用。 但是r&#39;我是一段字符&#39;表示法不能表示多行字符串(r&#39;&#39;&#39;一段字符&#39;&#39;&#39;)，也不能表示包含&#39;和 &quot;的字符串（为什么？） 因为如果r&#39;mtian&#39;yan&#39; r遇到左边第一个&#39;,会继续往后找闭合的标志&#39;然后找到mtian的地方。它任务结束了。代码继续往下执行。当扫到yan这里他就会报错。 ???(更深层待续) 或者r&quot;mtian&quot;yan&quot; 或导致r提前结束掉。后面的就无法继续匹配到对应的。 知识点: 多行字符串，可以用&#39;&#39;&#39;...&#39;&#39;&#39;表示： 12345'''Line 1Line 2Line 3'''#上面这个字符串的表示方法和下面的是完全一样的：'Line 1\nLine 2\nLine 3' 还可以在多行字符串前面添加 r ，把这个多行字符串也变成一个raw字符串： 123r'''Python is created by "Guido".It is free and easy to learn.Let's start learn Python in imooc!''' 编程任务：请把下面的字符串用r&#39;&#39;&#39;...&#39;&#39;&#39;的形式改写，并用print打印出来： 1&apos;\&quot;To be, or not to be\&quot;: that is the question.\nWhether it\&apos;s nobler in the mind to suffer.&apos; 12print r'''"To be,or not to be":that is the question.Whether it's nobler in the mind to suffer.''' 知识点: Unicode字符串字符串还有一个编码问题。 因为计算机只能处理数字，如果要处理文本，就必须先把文本转换为数字才能处理。最早的计算机在设计时采用8个比特（bit）作为一个字节（byte），所以，一个字节能表示的最大的整数就是255（二进制11111111=十进制255），0 - 255被用来表示大小写英文字母、数字和一些符号，这个编码表被称为ASCII编码，比如大写字母 A 的编码是65，小写字母 z 的编码是122。 如果要表示中文，显然一个字节是不够的，至少需要两个字节，而且还不能和ASCII编码冲突，所以，中国制定了GB2312编码，用来把中文编进去。 类似的，日文和韩文等其他语言也有这个问题。为了统一所有文字的编码，Unicode应运而生。Unicode把所有语言都统一到一套编码里，这样就不会再有乱码问题了。 Unicode通常用两个字节表示一个字符，原有的英文编码从单字节变成双字节，只需要把高字节全部填为0就可以。 因为Python的诞生比Unicode标准发布的时间还要早，所以最早的Python只支持ASCII编码，普通的字符串’ABC’在Python内部都是ASCII编码的。 Python在后来添加了对Unicode的支持，以Unicode表示的字符串用u’…’表示，比如： 123print u'中文'中文注意: 不加 u ，中文就不能正常显示。(这个应该是很早版本才会。笔者现在已经无法复现) 转载: http://blog.csdn.net/lxdcyh/article/details/4018054 字符串在Python内部的表示是unicode编码，因此，在做编码转换时，通常需要以unicode作为中间编码，即先将其他编码的字符串解码decode成unicode，再从unicode编码encode成另一种编码。 decode的作用是将其他编码的字符串转换成unicode编码，如str1.decode(&#39;gb2312&#39;)，表示将gb2312编码的字符串str1转换成unicode编码。 encode的作用是将unicode编码转换成其他编码的字符串，如str2.encode(‘gb2312’)，表示将unicode编码的字符串str2转换成gb2312编码 代码中字符串的默认编码与代码文件本身的编码一致。 如：s=’中文’ 如果是在utf8的文件中，该字符串就是utf8编码，如果是在gb2312的文件中，则其编码为gb2312。这种情况下，要进行编码转换，都需要先用decode方法将其转换成unicode编码，再使用encode方法将其转换成其他编码。通常，在没有指定特定的编码方式时，都是使用的系统默认编码创建的代码文件 如果字符串是这样定义：s=u’中文’ 则该字符串的编码就被指定为unicode了，即python的内部编码，而与代码文件本身的编码无关。因此，对于这种情况做编码转换，只需要直接使用encode方法将其转换成指定编码即可。 如果一个字符串已经是unicode了，再进行解码则将出错，因此通常要对其编码方式是否为unicode进行判断： 12isinstance(s, unicode) #用来判断是否为unicode 用非unicode编码形式的str来encode会报错 如何获得系统的默认编码？ 1234#!/usr/bin/env python#coding=utf-8import sysprint sys.getdefaultencoding() 该段程序在Win10(1079)上输出为：ascii 在某些IDE中，字符串的输出总是出现乱码，甚至错误，其实是由于IDE的结果输出控制台自身不能显示字符串的编码，而不是程序本身的问题。 如在UliPad(注:UliPad是wxPython的动力，导向和灵活的编程器)中运行如下代码： 12s=u&quot;中文&quot;print s 会提示：UnicodeEncodeError: ‘ascii’ codec can’t encode characters in position 0-1: ordinal not in range(128)。这是因为UliPad在控制台信息输出窗口是按照ascii编码输出的（系统的默认编码是ascii），而上面代码中的字符串是Unicode编码的，所以输出时产生了错误。 将最后一句改为：print s.encode(&#39;gb2312&#39;) 则能正确输出“中文”两个字。 若最后一句改为：print s.encode(&#39;utf8&#39;) 则输出：/xe4/xb8/xad/xe6/x96/x87，这是控制台信息输出窗口按照ascii编码输出utf8编码的字符串的结果。 unicode(str,&#39;gb2312&#39;)与str.decode(&#39;gb2312&#39;)是一样的，都是将gb2312编码的str转为unicode编码 使用str.__class__可以查看str的编码形式为str类型。 window默认编码gbk；linux默认编码utf8 原理说了半天，最后来个包治百病的吧：(天涯)：下面代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#!/usr/bin/env python #coding=utf-8def getCoding(strInput): ''' 获取编码格式 ''' if isinstance(strInput, unicode): return "unicode" try: strInput.decode("utf8") return 'utf8' except: pass try: strInput.decode("gbk") return 'gbk' except: pass def tran2UTF8(strInput): ''' 转化为utf8格式 ''' strCodingFmt = getCoding(strInput) if strCodingFmt == "utf8": return strInput elif strCodingFmt == "unicode": return strInput.encode("utf8") elif strCodingFmt == "gbk": return strInput.decode("gbk").encode("utf8")def tran2GBK(strInput): ''' 转化为gbk格式 ''' strCodingFmt = getCoding(strInput) if strCodingFmt == "gbk": return strInput elif strCodingFmt == "unicode": return strInput.encode("gbk") elif strCodingFmt == "utf8": return strInput.decode("utf8").encode("gbk")s = "中文"if isinstance(s, unicode): #s=u"中文" print s.encode('gb2312') print "我是Unicode编码的"elif getCoding(s) == "utf8": #s="中文" print s.decode('utf-8').encode('gb2312') print "我是utf-8编码的"else: print s.decode('gbk').encode('gbk') print "我是gbk编码的" 上图结果一：以utf-8格式保存的py文件。图二：以ascii格式保存的py文件。 编码检测包 chardet 知识点：因此，转码的时候一定要先搞明白，字符串str是什么编码，然后decode成unicode，然后再encode成其他编码 插入数据库报错的解决方案:UnicodeDecodeError: ‘ascii’ codec can’t decode byte 123import sysreload(sys)sys.setdefaultencoding(&apos;utf8&apos;) Unicode字符串除了多了一个 u 之外，与普通字符串没啥区别，转义字符和多行表示法仍然有效： 转义： 1234567891011u'中文\n日文\n韩文'#多行：u'''第一行第二行'''#raw+多行：ur'''Python的Unicode字符串支持"中文","日文","韩文"等多种语言''' 如果中文字符串在Python环境下遇到 UnicodeDecodeError，这是因为.py文件保存的格式有问题。可以在第一行添加注释 1234# -*- coding: utf-8 -*-#简洁版#coding=utf-8 目的是告诉Python解释器，用UTF-8编码读取源代码。然后用Notepad++ 另存为… 并选择UTF-8格式保存。 编程任务：用多行Unicode字符串表示下面的唐诗并打印： 静夜思 床前明月光，疑是地上霜。举头望明月，低头思故乡。 知识点: https://www.python.org/dev/peps/pep-0263/ python定义文件编码到底用哪种？ 12345# coding=&lt;encoding name&gt; #!/usr/bin/python# -*- coding: &lt;encoding name&gt; -*-#!/usr/bin/python# vim: set fileencoding=&lt;encoding name&gt; : 这些都可以只要第一二行能满足如下正则表达式 1^[ \t\v]*#.*?coding[:=][ \t]*([-_.a-zA-Z0-9]+) 12345678910# -*- coding: utf-8 -*-# This Python file uses the following encoding: utf-8# 花式标明print '''静夜思床前明月光，疑是地上霜。举头望明月，低头思故乡。''' 如果不标明文件编码或找不到。python会默认你是ASCII 整数和浮点数Python支持对整数和浮点数直接进行四则混合运算，运算规则和数学上的四则运算规则完全一致。 基本的运算： 1231 + 2 + 3 # ==&gt; 64 * 5 - 6 # ==&gt; 147.5 / 8 + 2.1 # ==&gt; 3.0375 使用括号可以提升优先级，这和数学运算完全一致，注意只能使用小括号，但是括号可以嵌套很多层： 12(1 + 2) * 3 # ==&gt; 9(2.2 + 3.3) / (1.5 * (9 - 0.3)) # ==&gt; 0.42145593869731807 和数学运算不同的地方是，Python的整数运算结果仍然是整数，浮点数运算结果仍然是浮点数： 121 + 2 # ==&gt; 整数 31.0 + 2.0 # ==&gt; 浮点数 3.0 但是整数和浮点数混合运算的结果就变成浮点数了： 11 + 2.0 # ==&gt; 浮点数 3.0 为什么要区分整数运算和浮点数运算呢？ 这是因为整数运算的结果永远是精确的，而浮点数运算的结果不一定精确，因为计算机内存再大，也无法精确表示出无限循环小数，比如 0.1 换成二进制表示就是无限循环小数。 那整数的除法运算遇到除不尽的时候，结果难道不是浮点数吗？我们来试一下： 111 / 4 # ==&gt; 2 令很多初学者惊讶的是，Python的整数除法，即使除不尽，结果仍然是整数，余数直接被扔掉。不过，Python提供了一个求余的运算 % 可以计算余数： 111 % 4 # ==&gt; 3 如果我们要计算 11 / 4 的精确结果，按照“整数和浮点数混合运算的结果是浮点数”的法则，把两个数中的一个变成浮点数再运算就没问题了： 111.0 / 4 # ==&gt; 2.75 编程任务：请计算 2.5 + 10 / 4 ,并解释计算结果为什么不是期望的 5.0 ? 请修复上述运算，使得计算结果是 5.0 1print 2.5 + 10.0 / 4 运行结果： 15.0 布尔类型我们已经了解了Python支持布尔类型的数据，布尔类型只有True和False两种值，但是布尔类型有以下几种运算： 与运算：只有两个布尔值都为 True 时，计算结果才为 True。 1234True and True # ==&gt; TrueTrue and False # ==&gt; FalseFalse and True # ==&gt; FalseFalse and False # ==&gt; False 或运算：只要有一个布尔值为 True，计算结果就是 True。 1234True or True # ==&gt; TrueTrue or False # ==&gt; TrueFalse or True # ==&gt; TrueFalse or False # ==&gt; False 非运算：把True变为False，或者把False变为True： 12not True # ==&gt; Falsenot False # ==&gt; True 布尔运算在计算机中用来做条件判断，根据计算结果为True或者False，计算机可以自动执行不同的后续代码。 在Python中，布尔类型还可以与其他数据类型做 and、or和not运算，请看下面的代码： 知识点：Python把0、空字符串’’和None看成 False，其他数值和非空字符串都看成 True。短路运算 12a = Trueprint a and 'a=T' or 'a=F' 计算结果不是布尔类型，而是字符串 &#39;a=T&#39;，这是为什么呢？ 因为Python把0、空字符串’’和None看成 False，其他数值和非空字符串都看成 True，所以： True and ‘a=T’ 计算结果是 ‘a=T’继续计算 ‘a=T’ or ‘a=F’ 计算结果还是 ‘a=T’要解释上述结果，又涉及到 and 和 or 运算的一条重要法则：短路计算。 在计算 a and b时，如果 a 是 False，则根据与运算法则，整个结果必定为 False，因此返回 a；如果 a 是 True，则整个计算结果必定取决与 b，因此返回 b。 在计算 a or b 时，如果 a 是 True，则根据或运算法则，整个计算结果必定为 True，因此返回 a；如果 a 是 False，则整个计算结果必定取决于 b，因此返回 b。 所以Python解释器在做布尔运算时，只要能提前确定计算结果，它就不会往后算了，直接返回结果。 编码任务：请运行如下代码，并解释打印的结果： 1234a = 'python'print 'hello,', a or 'world'b = ''print 'hello,', b or 'world' 1234567# -*- coding: utf-8 -*-a = 'python'print 'hello,', a or 'world'#a为非空，则输出ab = ''#b为空，输出worldprint 'hello,', b or 'world' 运行结果： 12hello, pythonhello, world Python集合类型:list和tuple创建listPython内置的一种数据类型是列表：list。list是一种有序的集合，可以随时添加和删除其中的元素。 比如，列出班里所有同学的名字，就可以用一个list表示： 12&gt;&gt;&gt; ['Michael', 'Bob', 'Tracy']['Michael', 'Bob', 'Tracy'] list是数学意义上的有序集合，也就是说，list中的元素是按照顺序排列的。 构造list非常简单，按照上面的代码，直接用 [ ]把list的所有元素都括起来，就是一个list对象。通常，我们会把list赋值给一个变量，这样，就可以通过变量来引用list： 123&gt;&gt;&gt; classmates = ['Michael', 'Bob', 'Tracy']&gt;&gt;&gt; classmates # 打印classmates变量的内容['Michael', 'Bob', 'Tracy'] 由于Python是动态语言，所以list中包含的元素并不要求都必须是同一种数据类型，我们完全可以在list中包含各种数据： 1&gt;&gt;&gt; L = [&apos;Michael&apos;, 100, True] 一个元素也没有的list，就是空list： 1&gt;&gt;&gt; empty_list = [] 编程任务 假设班里有3名同学：Adam，Lisa和Bart，他们的成绩分别是 95.5，85 和 59，请按照 名字, 分数, 名字, 分数… 的顺序按照分数从高到低用一个list表示，然后打印出来。 12L = ['Adam', 95.5,'Lisa', 85, 'Bart', 59]print L 运行结果: 1[&apos;Adam&apos;, 95.5, &apos;Lisa&apos;, 85, &apos;Bart&apos;, 59] 注：list本身就是有序的。所以直接打印即可。 Python按照索引访问list由于list是一个有序集合，所以，我们可以用一个list按分数从高到低表示出班里的3个同学： 1&gt;&gt;&gt; L = [&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;] 那我们如何从list中获取指定第 N 名的同学呢？方法是通过索引来获取list中的指定元素。 需要特别注意的是，索引从 0 开始，也就是说，第一个元素的索引是0，第二个元素的索引是1，以此类推。 因此，要打印第一名同学的名字，用 L[0]: 12345678910&gt;&gt;&gt; print L[0]Adam#要打印第二名同学的名字，用 L[1]:&gt;&gt;&gt; print L[1]Lisa#要打印第三名同学的名字，用 L[2]:&gt;&gt;&gt; print L[2]Bart 要打印第四名同学的名字，用 L[3]: 1234&gt;&gt;&gt; print L[3]Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;IndexError: list index out of range 报错了！IndexError意思就是索引超出了范围，因为上面的list只有3个元素，有效的索引是 0，1，2。 所以，使用索引时，千万注意不要越界。 编程任务 三名同学的成绩可以用一个list表示：L = [95.5, 85, 59] 请按照索引分别打印出第一名、第二名、第三名，同时测试 print L[3]。 实现代码： 12345L = [95.5,85,59]print L[0]print L[1]print L[2]print L[3] 运行结果： 1234567Traceback (most recent call last): File &quot;index.py&quot;, line 5, in print L[3]IndexError: list index out of range95.58559 知识点：正序从0开始，逆序从-1开始是最好一个list内容。 当索引数字为负数时，表示逆序读出List中的内容，记住List的最后一个空间的编号为-1开始 倒序访问list我们还是用一个list按分数从高到低表示出班里的3个同学： 1&gt;&gt;&gt; L = [&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;] 这时，老师说，请分数最低的同学站出来。 要写代码完成这个任务，我们可以先数一数这个 list，发现它包含3个元素，因此，最后一个元素的索引是2： 12&gt;&gt;&gt; print L[2]Bart Bart同学是最后一名，俗称倒数第一，所以，我们可以用 -1 这个索引来表示最后一个元素： 12&gt;&gt;&gt; print L[-1]Bart Bart同学表示躺枪。 类似的，倒数第二用 -2 表示，倒数第三用 -3 表示，倒数第四用 -4 表示： 123456789&gt;&gt;&gt; print L[-2]Lisa&gt;&gt;&gt; print L[-3]Adam&gt;&gt;&gt; print L[-4]Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;IndexError: list index out of rangeL[-4] 报错了，因为倒数第四不存在，一共只有3个元素。 使用倒序索引时，也要注意不要越界。 编程任务 三名同学的成绩可以用一个list表示：L = [95.5, 85, 59] 请按照倒序索引分别打印出倒数第一、倒数第二、倒数第三。 实现代码： 12345L = [95.5, 85, 59]print L[-1]print L[-2]print L[-3]print L[-4] 运行结果： 1234567Traceback (most recent call last): File &quot;index.py&quot;, line 5, in print L[-4]IndexError: list index out of range598595.5 list添加新元素(append insert)现在，班里有3名同学： 1&gt;&gt;&gt; L = [&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;] 今天，班里转来一名新同学 Paul，如何把新同学添加到现有的 list 中呢？ 第一个办法是用 list 的 append() 方法，把新同学追加到 list 的末尾： 1234&gt;&gt;&gt; L = [&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;]&gt;&gt;&gt; L.append(&apos;Paul&apos;)&gt;&gt;&gt; print L[&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;, &apos;Paul&apos;] append()总是把新的元素添加到 list 的尾部。 如果 Paul 同学表示自己总是考满分，要求添加到第一的位置，怎么办？ 方法是用list的 insert()方法，它接受两个参数，第一个参数是索引号，第二个参数是待添加的新元素： 1234&gt;&gt;&gt; L = [&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;]&gt;&gt;&gt; L.insert(0, &apos;Paul&apos;)&gt;&gt;&gt; print L[&apos;Paul&apos;, &apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;] L.insert(0, &#39;Paul&#39;) 的意思是，’Paul’将被添加到索引为 0 的位置上（也就是第一个），而原来索引为 0 的Adam同学，以及后面的所有同学，都自动向后移动一位。 编程任务 假设新来一名学生Paul，Paul 同学的成绩比Bart好，但是比Lisa差，他应该排到第三名的位置，请用代码实现。 代码实现: 123L = ['Adam', 'Lisa', 'Bart']L.insert(2,'paul')print L 运行结果: 1['Adam', 'Lisa', 'paul', 'Bart'] 正向第三名索引号为2.倒数第三名索引号为-3 list删除元素(pop)Paul同学刚来几天又要转走了，那么我们怎么把Paul 从现有的list中删除呢？ 如果Paul同学排在最后一个，我们可以用list的pop()方法删除： 12345&gt;&gt;&gt; L = [&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;, &apos;Paul&apos;]&gt;&gt;&gt; L.pop()&apos;Paul&apos;&gt;&gt;&gt; print L[&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;] pop()方法总是删掉list的最后一个元素，并且它还返回这个元素，所以我们执行 L.pop() 后，会打印出 ‘Paul’。 如果Paul同学不是排在最后一个怎么办？比如Paul同学排在第三： 1&gt;&gt;&gt; L = [&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Paul&apos;, &apos;Bart&apos;] 要把Paul踢出list，我们就必须先定位Paul的位置。由于Paul的索引是2，因此，用 pop(2)把Paul删掉： 1234&gt;&gt;&gt; L.pop(2)&apos;Paul&apos;&gt;&gt;&gt; print L[&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;] 两种方式：直接pop()默认删除第一个，括号内指定参数：索引，删除索引位置上。 编码任务1L = [&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Paul&apos;, &apos;Bart&apos;] Paul的索引是2，Bart的索引是3，如果我们要把Paul和Bart都删掉，请解释下面的代码为什么不能正确运行： 12L.pop(2)L.pop(3) 怎样调整代码可以把Paul和Bart都正确删除掉？ 解释：因为语句是按顺序执行的删除了Paul之后。索引号3已经越界。我们要删除的Bart已经变成2了。 知识点：这教育我们删除list时要秉着从前到后顺序。 List替换元素假设现在班里仍然是3名同学： &gt;&gt;&gt; L = [&#39;Adam&#39;, &#39;Lisa&#39;, &#39;Bart&#39;] 现在，Bart同学要转学走了，碰巧来了一个Paul同学，要更新班级成员名单，我们可以先把Bart删掉，再把Paul添加进来。 另一个办法是直接用Paul把Bart给替换掉： 123&gt;&gt;&gt; L[2] = &apos;Paul&apos;&gt;&gt;&gt; print LL = [&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Paul&apos;] 对list中的某一个索引赋值，就可以直接用新的元素替换掉原来的元素，list包含的元素个数保持不变。 由于Bart还可以用 -1 做索引，因此，下面的代码也可以完成同样的替换工作： &gt;&gt;&gt; L[-1] = &#39;Paul&#39; 编程任务 班里的同学按照分数排名是这样的：L = [‘Adam’, ‘Lisa’, ‘Bart’]但是，在一次考试后，Bart同学意外取得第一，而Adam同学考了倒数第一。 请通过对list的索引赋值，生成新的排名。 实现代码： 1234L = ['Adam', 'Lisa', 'Bart']L[0]='Bart'L[-1]='Adam'print L 运行结果： 1[&apos;Bart&apos;, &apos;Lisa&apos;, &apos;Adam&apos;] 创建tupletuple是另一种有序的列表，中文翻译为“ 元组 ”。tuple 和 list 非常类似，但是，知识点：tuple一旦创建完毕，就不能修改了。 同样是表示班里同学的名称，用tuple表示如下： 1&gt;&gt;&gt; t = (&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;) 创建tuple和创建list唯一不同之处是用( )替代了[ ]。 现在，这个 t 就不能改变了，tuple没有 append()方法，也没有insert()和pop()方法。所以，新同学没法直接往 tuple 中添加，老同学想退出 tuple 也不行。 获取 tuple 元素的方式和 list 是一模一样的，我们可以正常使用 t[0]，t[-1]等索引方式访问元素，但是不能赋值成别的元素，不信可以试试： 1234&gt;&gt;&gt; t[0] = &apos;Paul&apos;Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: &apos;tuple&apos; object does not support item assignment 编程任务 创建一个tuple，顺序包含0 - 9这10个数。 实现代码： 12t = (0,1,2,3,4,5,6,7,8,9)print t 运行结果： 1(0, 1, 2, 3, 4, 5, 6, 7, 8, 9) 创建单元素tupletuple和list一样，可以包含 0 个、1个和任意多个元素。 包含多个元素的 tuple，前面我们已经创建过了。 包含 0 个元素的 tuple，也就是空tuple，直接用 ()表示： 123&gt;&gt;&gt; t = ()&gt;&gt;&gt; print t() 创建包含1个元素的 tuple 呢？来试试： 123&gt;&gt;&gt; t = (1)&gt;&gt;&gt; print t1 好像哪里不对！t 不是 tuple ，而是整数1。为什么呢？ 知识点：单元素tuple的()被当做优先级。(1)变成整数1.单元素括号结尾加, 因为()既可以表示tuple，又可以作为括号表示运算时的优先级，结果 (1) 被Python解释器计算出结果 1，导致我们得到的不是tuple，而是整数 1。 正是因为用()定义单元素的tuple有歧义，所以 Python 规定，单元素 tuple 要多加一个逗号,，这样就避免了歧义： 123&gt;&gt;&gt; t = (1,)&gt;&gt;&gt; print t(1,) Python在打印单元素tuple时，也自动添加了一个,，为了更明确地告诉你这是一个tuple。 多元素 tuple 加不加这个额外的,效果是一样的： 123&gt;&gt;&gt; t = (1, 2, 3,)&gt;&gt;&gt; print t(1, 2, 3) 编程任务下面代码为什么没有创建出包含一个学生的 tuple： 12t = ('Adam')print t 请修改代码，确保 t 是一个tuple。 因为单元素tuple的括号被当做是优先级标志。要加上额外,标识这是一个元组。 实现代码： 12t = ('Adam',)print t 运行结果: 1(&apos;Adam&apos;,) “可变”的tuple(指向不变。指向的东西可以变)前面我们看到了tuple一旦创建就不能修改。现在，我们来看一个可变的tuple： 1&gt;&gt;&gt; t = (&apos;a&apos;, &apos;b&apos;, [&apos;A&apos;, &apos;B&apos;]) 注意到 t 有 3 个元素：&#39;a&#39;，&#39;b&#39;和一个list：[&#39;A&#39;, &#39;B&#39;]。list作为一个整体是tuple的第3个元素。list对象可以通过 t[2] 拿到： 12345&gt;&gt;&gt; L = t[2]# 然后，我们把list的两个元素改一改：&gt;&gt;&gt; L[0] = 'X'&gt;&gt;&gt; L[1] = 'Y' 再看看tuple的内容： 12&gt;&gt;&gt; print t(&apos;a&apos;, &apos;b&apos;, [&apos;X&apos;, &apos;Y&apos;]) 不是说tuple一旦定义后就不可变了吗？怎么现在又变了？ 别急，我们先看看定义的时候tuple包含的3个元素： 当我们把list的元素’A’和’B’修改为’X’和’Y’后，tuple变为： 表面上看，tuple的元素确实变了，但其实变的不是 tuple 的元素，而是list的元素。 tuple一开始指向的list并没有改成别的list，所以，tuple所谓的“不变”是说，tuple的每个元素，指向永远不变。即指向’a’，就不能改成指向’b’，指向一个list，就不能改成指向其他对象，但指向的这个list本身是可变的！ 理解了指向不变后，要创建一个内容也不变的tuple怎么做？那就必须保证tuple的每一个元素本身也不能变。 编程任务： 定义了tuple：t = (‘a’, ‘b’, [‘A’, ‘B’]) 由于 t 包含一个list元素，导致tuple的内容是可变的。能否修改上述代码，让tuple内容不可变？ 解答：将里面的list替换成一个不可变的元素。比如tuple。 实现代码: 12t = (&apos;a&apos;, &apos;b&apos;, (&apos;A&apos;, &apos;B&apos;))print t 运行结果： 1(&apos;a&apos;, &apos;b&apos;, (&apos;A&apos;, &apos;B&apos;)) Python的条件判断和循环语句if语句计算机之所以能做很多自动化的任务，因为它可以自己做条件判断。 比如，输入用户年龄，根据年龄打印不同的内容，在Python程序中，可以用if语句实现： 12345age = 20if age &gt;= 18: print 'your age is', age print 'adult'print 'END' 注意: Python代码的缩进规则。具有相同缩进的代码被视为代码块，上面的3，4行 print 语句就构成一个代码块（但不包括第5行的print）。如果 if 语句判断为 True，就会执行这个代码块。 知识点: 缩进请严格按照Python的习惯写法：4个空格，不要使用Tab，更不要混合Tab和空格，否则很容易造成因为缩进引起的语法错误。 注意: if 语句后接表达式，然后用:表示代码块开始。 如果你在Python交互环境下敲代码，还要特别留意缩进，并且退出缩进需要多敲一行回车： 12345&gt;&gt;&gt; age = 20&gt;&gt;&gt; if age &gt;= 18:... print &apos;your age is&apos;, age... print &apos;adult&apos;... 12your age is 20adult 编程任务 如果成绩达到60分或以上，视为passed。 假设Bart同学的分数是75，请用if语句判断是否能打印出 passed: 实现代码: 123score = 75if score&gt;=60: print 'passed' 运行结果: 1passed if-else当 if 语句判断表达式的结果为 True 时，就会执行 if 包含的代码块： 12if age &gt;= 18: print 'adult' 如果我们想判断年龄在18岁以下时，打印出 ‘teenager’，怎么办？ 方法是再写一个 if: 12if age &lt; 18: print 'teenager' 或者用 not 运算： 12if not age &gt;= 18: print 'teenager' 细心的同学可以发现，这两种条件判断是“非此即彼”的，要么符合条件1，要么符合条件2，因此，完全可以用一个 if ... else ... 语句把它们统一起来： 1234if age &gt;= 18: print 'adult'else: print 'teenager' 利用 if ... else ...语句，我们可以根据条件表达式的值为 True 或者 False ，分别执行 if 代码块或者 else 代码块。 注意: else 后面有个:。 编程任务 如果成绩达到60分或以上，视为passed，否则视为failed。 假设Bart同学的分数是55，请用if语句打印出 passed 或者 failed: 实现代码： 12345score = 55if score&gt;=60: print 'passed'else: print 'failed' 运行结果: 1failed if-elif-else有的时候，一个 if … else … 还不够用。比如，根据年龄的划分： 条件1：18岁或以上：adult 条件2：6岁或以上：teenager 条件3：6岁以下：kid 我们可以用一个 if age &gt;= 18 判断是否符合条件1，如果不符合，再通过一个 if 判断 age &gt;= 6 来判断是否符合条件2，否则，执行条件3： 1234567if age &gt;= 18: print &apos;adult&apos;else: if age &gt;= 6: print &apos;teenager&apos; else: print &apos;kid&apos; 这样写出来，我们就得到了一个两层嵌套的 if … else … 语句。这个逻辑没有问题，但是，如果继续增加条件，比如3岁以下是 baby： 12345678910if age &gt;= 18: print &apos;adult&apos;else: if age &gt;= 6: print &apos;teenager&apos; else: if age &gt;= 3: print &apos;kid&apos; else: print &apos;baby&apos; 这种缩进只会越来越多，代码也会越来越难看。 要避免嵌套结构的 if … else …，我们可以用 if … 多个elif … else … 的结构，一次写完所有的规则： 12345678if age &gt;= 18: print &apos;adult&apos;elif age &gt;= 6: print &apos;teenager&apos;elif age &gt;= 3: print &apos;kid&apos;else: print &apos;baby&apos; elif 意思就是 else if。这样一来，我们就写出了结构非常清晰的一系列条件判断。 特别注意: 这一系列条件判断会从上到下依次判断，如果某个判断为 True，执行完对应的代码块，后面的条件判断就直接忽略，不再执行了。 请思考下面的代码： 1234567age = 8if age &gt;= 6: print &apos;teenager&apos;elif age &gt;= 18: print &apos;adult&apos;else: print &apos;kid&apos; 当 age = 8 时，结果正确，但 age = 20 时，为什么没有打印出 adult？ 如果要修复，应该如何修复？ 知识点解答: 因为当age=20.第一个条件&gt;=6满足就短路了。因此我们在设置条件应该从严格到松泛. 1234567age = 20if age &gt;= 18: print &apos;teenager&apos;elif age &gt;= 6: print &apos;adult&apos;else: print &apos;kid&apos; 编程任务 如果按照分数划定结果： 90分或以上：excellent 80分或以上：good 60分或以上：passed 60分以下：failed 请编写程序根据分数打印结果。 实现代码: 12345678910score = 85if score&gt;=90: print 'excellent'elif score&gt;=80: print 'good'elif score&gt;=60: print 'passed'else: print 'failed' 运行结果: 1good for循环list或tuple可以表示一个有序集合。如果我们想依次访问一个list中的每一个元素呢？比如 list： 1234L = ['Adam', 'Lisa', 'Bart']print L[0]print L[1]print L[2] 如果list只包含几个元素，这样写还行，如果list包含1万个元素，我们就不可能写1万行print。 这时，循环就派上用场了。 Python的 for 循环就可以依次把list或tuple的每个元素迭代出来： 123L = [&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;]for name in L: print name 注意: name 这个变量是在 for 循环中定义的(这是一个临时变量名字可自定义)，意思是，依次取出list中的每一个元素，并把元素赋值给 name，然后执行for循环体（就是缩进的代码块）。 这样一来，遍历一个list或tuple就非常容易了。 编程任务 班里考试后，老师要统计平均成绩，已知4位同学的成绩用list表示如下：L = [75, 92, 59, 68] 请利用for循环计算出平均成绩。 实现代码: 12345L = [75, 92, 59, 68]sum = 0.0for x in L: sum =sum+xprint sum / 4 运行结果： 173.5 while循环和 for 循环不同的另一种循环是 while 循环，while 循环不会迭代 list 或 tuple 的元素，而是根据表达式判断循环是否结束。 比如要从 0 开始打印不大于 N 的整数： 12345N = 10x = 0while x &lt; N: print x x = x + 1 while循环每次先判断 x &lt; N，如果为True，则执行循环体的代码块,否则，退出循环。 在循环体内，x = x + 1 会让 x 不断增加，最终因为 x &lt; N 不成立而退出循环。 如果没有这一个语句，while循环在判断 x &lt; N 时总是为True，就会无限循环下去，变成死循环，所以要特别留意while循环的退出条件。 编程任务 利用while循环计算100以内奇数的和。 实现代码: 123456sum = 0x = 1while x&lt;=100: sum=sum+x x=x+2print sum 知识点: 奇数只需要从1开始不断加2都是奇数。 运行结果： 12500 break退出循环用for 循环或者 while 循环时，如果要在循环体内直接退出循环，可以使用 break 语句。 比如计算1至100的整数和，我们用while来实现： 12345678sum = 0x = 1while True: sum = sum + x x = x + 1 if x &gt; 100: breakprint sum 咋一看， while True 就是一个死循环，但是在循环体内，我们还判断了 x &gt; 100 条件成立时，用break语句退出循环，这样也可以实现循环的结束。 编程任务 利用 while True 无限循环配合 break 语句，计算 1 + 2 + 4 + 8 + 16 + … 的前20项的和。 实现代码: 12345678910sum = 0x = 1n = 1while True: sum =sum+x x =2*x n =n+1 if n &gt;20: breakprint sum 运行结果: 11048575 continue继续循环在循环过程中，可以用break退出当前循环，还可以用continue跳过后续循环代码，继续下一次循环。 假设我们已经写好了利用for循环计算平均分的代码： 1234567L = [75, 98, 59, 81, 66, 43, 69, 85]sum = 0.0n = 0for x in L: sum = sum + x n = n + 1print sum / n 现在老师只想统计及格分数的平均分，就要把 x &lt; 60 的分数剔除掉，这时，利用continue，可以做到当 x &lt; 60的时候，不继续执行循环体的后续代码，直接进入下一次循环： 12345for x in L: if x &lt; 60: continue sum = sum + x n = n + 1 coutinue: 跳过下面的代码。开始下一次循环。 编程任务 对已有的计算 0 - 100 的while循环进行改造，通过增加 continue 语句，使得只计算奇数的和： 12345678sum = 0x = 1while True: sum = sum + x x = x + 1 if x &gt; 100: breakprint sum 思路: if判断到是偶数，continue跳过。 实现代码: 1234567891011sum = 0x = 0while True: x = x + 1 if x &gt; 100: break if x%2==0: continue sum = sum+x print sum 运行结果: 12500 多重循环(嵌套循环)在循环内部，还可以嵌套循环，我们来看一个例子： 123for x in [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;]: for y in [&apos;1&apos;, &apos;2&apos;, &apos;3&apos;]: print x + y x 每循环一次，y就会循环 3 次，这样，我们可以打印出一个全排列： 123456789A1A2A3B1B2B3C1C2C3 编程任务 对100以内的两位数，请使用一个两重循环打印出所有十位数数字比个位数数字小的数，例如，23（2 &lt; 3）。 代码实现。 123456tens_place = [1,2,3,4,5,6,7,8,9]ones_place = [0,1,2,3,4,5,6,7,8,9]for x in tens_place: for y in ones_place: if x&lt;y: print x*10 + y 运行结果： 12345678910121314151617181923略 重要的数据类型Dict和Set什么是dict我们已经知道，list 和 tuple 可以用来表示顺序集合，例如，班里同学的名字： 1[&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;] 或者考试的成绩列表： 1[95, 85, 59] 但是，要根据名字找到对应的成绩，用两个 list 表示就不方便。 如果把名字和分数关联起来，组成类似的查找表： 123&apos;Adam&apos; ==&gt; 95&apos;Lisa&apos; ==&gt; 85&apos;Bart&apos; ==&gt; 59 给定一个名字，就可以直接查到分数。 Python的 dict 就是专门干这件事的。用 dict 表示名字-成绩的查找表如下： 12345d = &#123; &apos;Adam&apos;: 95, &apos;Lisa&apos;: 85, &apos;Bart&apos;: 59&#125; 我们把名字称为key，对应的成绩称为value，dict就是通过 key来查找 value。 花括号 {} 表示这是一个dict，然后按照 key: value, 写出来即可。最后一个 key: value 的逗号可以省略。 知识点： 区别小课堂 单元素的tuple必须在后面多加一个逗号。 dict最后的逗号可以省略 由于dict也是集合，len() 函数可以计算任意集合的大小： 12&gt;&gt;&gt; len(d)3 知识点：注意: 一个 key-value 算一个，因此，dict大小为3。 编程任务 新来的Paul同学成绩是 75 分，请编写一个dict，把Paul同学的成绩也加进去。 12345d = &#123; &apos;Adam&apos;: 95, &apos;Lisa&apos;: 85, &apos;Bart&apos;: 59&#125; 实现代码: 1234567d = &#123; &apos;Adam&apos;: 95, &apos;Lisa&apos;: 85, &apos;Bart&apos;: 59, &apos;Paul&apos;: 75 &#125; 访问dict我们已经能创建一个dict，用于表示名字和成绩的对应关系： 12345d = &#123; &apos;Adam&apos;: 95, &apos;Lisa&apos;: 85, &apos;Bart&apos;: 59&#125; 那么，如何根据名字来查找对应的成绩呢？ 可以简单地使用 d[key] 的形式来查找对应的 value，这和 list 很像，不同之处是，list 必须使用索引返回对应的元素，而dict使用key： 1234567&gt;&gt;&gt; print d[&apos;Adam&apos;]95&gt;&gt;&gt; print d[&apos;Paul&apos;]Traceback (most recent call last): File &quot;index.py&quot;, line 11, in &lt;module&gt; print d[&apos;Paul&apos;]KeyError: &apos;Paul&apos; 注意: 通过 key 访问 dict 的value，只要 key 存在，dict就返回对应的value。如果key不存在，会直接报错：KeyError。 知识点：避免 KeyError 发生，有两个办法： 是先判断一下 key 是否存在，用 in 操作符： 12if &apos;Paul&apos; in d: print d[&apos;Paul&apos;] 如果 ‘Paul’ 不存在，if语句判断为False，自然不会执行 print d[‘Paul’] ，从而避免了错误。 是使用dict本身提供的一个get方法，在Key不存在的时候，返回None： 1234&gt;&gt;&gt; print d.get(&apos;Bart&apos;)59&gt;&gt;&gt; print d.get(&apos;Paul&apos;)None 编程任务根据如下dict：12345d = &#123; &apos;Adam&apos;: 95, &apos;Lisa&apos;: 85, &apos;Bart&apos;: 59&#125; 请打印出：Adam: 95Lisa: 85Bart: 59 实现代码: 12345678d = &#123; &apos;Adam&apos;: 95, &apos;Lisa&apos;: 85, &apos;Bart&apos;: 59&#125;print &apos;Adam:&apos;,d[&apos;Adam&apos;]print &apos;Lisa:&apos;,d.get(&apos;Lisa&apos;)print &apos;Bart:&apos;,d[&apos;Bart&apos;] 运行结果： 123Adam: 95Lisa: 85Bart: 59 dict的特点知识点：dict查找速度快。list查找速度随着元素增加而逐渐下降。缺点：内存占用大。list慢但内存占用小。 dict的第一个特点是查找速度快，无论dict有10个元素还是10万个元素，查找速度都一样。而list的查找速度随着元素增加而逐渐下降。 不过dict的查找速度快不是没有代价的，dict的缺点是占用内存大，还会浪费很多内容，list正好相反，占用内存小，但是查找速度慢。 由于dict是按 key 查找，所以，在一个dict中，key不能重复。 dict的第二个特点就是存储的key-value序对是没有顺序的！这和list不一样： 12345d = &#123; &apos;Adam&apos;: 95, &apos;Lisa&apos;: 85, &apos;Bart&apos;: 59&#125; 当我们试图打印这个dict时： 12&gt;&gt;&gt; print d&#123;&apos;Lisa&apos;: 85, &apos;Adam&apos;: 95, &apos;Bart&apos;: 59&#125; 打印的顺序不一定是我们创建时的顺序，而且，不同的机器打印的顺序都可能不同，这说明 知识点:dict内部是无序的，不能用dict存储有序的集合。 知识点：dict的第三个特点是作为 key 的元素必须不可变，Python的基本类型如字符串、整数、浮点数都是不可变的，都可以作为 key。 但是list是可变的，就不能作为 key。 可以试试用list作为key时会报什么样的错误。 不可变这个限制仅作用于key，value是否可变无所谓： 12345&#123; &apos;123&apos;: [1, 2, 3], # key 是 str，value是list 123: &apos;123&apos;, # key 是 int，value 是 str (&apos;a&apos;, &apos;b&apos;): True # key 是 tuple，并且tuple的每个元素都是不可变对象，value是 boolean&#125; 最常用的key还是字符串，因为用起来最方便。 编程任务 请设计一个dict，可以根据分数来查找名字，已知成绩如下： 123Adam: 95,Lisa: 85,Bart: 59. 实现代码: 12345d = &#123; 95:&apos;Adam&apos;, 85:&apos;Lisa&apos;, 59:&apos;Bart&apos;&#125; 运行结果：无 更新dictdict是可变的，也就是说，我们可以随时往dict中添加新的 key-value。比如已有dict： 12345d = &#123; &apos;Adam&apos;: 95, &apos;Lisa&apos;: 85, &apos;Bart&apos;: 59&#125; 要把新同学’Paul’的成绩 72 加进去，用赋值语句： 1&gt;&gt;&gt; d[&apos;Paul&apos;] = 72 再看看dict的内容： 12&gt;&gt;&gt; print d&#123;&apos;Lisa&apos;: 85, &apos;Paul&apos;: 72, &apos;Adam&apos;: 95, &apos;Bart&apos;: 59&#125; 如果 key 已经存在，则赋值会用新的 value 替换掉原来的 value： 123&gt;&gt;&gt; d[&apos;Bart&apos;] = 60&gt;&gt;&gt; print d&#123;&apos;Lisa&apos;: 85, &apos;Paul&apos;: 72, &apos;Adam&apos;: 95, &apos;Bart&apos;: 60&#125; 编程任务 请根据Paul的成绩 72 更新下面的dict：123456789d = &#123; 95: &apos;Adam&apos;, 85: &apos;Lisa&apos;, 59: &apos;Bart&apos;&#125; 实现代码: 1234567d = &#123; 95: 'Adam', 85: 'Lisa', 59: 'Bart'&#125;d[72] = 'Paul'print d 运行结果： 1&#123;72: &apos;Paul&apos;, 59: &apos;Bart&apos;, 85: &apos;Lisa&apos;, 95: &apos;Adam&apos;&#125; 遍历dict由于dict也是一个集合，所以，遍历dict和遍历list类似，都可以通过 for 循环实现。 直接使用for循环可以遍历 dict 的 key： 1234567&gt;&gt;&gt; d = &#123; 'Adam': 95, 'Lisa': 85, 'Bart': 59 &#125;&gt;&gt;&gt; for key in d:... print key... LisaAdamBart 由于通过 key 可以获取对应的 value，因此，在循环体内，可以获取到value的值。 注：这里的key只是一个约定俗称的变量，可以改为其他名字。但是推荐用key。 编程任务 请用 for 循环遍历如下的dict，打印出 name: score 来。 12345d = &#123; &apos;Adam&apos;: 95, &apos;Lisa&apos;: 85, &apos;Bart&apos;: 59&#125; 实现代码： 1234567d = &#123; &apos;Adam&apos;: 95, &apos;Lisa&apos;: 85, &apos;Bart&apos;: 59&#125;for key in d: print key+&quot;:&quot;,d[key] 运行结果: 123Lisa: 85Adam: 95Bart: 59 什么是setdict的作用是建立一组 key 和一组 value 的映射关系，dict的key是不能重复的。 有的时候，我们只想要 dict 的 key，不关心 key 对应的 value，目的就是保证这个集合的元素不会重复，这时，set就派上用场了。 set 持有一系列元素，这一点和 list 很像，但是set的元素没有重复，而且是无序的，这点和 dict 的 key很像。 知识点: 创建 set 的方式是调用 set() 并传入一个 list，list的元素将作为set的元素： 12345&gt;&gt;&gt; s = set(['A', 'B', 'C'])可以查看 set 的内容：&gt;&gt;&gt; print sset(['A', 'C', 'B']) 请注意，上述打印的形式类似 list， 但它不是 list，仔细看还可以发现，打印的顺序和原始 list 的顺序有可能是不同的，因为set内部存储的元素是无序的。 因为set不能包含重复的元素，所以，当我们传入包含重复元素的 list 会怎么样呢？ 12345&gt;&gt;&gt; s = set([&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;C&apos;])&gt;&gt;&gt; print sset([&apos;A&apos;, &apos;C&apos;, &apos;B&apos;])&gt;&gt;&gt; len(s)3 结果显示，set会自动去掉重复的元素，原来的list有4个元素，但set只有3个元素。 编程任务 请用set表示班里的4位同学：Adam, Lisa, Bart, Paul 实现代码: 12s = set(['Adam', 'Lisa', 'Bart', 'Paul'])print s 运行结果: 1set([&apos;Lisa&apos;, &apos;Paul&apos;, &apos;Adam&apos;, &apos;Bart&apos;]) 访问set由于set存储的是无序集合，所以我们没法通过索引来访问。 访问 set中的某个元素实际上就是判断一个元素是否在set中。 例如，存储了班里同学名字的set： 1&gt;&gt;&gt; s = set([&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;, &apos;Paul&apos;]) 我们可以用 in 操作符判断： Bart是该班的同学吗？ 12345678910&gt;&gt;&gt; &apos;Bart&apos; in sTrueBill是该班的同学吗？&gt;&gt;&gt; &apos;Bill&apos; in sFalsebart是该班的同学吗？&gt;&gt;&gt; &apos;bart&apos; in sFalse 知识点：大小写很重要，’Bart’ 和 ‘bart’被认为是两个不同的元素。 编程任务 由于上述set不能识别小写的名字，请改进set，使得 ‘adam’ 和 ‘bart’都能返回True。 既然大小写是不同的。那我们的set中就把大小写都包含。 实现代码: 123s = set(['Adam', 'Lisa', 'Bart', 'Paul','adam', 'lisa', 'bart', 'paul'])print 'adam' in sprint 'bart' in s 运行结果. 12TrueTrue set的特点set的内部结构和dict很像，唯一区别是不存储value，因此，判断一个元素是否在set中速度很快。 set存储的元素和dict的key类似，必须是不变对象，因此，任何可变对象是不能放入set中的。 最后，set存储的元素也是没有顺序的。 set的这些特点，可以应用在哪些地方呢？ 星期一到星期日可以用字符串&#39;MON&#39;, &#39;TUE&#39;, ... &#39;SUN&#39;表示。 假设我们让用户输入星期一至星期日的某天，如何判断用户的输入是否是一个有效的星期呢？ 可以用 if 语句判断，但这样做非常繁琐： 12345x = '???' # 用户输入的字符串if x!= 'MON' and x!= 'TUE' and x!= 'WED' ... and x!= 'SUN': print 'input error'else: print 'input ok' 注意：if 语句中的…表示没有列出的其它星期名称，测试时，请输入完整。 如果事先创建好一个set，包含&#39;MON&#39; ~ &#39;SUN&#39;： 1weekdays = set([&apos;MON&apos;, &apos;TUE&apos;, &apos;WED&apos;, &apos;THU&apos;, &apos;FRI&apos;, &apos;SAT&apos;, &apos;SUN&apos;]) 再判断输入是否有效，只需要判断该字符串是否在set中： 123456x = '???' # 用户输入的字符串if x in weekdays: print 'input ok'else: print 'input error'这样一来，代码就简单多了。 编程任务 月份也可以用set表示，请设计一个set并判断用户输入的月份是否有效。月份可以用字符串&#39;Jan&#39;, &#39;Feb&#39;, ...表示。 实现代码: 12345678910111213months = set(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul','Aug','Sep','Oct','Nov','Dec'])x1 = 'Feb'x2 = 'Sun'if x1 in months: print 'x1: ok'else: print 'x1: error'if x2 in months: print 'x2: ok'else: print 'x2: error' 运行结果: 12x1: okx2: error 遍历set由于 set 也是一个集合，所以，遍历 set 和遍历 list 类似，都可以通过 for 循环实现。 直接使用 for 循环可以遍历 set 的元素： 1234567&gt;&gt;&gt; s = set(['Adam', 'Lisa', 'Bart'])&gt;&gt;&gt; for name in s:... print name... LisaAdamBart 注意: 观察 for 循环在遍历set时，元素的顺序和list的顺序很可能是不同的，而且不同的机器上运行的结果也可能不同。 编程任务 请用 for 循环遍历如下的set，打印出 name: score 来。 1s = set([(&apos;Adam&apos;, 95), (&apos;Lisa&apos;, 85), (&apos;Bart&apos;, 59)]) 上面这个set中的每一个元素又是一个字典。 set([ ])是壳子。 (&#39;Adam&#39;, 95), (&#39;Lisa&#39;, 85), (&#39;Bart&#39;, 59)才是真正的内容 实现代码： 123s = set([('Adam', 95), ('Lisa', 85), ('Bart', 59)])for name,score in s: print name,':',score 运行结果: 123Lisa : 85Adam : 95Bart : 59 更新set(add remove)由于set存储的是一组不重复的无序元素，因此，更新set主要做两件事： 是把新的元素添加到set中 是把已有元素从set中删除。(前提是如果有) 添加元素时，用set的add()方法： 1234&gt;&gt;&gt; s = set([1, 2, 3])&gt;&gt;&gt; s.add(4)&gt;&gt;&gt; print sset([1, 2, 3, 4]) 如果添加的元素已经存在于set中，add()不会报错，但是不会加进去了： 1234&gt;&gt;&gt; s = set([1, 2, 3])&gt;&gt;&gt; s.add(3)&gt;&gt;&gt; print sset([1, 2, 3]) 删除set中的元素时，用set的remove()方法： 1234&gt;&gt;&gt; s = set([1, 2, 3, 4])&gt;&gt;&gt; s.remove(4)&gt;&gt;&gt; print sset([1, 2, 3]) 如果删除的元素不存在set中，remove()会报错： 12345&gt;&gt;&gt; s = set([1, 2, 3])&gt;&gt;&gt; s.remove(4)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;KeyError: 4 所以用add()可以直接添加，而remove()前需要判断。 编程任务 针对下面的set，给定一个list，对list中的每一个元素，如果在set中，就将其删除，如果不在set中，就添加进去。 12s = set([&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Paul&apos;])L = [&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;, &apos;Paul&apos;] 实现代码： 12345678s = set(['Adam', 'Lisa', 'Paul'])L = ['Adam', 'Lisa', 'Bart', 'Paul']for name in L: if name in s: s.remove(name) else: s.add(name)print s 函数定义与调用什么是函数我们知道圆的面积计算公式为： S = πr² 当我们知道半径r的值时，就可以根据公式计算出面积。假设我们需要计算3个不同大小的圆的面积： 123456r1 = 12.34r2 = 9.08r3 = 73.1s1 = 3.14 * r1 * r1s2 = 3.14 * r2 * r2s3 = 3.14 * r3 * r3 当代码出现有规律的重复的时候，你就需要当心了，每次写3.14 * x * x不仅很麻烦，而且，如果要把3.14改成3.14159265359的时候，得全部替换。 有了函数，我们就不再每次写s = 3.14 * x * x，而是写成更有意义的函数调用 s = area_of_circle(x)，而函数 area_of_circle本身只需要写一次，就可以多次调用。 抽象是数学中非常常见的概念。举个例子： 计算数列的和，比如：1 + 2 + 3 + … + 100，写起来十分不方便，于是数学家发明了求和符号∑，可以把1 + 2 + 3 + … + 100记作： 123100∑nn=1 这种抽象记法非常强大，因为我们看到∑就可以理解成求和，而不是还原成低级的加法运算。 而且，这种抽象记法是可扩展的，比如： 123100∑(n²+1)n=1 还原成加法运算就变成了： (1 x 1 + 1) + (2 x 2 + 1) + (3 x 3 + 1) + ... + (100 x 100 + 1)可见，借助抽象，我们才能不关心底层的具体计算过程，而直接在更高的层次上思考问题。 写计算机程序也是一样，函数就是最基本的一种代码抽象的方式。 Python不但能非常灵活地定义函数，而且本身内置了很多有用的函数，可以直接调用。 编程任务 写一个函数 实现代码： 12s = area_of_circle(x)area_of_circle(x) 运行结果： 调用函数,内置函数Python内置了很多有用的函数，我们可以直接调用。 要调用一个函数，需要知道函数的名称和参数，比如求绝对值的函数 abs，它接收一个参数。 可以直接从Python的官方网站查看文档：http://docs.python.org/2/library/functions.html#abs 也可以在交互式命令行通过 help(abs)查看abs函数的帮助信息。 调用 abs 函数： 123456&gt;&gt;&gt; abs(100)100&gt;&gt;&gt; abs(-20)20&gt;&gt;&gt; abs(12.34)12.34 调用函数的时候，如果传入的参数数量不对，会报TypeError的错误，并且Python会明确地告诉你：abs()有且仅有1个参数，但给出了两个： 1234&gt;&gt;&gt; abs(1, 2)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: abs() takes exactly one argument (2 given) 如果传入的参数数量是对的，但参数类型不能被函数所接受，也会报TypeError的错误，并且给出错误信息：str是错误的参数类型： 1234&gt;&gt;&gt; abs(&apos;a&apos;)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: bad operand type for abs(): &apos;str&apos; 而比较函数 cmp(x, y) 就需要两个参数，如果 x&lt;y，返回 -1，如果 x==y，返回0，如果 x&gt;y，返回 1： 123456&gt;&gt;&gt; cmp(1, 2)-1&gt;&gt;&gt; cmp(2, 1)1&gt;&gt;&gt; cmp(3, 3)0 Python内置的常用函数还包括数据类型转换函数，比如 int()函数可以把其他数据类型转换为整数： 1234&gt;&gt;&gt; int(&apos;123&apos;)123&gt;&gt;&gt; int(12.34)12 str()函数把其他类型转换成 str： 1234&gt;&gt;&gt; str(123)&apos;123&apos;&gt;&gt;&gt; str(1.23)&apos;1.23&apos; 编程任务 sum()函数接受一个list作为参数，并返回list所有元素之和。请计算 1*1 + 2*2 + 3*3 + ... + 100*100。 实现代码： 1234567L = []L = []x = 1while x &lt;= 100: L.append(x * x) x = x + 1print sum(L) 运行结果: 1338350 编写函数在Python中，定义一个函数要使用 def 语句，依次写出函数名、括号、括号中的参数和冒号:，然后，在缩进块中编写函数体，函数的返回值用 return语句返回。 我们以自定义一个求绝对值的 my_abs 函数为例： 12345def my_abs(x): if x &gt;= 0: return x else: return -x 请注意，函数体内部的语句在执行时，一旦执行到return时，函数就执行完毕，并将结果返回。因此，函数内部通过条件判断和循环可以实现非常复杂的逻辑。 知识点； 如果没有return语句，函数执行完毕后也会返回结果，只是结果为 None。return None可以简写为return。 编程任务 请定义一个 square_of_sum 函数，它接受一个list，返回list中每个元素平方的和。 实现代码: 12345678def square_of_sum(L): sum = 0 for x in L: sum = x*x+sum return sumprint square_of_sum([1, 2, 3, 4, 5])print square_of_sum([-5, 0, 5, 15, 25]) 运行结果: 1255900 函数之返回”多值”函数可以返回多个值吗？答案是肯定的。 比如在游戏中经常需要从一个点移动到另一个点，给出坐标、位移和角度，就可以计算出新的坐标： math包提供了sin()和 cos()函数，我们先用import引用它： 12345import mathdef move(x, y, step, angle): nx = x + step * math.cos(angle) ny = y - step * math.sin(angle) return nx, ny 这样我们就可以同时获得返回值： 123&gt;&gt;&gt; x, y = move(100, 100, 60, math.pi / 6)&gt;&gt;&gt; print x, y151.961524227 70.0 但其实这只是一种假象，Python函数返回的仍然是单一值： 123&gt;&gt;&gt; r = move(100, 100, 60, math.pi / 6)&gt;&gt;&gt; print r(151.96152422706632, 70.0) 知识点：用print打印返回结果，原来返回值是一个tuple！ 但是，在语法上，返回一个tuple可以省略括号，而多个变量可以同时接收一个tuple，按位置赋给对应的值，所以，知识点：Python的函数返回多值其实就是返回一个tuple，但写起来更方便。 编程任务 一元二次方程的定义是：ax² + bx + c = 0 请编写一个函数，返回一元二次方程的两个解。 注意：Python的math包提供了sqrt()函数用于计算平方根。 实现代码: 12345678import mathdef quadratic_equation(a, b, c): t = math.sqrt(b*b - 4*a*c) return (-b + t) / (2 * a),( -b - t )/ (2 * a)print quadratic_equation(2, 3, 0)print quadratic_equation(1, -6, 5) 运行结果: 12(0.0, -1.5)(5.0, 1.0) 递归函数在函数内部，可以调用其他函数。知识点: 如果一个函数在内部调用自身本身，这个函数就是递归函数。 举个例子，我们来计算阶乘 n! = 1 * 2 * 3 * ... * n，用函数 fact(n)表示，可以看出： fact(n) = n! = 1 * 2 * 3 * ... * (n-1) * n = (n-1)! * n = fact(n-1) * n所以，fact(n)可以表示为 n * fact(n-1)，只有n=1时需要特殊处理。 于是，fact(n)用递归的方式写出来就是： 1234def fact(n): if n==1: return 1 return n * fact(n - 1) 上面就是一个递归函数。可以试试： 123456&gt;&gt;&gt; fact(1)1&gt;&gt;&gt; fact(5)120&gt;&gt;&gt; fact(100)93326215443944152681699238856266700490715968264381621468592963895217599993229915608941463976156518286253697920827223758251185210916864000000000000000000000000 如果我们计算fact(5)，可以根据函数定义看到计算过程如下： 12345678910===&gt; fact(5)===&gt; 5 * fact(4)===&gt; 5 * (4 * fact(3))===&gt; 5 * (4 * (3 * fact(2)))===&gt; 5 * (4 * (3 * (2 * fact(1))))===&gt; 5 * (4 * (3 * (2 * 1)))===&gt; 5 * (4 * (3 * 2))===&gt; 5 * (4 * 6)===&gt; 5 * 24===&gt; 120 递归函数的优点是定义简单，逻辑清晰。知识点: 理论上，所有的递归函数都可以写成循环的方式，但循环的逻辑不如递归清晰。 知识点: 使用递归函数需要注意防止栈溢出。在计算机中，函数调用是通过栈（stack）这种数据结构实现的，每当进入一个函数调用，栈就会加一层栈帧，每当函数返回，栈就会减一层栈帧。由于栈的大小不是无限的，所以，递归调用的次数过多，会导致栈溢出。可以试试计算 fact(10000)。 编程任务(天涯) 汉诺塔 (http://baike.baidu.com/view/191666.htm) 的移动也可以看做是递归函数。 我们对柱子编号为a, b, c，将所有圆盘从a移到c可以描述为： 如果a只有一个圆盘，可以直接移动到c； 如果a有N个圆盘，可以看成a有1个圆盘（底盘） + (N-1)个圆盘，首先需要把 (N-1) 个圆盘移动到 b，然后，将 a的最后一个圆盘移动到c，再将b的(N-1)个圆盘移动到c。 请编写一个函数，给定输入 n, a, b, c，打印出移动的步骤： 1move(n, a, b, c) 例如，输入 move(2, ‘A’, ‘B’, ‘C’)，打印出： 123A --&gt; BA --&gt; CB --&gt; C 实现代码： 12345678def move(n, a, b, c): if n ==1: print a, '--&gt;', c return move(n-1, a, c, b) print a, '--&gt;', c move(n-1, b, a, c)move(4, 'A', 'B', 'C') 运行结果: 123456789101112131415A --&gt; BA --&gt; CB --&gt; CA --&gt; BC --&gt; AC --&gt; BA --&gt; BA --&gt; CB --&gt; CB --&gt; AC --&gt; AB --&gt; CA --&gt; BA --&gt; CB --&gt; C 定义默认参数定义函数的时候，还可以有默认参数。 例如Python自带的 int() 函数，其实就有两个参数，我们既可以传一个参数，又可以传两个参数： 1234&gt;&gt;&gt; int(&apos;123&apos;)123&gt;&gt;&gt; int(&apos;123&apos;, 8)83 知识点: int()函数的第二个参数是转换进制，如果不传，默认是十进制 (base=10)，如果传了，就用传入的参数。 可见，函数的默认参数的作用是简化调用，你只需要把必须的参数传进去。但是在需要的时候，又可以传入额外的参数来覆盖默认参数值。 我们来定义一个计算 x 的N次方的函数: 123456def power(x, n): s = 1 while n &gt; 0: n = n - 1 s = s * x return s 假设计算平方的次数最多，我们就可以把 n 的默认值设定为 2： 123456def power(x, n=2): s = 1 while n &gt; 0: n = n - 1 s = s * x return s 这样一来，计算平方就不需要传入两个参数了： 12&gt;&gt;&gt; power(5)25 知识点: 由于函数的参数按从左到右的顺序匹配，所以默认参数只能定义在必需参数的后面： 123456# OK:def fn1(a, b=1, c=2): pass# Error:def fn2(a=1, b): pass 个人: 这里我们可以把自己想象成计算机。在自己感到为难不知道哪个是哪个的时候。那么恭喜你，计算机也不知道。 编程任务 请定义一个 greet()函数，它包含一个默认参数，如果没有传入，打印 &#39;Hello, world.&#39;，如果传入，打印 &#39;Hello, xxx.&#39; 实现代码: 12345def greet(x = 'World'): print 'Hello,'+x+'.'greet()greet('mtianyan') 运行结果: 12Hello,World.Hello,mtianyan. 知识点: 定义可变参数如果想让一个函数能接受任意个参数，我们就可以定义一个可变参数： 12def fn(*args): print args 可变参数的名字前面有个 * 号，我们可以传入0个、1个或多个参数给可变参数： 12345678&gt;&gt;&gt; fn()()&gt;&gt;&gt; fn('a')('a',)&gt;&gt;&gt; fn('a', 'b')('a', 'b')&gt;&gt;&gt; fn('a', 'b', 'c')('a', 'b', 'c') 可变参数也不是很神秘，Python解释器会把传入的一组参数组装成一个tuple传递给可变参数，因此，在函数内部，直接把变量 args 看成一个 tuple 就好了。 定义可变参数的目的也是为了简化调用。假设我们要计算任意个数的平均值，就可以定义一个可变参数： 12def average(*args): ... 这样，在调用的时候，可以这样写： 123456&gt;&gt;&gt; average()0&gt;&gt;&gt; average(1, 2)1.5&gt;&gt;&gt; average(1, 2, 2, 3, 4)2.4 编程任务 请编写接受可变参数的 average() 函数。 12345678910def average(*args): sum = 0.0 if len(args) == 0: return sum for x in args: sum = sum + x return sum / len(args)print average()print average(1, 2)print average(1, 2, 2, 3, 4) 运行结果: 1230.01.52.4 切片操作对list进行切片取一个list的部分元素是非常常见的操作。比如，一个list如下： 1&gt;&gt;&gt; L = [&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;, &apos;Paul&apos;] 取前3个元素，应该怎么做？ 笨办法： 12&gt;&gt;&gt; [L[0], L[1], L[2]][&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;] 之所以是笨办法是因为扩展一下，取前N个元素就没辙了。 取前N个元素，也就是索引为0-(N-1)的元素，可以用循环： 1234567&gt;&gt;&gt; r = []&gt;&gt;&gt; n = 3&gt;&gt;&gt; for i in range(n):... r.append(L[i])... &gt;&gt;&gt; r[&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;] 对这种经常取指定索引范围的操作，用循环十分繁琐，因此，Python提供了切片（Slice）操作符，能大大简化这种操作。 对应上面的问题，取前3个元素，用一行代码就可以完成切片： 123&gt;&gt;&gt; L[0:3][&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;]L[0:3]表示，从索引0开始取，直到索引3为止，但不包括索引3。即索引0，1，2，正好是3个元素。 知识点： [0:3]表示，从索引0开始取，直到索引3为止，但不包括索引3。即索引0，1，2，正好是3个元素。 如果第一个索引是0，还可以省略： 12&gt;&gt;&gt; L[:3][&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;] 也可以从索引1开始，取出2个元素出来： 12&gt;&gt;&gt; L[1:3][&apos;Lisa&apos;, &apos;Bart&apos;] 只用一个 : ，表示从头到尾： 12&gt;&gt;&gt; L[:][&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;, &apos;Paul&apos;] 因此，L[:]实际上复制出了一个新list。 知识点: 切片操作还可以指定第三个参数： 12&gt;&gt;&gt; L[::2][&apos;Adam&apos;, &apos;Bart&apos;] 第三个参数表示每N个取一个，上面的 L[::2] 会每两个元素取出一个来，也就是隔一个取一个。 把list换成tuple，切片操作完全相同，只是切片的结果也变成了tuple。 编程任务 range()函数可以创建一个数列： 12&gt;&gt;&gt; range(1, 101)[1, 2, 3, ..., 100] 请利用切片，取出： 前10个数； 3的倍数； 不大于50的5的倍数。 实现代码: 12345L = range(1, 101)print L[:10]print L[2::3]print L[4:50:5] 运行结果: 123[1, 2, 3, 4, 5, 6, 7, 8, 9, 10][3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54, 57, 60, 63, 66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99][5, 10, 15, 20, 25, 30, 35, 40, 45, 50] 倒序切片对于list，既然Python支持L[-1]取倒数第一个元素，那么它同样支持倒数切片，试试： 12345678910111213&gt;&gt;&gt; L = ['Adam', 'Lisa', 'Bart', 'Paul']&gt;&gt;&gt; L[-2:]['Bart', 'Paul']&gt;&gt;&gt; L[:-2]['Adam', 'Lisa']&gt;&gt;&gt; L[-3:-1]['Lisa', 'Bart']&gt;&gt;&gt; L[-4:-1:2]['Adam', 'Bart'] 记住倒数第一个元素的索引是-1。知识点：倒序切片包含起始索引，不包含结束索引。 编程任务 利用倒序切片对 1 - 100 的数列取出： 最后10个数； 最后10个5的倍数。 实现代码： 123L = range(1, 101)print L[-10:]print L[-46::5] 对字符串切片字符串 &#39;xxx&#39;和 Unicode字符串 u&#39;xxx&#39;也可以看成是一种list，每个元素就是一个字符。因此，字符串也可以用切片操作，只是操作结果仍是字符串： 123456&gt;&gt;&gt; &apos;ABCDEFG&apos;[:3]&apos;ABC&apos;&gt;&gt;&gt; &apos;ABCDEFG&apos;[-3:]&apos;EFG&apos;&gt;&gt;&gt; &apos;ABCDEFG&apos;[::2]&apos;ACEG&apos; 在很多编程语言中，针对字符串提供了很多各种截取函数，其实目的就是对字符串切片。知识点：Python没有针对字符串的截取函数，只需要切片一个操作就可以完成，非常简单。 编程任务 字符串有个方法 upper() 可以把字符变成大写字母： 12&gt;&gt;&gt; &apos;abc&apos;.upper()&apos;ABC&apos; 但它会把所有字母都变成大写。请设计一个函数，它接受一个字符串，然后返回一个仅首字母变成大写的字符串。 提示：利用切片操作简化字符串操作。 实现代码: 123456def firstCharUpper(s): return s[0].upper() + s[1:]print firstCharUpper('hello')print firstCharUpper('sunday')print firstCharUpper('september') 运行结果： 123HelloSundaySeptember 各种迭代方式什么是迭代在Python中，如果给定一个list或tuple，我们可以通过for循环来遍历这个list或tuple，这种遍历我们称为迭代（Iteration）。 在Python中，迭代是通过 for ... in 来完成的，而很多语言比如C或者Java，迭代list是通过下标完成的，比如Java代码： 123for (i=0; i&lt;list.length; i++) &#123; n = list[i];&#125; 可以看出，Python的for循环抽象程度要高于Java的for循环。 因为 Python 的 for循环不仅可以用在list或tuple上，还可以作用在其他任何可迭代对象上。 因此，迭代操作就是对于一个集合，无论该集合是有序还是无序，我们用 for 循环总是可以依次取出集合的每一个元素。 注意: 集合是指包含一组元素的数据结构，我们已经介绍的包括： 有序集合：list，tuple，知识点: str和unicode； 无序集合：set 无序集合并且具有 key-value 对：dict 而迭代是一个动词，它指的是一种操作，在Python中，就是 for 循环。 迭代与按下标访问数组最大的不同是，后者是一种具体的迭代实现方式，而前者只关心迭代结果，根本不关心迭代内部是如何实现的。 编程任务 请用for循环迭代数列 1-100 并打印出7的倍数。 实现代码: 123for i in range(1, 101): if i % 7 == 0: print i 运行结果: 1234567891011121314714212835424956637077849198 索引迭代知识点：Python中，迭代永远是取出元素本身，而非元素的索引。 对于有序集合，元素确实是有索引的。有的时候，我们确实想在 for 循环中拿到索引，怎么办？ 方法是使用 enumerate()函数： 12345678&gt;&gt;&gt; L = [&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;, &apos;Paul&apos;]&gt;&gt;&gt; for index, name in enumerate(L):... print index, &apos;-&apos;, name... 0 - Adam1 - Lisa2 - Bart3 - Paul 使用 enumerate()函数，我们可以在for循环中同时绑定索引index和元素name。但是，这不是 enumerate() 的特殊语法。实际上，enumerate() 函数把： 1[&apos;Adam&apos;, &apos;Lisa&apos;, &apos;Bart&apos;, &apos;Paul&apos;] 变成了类似： 1[(0, &apos;Adam&apos;), (1, &apos;Lisa&apos;), (2, &apos;Bart&apos;), (3, &apos;Paul&apos;)] 因此，迭代的每一个元素实际上是一个tuple： 1234for t in enumerate(L): index = t[0] name = t[1] print index, &apos;-&apos;, name 如果我们知道每个tuple元素都包含两个元素，for循环又可以进一步简写为： 12for index, name in enumerate(L): print index, &apos;-&apos;, name 这样不但代码更简单，而且还少了两条赋值语句。 可见，知识点: 索引迭代也不是真的按索引访问，而是由 enumerate() 函数自动把每个元素变成 (index, element) 这样的tuple，再迭代，就同时获得了索引和元素本身。 编程任务(天涯) zip()函数可以把两个 list 变成一个 list： 12&gt;&gt;&gt; zip([10, 20, 30], [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;])[(10, &apos;A&apos;), (20, &apos;B&apos;), (30, &apos;C&apos;)] 在迭代 [&#39;Adam&#39;, &#39;Lisa&#39;, &#39;Bart&#39;, &#39;Paul&#39;]时，如果我们想打印出名次 - 名字（名次从1开始)，请考虑如何在迭代中打印出来。 提示：考虑使用zip()函数和range()函数 实现代码: 123L = ['Adam', 'Lisa', 'Bart', 'Paul']for index, name in zip(range(1, len(L)+1), L): print index, '-', name 运行结果: 12341 - Adam2 - Lisa3 - Bart4 - Paul 迭代dict的value迭代dict的value我们已经了解了dict对象本身就是可迭代对象，用 for 循环直接迭代 dict，可以每次拿到dict的一个key。 如果我们希望迭代 dict 对象的value，应该怎么做？ 知识点：values()把dict转换成一个包含所有value的listdict 对象有一个 values() 方法，这个方法把dict转换成一个包含所有value的list，这样，我们迭代的就是 dict的每一个 value： 12345678d = &#123; &apos;Adam&apos;: 95, &apos;Lisa&apos;: 85, &apos;Bart&apos;: 59 &#125;print d.values()# [85, 95, 59]for v in d.values(): print v# 85# 95# 59 如果仔细阅读Python的文档，还可以发现，dict除了values()方法外，还有一个 itervalues() 方法，用 itervalues() 方法替代 values() 方法，迭代效果完全一样： 12345678d = &#123; &apos;Adam&apos;: 95, &apos;Lisa&apos;: 85, &apos;Bart&apos;: 59 &#125;print d.itervalues()# &lt;dictionary-valueiterator object at 0x106adbb50&gt;for v in d.itervalues(): print v# 85# 95# 59 那这两个方法有何不同之处呢？ values() 方法实际上把一个 dict 转换成了包含 value 的list。 但是 itervalues() 方法不会转换，它会在迭代过程中依次从 dict 中取出 value，所以 itervalues() 方法比 values() 方法节省了生成 list 所需的内存。 打印 itervalues() 发现它返回一个 对象，这说明在Python中，for 循环可作用的迭代对象远不止 list，tuple，str，unicode，dict等，知识点: 任何可迭代对象都可以作用于for循环，而内部如何迭代我们通常并不用关心。 如果一个对象说自己可迭代，那我们就直接用 for 循环去迭代它，知识点: 可见，迭代是一种抽象的数据操作，它不对迭代对象内部的数据有任何要求。 编程任务 给定一个dict：d = { ‘Adam’: 95, ‘Lisa’: 85, ‘Bart’: 59, ‘Paul’: 74 } 请计算所有同学的平均分。 实现代码: 12345d = &#123; &apos;Adam&apos;: 95, &apos;Lisa&apos;: 85, &apos;Bart&apos;: 59, &apos;Paul&apos;: 74 &#125;sum = 0.0for v in d.itervalues(): sum = sum + vprint sum / len(d) 运行结果: 178.25 迭代dict的key和value我们了解了如何迭代 dict 的key和value，那么，在一个 for 循环中，能否同时迭代 key和value？答案是肯定的。 首先，我们看看 dict 对象的 items()方法返回的值： 123&gt;&gt;&gt; d = &#123; &apos;Adam&apos;: 95, &apos;Lisa&apos;: 85, &apos;Bart&apos;: 59 &#125;&gt;&gt;&gt; print d.items()[(&apos;Lisa&apos;, 85), (&apos;Adam&apos;, 95), (&apos;Bart&apos;, 59)] 可以看到，items() 方法把dict对象转换成了包含tuple的list，我们对这个list进行迭代，可以同时获得key和value： 123456&gt;&gt;&gt; for key, value in d.items():... print key, &apos;:&apos;, value... Lisa : 85Adam : 95Bart : 59 和 values()有一个 itervalues() 类似，items() 也有一个对应的 iteritems()，知识点： iteritems() 不把dict转换成list，而是在迭代过程中不断给出 tuple，所以， iteritems() 不占用额外的内存。 编程任务 请根据dict：d = { ‘Adam’: 95, ‘Lisa’: 85, ‘Bart’: 59, ‘Paul’: 74 } 打印出 name : score，最后再打印出平均分 average : score。 实现代码： 123456d = &#123; 'Adam': 95, 'Lisa': 85, 'Bart': 59, 'Paul': 74 &#125;sum = 0.0for k, v in d.iteritems(): sum = sum + v print k, ':', vprint 'average', ':', sum / len(d) 运行结果： 12345Lisa : 85Paul : 74Adam : 95Bart : 59average : 78.25 列表生成式:快速生成列表生成列表要生成list [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]，我们可以用range(1, 11)： 12&gt;&gt;&gt; range(1, 11)[1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 但如果要生成[1x1, 2x2, 3x3, ..., 10x10]怎么做？ 方法一是循环： 123456&gt;&gt;&gt; L = []&gt;&gt;&gt; for x in range(1, 11):... L.append(x * x)... &gt;&gt;&gt; L[1, 4, 9, 16, 25, 36, 49, 64, 81, 100] 但是循环太繁琐，而列表生成式则可以用一行语句代替循环生成上面的list： 12&gt;&gt;&gt; [x * x for x in range(1, 11)][1, 4, 9, 16, 25, 36, 49, 64, 81, 100] 这种写法就是Python特有的列表生成式。利用列表生成式，可以以非常简洁的代码生成 list。 知识点: 写列表生成式时，把要生成的元素 x * x放到前面，后面跟 for 循环，就可以把list创建出来，十分有用，多写几次，很快就可以熟悉这种语法。 编程任务 请利用列表生成式生成列表 [1x2, 3x4, 5x6, 7x8, ..., 99x100] 提示：range(1, 100, 2)可以生成list [1, 3, 5, 7, 9,...] 实现代码： 1print [x * (x + 1) for x in range(1, 100, 2)] 运行结果： 1[2, 12, 30, 56, 90, 132, 182, 240, 306, 380, 462, 552, 650, 756, 870, 992, 1122, 1260, 1406, 1560, 1722, 1892, 2070, 2256, 2450, 2652, 2862, 3080, 3306, 3540, 3782, 4032, 4290, 4556, 4830, 5112, 5402, 5700, 6006, 6320, 6642, 6972, 7310, 7656, 8010, 8372, 8742, 9120, 9506, 9900] 复杂表达式使用for循环的迭代不仅可以迭代普通的list，还可以迭代dict。 假设有如下的dict： 1d = &#123; 'Adam': 95, 'Lisa': 85, 'Bart': 59 &#125; 完全可以通过一个复杂的列表生成式把它变成一个 HTML 表格： 12345tds = ['&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%s&lt;/td&gt;&lt;/tr&gt;' % (name, score) for name, score in d.iteritems()]print '&lt;table&gt;'print '&lt;tr&gt;&lt;th&gt;Name&lt;/th&gt;&lt;th&gt;Score&lt;/th&gt;&lt;tr&gt;'print '\n'.join(tds)print '&lt;/table&gt;' 个人：&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%s&lt;/td&gt;&lt;/tr&gt; 中： 第一个%s是name的填充位置。 第二个%s为score的填充位置。 有多少个name和score，会通过循环生成多少个。&lt;tr&gt;&lt;th&gt;Name&lt;/th&gt;&lt;th&gt;Score&lt;/th&gt;&lt;tr&gt;设置表格头print ‘\n’.join(tds)。列表里的项通过\n连接成字符串。 注：字符串可以通过%进行格式化，用指定的参数替代 %s。字符串的join()方法可以把一个 list拼接成一个字符串。 把打印出来的结果保存为一个html文件，就可以在浏览器中看到效果了： 123456&lt;table border="1"&gt;&lt;tr&gt;&lt;th&gt;Name&lt;/th&gt;&lt;th&gt;Score&lt;/th&gt;&lt;tr&gt;&lt;tr&gt;&lt;td&gt;Lisa&lt;/td&gt;&lt;td&gt;85&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Adam&lt;/td&gt;&lt;td&gt;95&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Bart&lt;/td&gt;&lt;td&gt;59&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; 编程任务(天涯) 在生成的表格中，对于没有及格的同学，请把分数标记为红色。 提示：红色可以用 &lt;td style=&quot;color:red&quot;&gt; 实现。 实现代码: 12345678910d = &#123; &apos;Adam&apos;: 95, &apos;Lisa&apos;: 85, &apos;Bart&apos;: 59 &#125;def generate_tr(name, score): if score &lt; 60: return &apos;&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td style=&quot;color:red&quot;&gt;%s&lt;/td&gt;&lt;/tr&gt;&apos; % (name, score) return &apos;&lt;tr&gt;&lt;td&gt;%s&lt;/td&gt;&lt;td&gt;%s&lt;/td&gt;&lt;/tr&gt;&apos; % (name, score)tds = [generate_tr(name, score) for name, score in d.iteritems()]print &apos;&lt;table border=&quot;1&quot;&gt;&apos;print &apos;&lt;tr&gt;&lt;th&gt;Name&lt;/th&gt;&lt;th&gt;Score&lt;/th&gt;&lt;tr&gt;&apos;print &apos;\n&apos;.join(tds)print &apos;&lt;/table&gt;&apos; 运行结果: 条件过滤列表生成式的 for 循环后面还可以加上 if 判断。例如： 12&gt;&gt;&gt; [x * x for x in range(1, 11)][1, 4, 9, 16, 25, 36, 49, 64, 81, 100] 如果我们只想要偶数的平方，不改动 range()的情况下，可以加上 if 来筛选： 12&gt;&gt;&gt; [x * x for x in range(1, 11) if x % 2 == 0][4, 16, 36, 64, 100] 有了 if 条件，只有 if 判断为 True 的时候，才把循环的当前元素添加到列表中。 编程任务 请编写一个函数，它接受一个 list，然后把list中的所有字符串变成大写后返回，非字符串元素将被忽略。 提示： isinstance(x, str) 可以判断变量 x 是否是字符串； 字符串的 upper() 方法可以返回大写的字母。 实现代码: 123def toUppers(L): return [x.upper() for x in L if isinstance(x, str)]print toUppers(['Hello', 'world', 101]) 运行结果: 1[&apos;HELLO&apos;, &apos;WORLD&apos;] 多层表达式(知识点)for循环可以嵌套，知识点：因此，在列表生成式中，也可以用多层 for 循环来生成列表。 对于字符串 &#39;ABC&#39; 和 &#39;123&#39;，可以使用两层循环，生成全排列： 12&gt;&gt;&gt; [m + n for m in 'ABC' for n in '123']['A1', 'A2', 'A3', 'B1', 'B2', 'B3', 'C1', 'C2', 'C3'] 翻译成循环代码就像下面这样： 1234L = []for m in 'ABC': for n in '123': L.append(m + n) 编程任务(天涯) 利用 3 层for循环的列表生成式，找出对称的 3 位数。例如，121 就是对称数，因为从右到左倒过来还是 121。 实现代码: 1print [100 * n1 + 10 * n2 + n3 for n1 in range(1, 10) for n2 in range(10) for n3 in range(10) if n1==n3] 运行结果： 1101, 111, 121, 131, 141, 151, 161, 171, 181, 191, 202, 212, 222, 232, 242, 252, 262, 272, 282, 292, 303, 313, 323, 333, 343, 353, 363, 373, 383, 393, 404, 414, 424, 434, 444, 454, 464, 474, 484, 494, 505, 515, 525, 535, 545, 555, 565, 575, 585, 595, 606, 616, 626, 636, 646, 656, 666, 676, 686, 696, 707, 717, 727, 737, 747, 757, 767, 777, 787, 797, 808, 818, 828, 838, 848, 858, 868, 878, 888, 898, 909, 919, 929, 939, 949, 959, 969, 979, 989, 999]]]></content>
      <categories>
        <category>python从入门到精通</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>零基础入门</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
</search>
